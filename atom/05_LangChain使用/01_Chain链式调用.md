# Chain é“¾å¼è°ƒç”¨

> åŸå­åŒ–çŸ¥è¯†ç‚¹ | LangChain ä½¿ç”¨ | LangChain æºç å­¦ä¹ æ ¸å¿ƒçŸ¥è¯†

---

## 1. ã€30å­—æ ¸å¿ƒã€‘

**Chain æ˜¯ LangChain ä¸­å°†å¤šä¸ªç»„ä»¶ä¸²è”çš„æ ¸å¿ƒæœºåˆ¶ï¼Œé€šè¿‡ LCEL çš„ pipe(|) æ“ä½œç¬¦å®ç°æ•°æ®çš„æµæ°´çº¿å¤„ç†ã€‚**

---

## 2. ã€ç¬¬ä¸€æ€§åŸç†ã€‘

### ä»€ä¹ˆæ˜¯ç¬¬ä¸€æ€§åŸç†ï¼Ÿ

**ç¬¬ä¸€æ€§åŸç†**ï¼šå›åˆ°äº‹ç‰©æœ€åŸºæœ¬çš„çœŸç†ï¼Œä»æºå¤´æ€è€ƒé—®é¢˜

### Chain é“¾å¼è°ƒç”¨çš„ç¬¬ä¸€æ€§åŸç† ğŸ¯

#### 1. æœ€åŸºç¡€çš„å®šä¹‰

**Chain = å¤šä¸ªå¤„ç†æ­¥éª¤çš„æœ‰åºç»„åˆ**

ä»…æ­¤è€Œå·²ï¼æ²¡æœ‰æ›´åŸºç¡€çš„äº†ã€‚

```python
# Chain çš„æœ¬è´¨å°±æ˜¯ï¼š
# è¾“å…¥ â†’ æ­¥éª¤1 â†’ æ­¥éª¤2 â†’ æ­¥éª¤3 â†’ è¾“å‡º

# æ¯ä¸€æ­¥çš„è¾“å‡ºæˆä¸ºä¸‹ä¸€æ­¥çš„è¾“å…¥
def chain(input):
    result = step1(input)
    result = step2(result)
    result = step3(result)
    return result
```

#### 2. ä¸ºä»€ä¹ˆéœ€è¦ Chainï¼Ÿ

**æ ¸å¿ƒé—®é¢˜ï¼šLLM åº”ç”¨é€šå¸¸ä¸æ˜¯å•ä¸€è°ƒç”¨ï¼Œè€Œæ˜¯å¤šä¸ªæ­¥éª¤çš„ç»„åˆ**

```python
# å®é™…åœºæ™¯ï¼šä¸€ä¸ªç®€å•çš„é—®ç­”ç³»ç»Ÿ
# æ­¥éª¤1ï¼šæ ¼å¼åŒ–ç”¨æˆ·é—®é¢˜ï¼ˆPromptï¼‰
# æ­¥éª¤2ï¼šè°ƒç”¨ LLM è·å–å›ç­”
# æ­¥éª¤3ï¼šè§£æè¾“å‡ºæ ¼å¼ï¼ˆParserï¼‰

# å¦‚æœæ²¡æœ‰ Chainï¼Œä»£ç ä¼šå˜æˆï¼š
prompt_result = format_prompt(user_question)
llm_result = call_llm(prompt_result)
final_result = parse_output(llm_result)

# æœ‰äº† Chainï¼Œä»£ç å˜æˆï¼š
chain = prompt | llm | parser
result = chain.invoke(user_question)
```

#### 3. Chain çš„ä¸‰å±‚ä»·å€¼

##### ä»·å€¼1ï¼šç»„åˆæ€§ - åƒä¹é«˜ç§¯æœ¨ä¸€æ ·ç»„è£…

```python
# ä»»ä½• Runnable éƒ½å¯ä»¥ç»„åˆ
chain1 = prompt1 | llm | parser1
chain2 = prompt2 | llm | parser2

# ç»„åˆæˆæ›´å¤§çš„ Chain
big_chain = chain1 | transform | chain2
```

##### ä»·å€¼2ï¼šç»Ÿä¸€æ¥å£ - invoke/stream/batch é€šç”¨

```python
# åŒä¸€ä¸ª Chainï¼Œä¸åŒè°ƒç”¨æ–¹å¼
result = chain.invoke(input)              # å•æ¬¡è°ƒç”¨
async_result = await chain.ainvoke(input) # å¼‚æ­¥è°ƒç”¨
stream = chain.stream(input)              # æµå¼è¾“å‡º
results = chain.batch([input1, input2])   # æ‰¹é‡è°ƒç”¨
```

##### ä»·å€¼3ï¼šé…ç½®ä¼ é€’ - å‚æ•°è‡ªåŠ¨æµè½¬

```python
# config ä¼šè‡ªåŠ¨ä¼ é€’ç»™ Chain ä¸­çš„æ¯ä¸ªç»„ä»¶
result = chain.invoke(
    input,
    config={
        "callbacks": [my_callback],
        "tags": ["production"],
        "metadata": {"user_id": "123"}
    }
)
```

#### 4. ä»ç¬¬ä¸€æ€§åŸç†æ¨å¯¼ LCEL

**æ¨ç†é“¾ï¼š**

```
1. LLM åº”ç”¨éœ€è¦å¤šæ­¥éª¤å¤„ç†
   â†“
2. æ­¥éª¤ä¹‹é—´éœ€è¦æ•°æ®ä¼ é€’
   â†“
3. éœ€è¦ç»Ÿä¸€çš„ç»„åˆæ–¹å¼
   â†“
4. Python çš„ | æ“ä½œç¬¦å¯ä»¥é‡è½½
   â†“
5. å®ç° __or__ æ–¹æ³•å®ç° pipe è¯­æ³•
   â†“
6. è¿™å°±æ˜¯ LCEL (LangChain Expression Language)
   â†“
7. chain = component1 | component2 | component3
```

#### 5. ä¸€å¥è¯æ€»ç»“ç¬¬ä¸€æ€§åŸç†

**Chain æ˜¯å°†å¤šä¸ªå¤„ç†æ­¥éª¤ç»„åˆæˆæµæ°´çº¿çš„æœºåˆ¶ï¼Œé€šè¿‡ LCEL çš„ pipe æ“ä½œç¬¦å®ç°ä¼˜é›…çš„å£°æ˜å¼ç»„åˆã€‚**

---

## 3. ã€æ ¸å¿ƒæ¦‚å¿µï¼ˆå…¨é¢è¦†ç›–ï¼‰ã€‘

### æ ¸å¿ƒæ¦‚å¿µ1ï¼šRunnableSequence åºåˆ—æ‰§è¡Œ ğŸ”—

**RunnableSequence æ˜¯å¤šä¸ª Runnable é¡ºåºæ‰§è¡Œçš„å®¹å™¨ï¼Œå‰ä¸€ä¸ªçš„è¾“å‡ºæ˜¯åä¸€ä¸ªçš„è¾“å…¥**

```python
from langchain_core.runnables import RunnableSequence, RunnableLambda
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

# æ–¹å¼1ï¼šä½¿ç”¨ pipe æ“ä½œç¬¦ï¼ˆæ¨èï¼‰
prompt = ChatPromptTemplate.from_template("ç¿»è¯‘æˆè‹±æ–‡ï¼š{text}")
chain = prompt | llm | StrOutputParser()

# æ–¹å¼2ï¼šæ˜¾å¼åˆ›å»º RunnableSequence
chain = RunnableSequence(
    first=prompt,
    middle=[llm],
    last=StrOutputParser()
)

# æ‰§è¡Œ
result = chain.invoke({"text": "ä½ å¥½ä¸–ç•Œ"})
print(result)  # "Hello World"
```

**æ•°æ®æµè½¬ç¤ºæ„ï¼š**

```
è¾“å…¥: {"text": "ä½ å¥½ä¸–ç•Œ"}
    â†“
[ChatPromptTemplate] â†’ ChatPromptValue
    â†“
[ChatOpenAI] â†’ AIMessage(content="Hello World")
    â†“
[StrOutputParser] â†’ "Hello World"
    â†“
è¾“å‡º: "Hello World"
```

**åœ¨ LangChain æºç ä¸­çš„å®ç°ï¼š**

```python
# langchain_core/runnables/base.py
class RunnableSequence(RunnableSerializable):
    """é¡ºåºæ‰§è¡Œå¤šä¸ª Runnable"""

    first: Runnable  # ç¬¬ä¸€ä¸ª
    middle: List[Runnable] = []  # ä¸­é—´çš„
    last: Runnable  # æœ€åä¸€ä¸ª

    def invoke(self, input, config=None):
        # ä¾æ¬¡æ‰§è¡Œæ¯ä¸ªæ­¥éª¤
        for step in self.steps:
            input = step.invoke(input, config)
        return input

    @property
    def steps(self):
        return [self.first] + self.middle + [self.last]
```

---

### æ ¸å¿ƒæ¦‚å¿µ2ï¼šPipe æ“ä½œç¬¦ | ğŸ“

**pipe æ“ä½œç¬¦é€šè¿‡ Python çš„ `__or__` é­”æ³•æ–¹æ³•å®ç°ï¼Œè®© Chain ç»„åˆå˜å¾—ä¼˜é›…**

```python
from langchain_core.runnables import Runnable, RunnableLambda

# | æ“ä½œç¬¦çš„æœ¬è´¨
# a | b ç­‰ä»·äº a.__or__(b) æˆ– b.__ror__(a)

# ç¤ºä¾‹ï¼šè‡ªå®šä¹‰ Runnable
def add_one(x: int) -> int:
    return x + 1

def multiply_two(x: int) -> int:
    return x * 2

# ä½¿ç”¨ RunnableLambda åŒ…è£…å‡½æ•°
step1 = RunnableLambda(add_one)
step2 = RunnableLambda(multiply_two)

# ä½¿ç”¨ pipe ç»„åˆ
chain = step1 | step2

# æ‰§è¡Œï¼š(5 + 1) * 2 = 12
result = chain.invoke(5)
print(result)  # 12
```

**pipe æ“ä½œç¬¦æ”¯æŒçš„ç»„åˆç±»å‹ï¼š**

```python
from langchain_core.runnables import RunnableParallel, RunnablePassthrough

# 1. Runnable | Runnable
chain = prompt | llm

# 2. Runnable | dict (è‡ªåŠ¨è½¬æ¢ä¸º RunnableParallel)
chain = retriever | {"context": lambda x: x, "question": RunnablePassthrough()}

# 3. dict | Runnable
chain = {"a": step1, "b": step2} | combine_step

# 4. å‡½æ•°ä¹Ÿå¯ä»¥ï¼ˆè‡ªåŠ¨åŒ…è£…ä¸º RunnableLambdaï¼‰
chain = prompt | llm | (lambda x: x.content.upper())
```

**åœ¨ LangChain æºç ä¸­çš„å®ç°ï¼š**

```python
# langchain_core/runnables/base.py
class Runnable(ABC):
    def __or__(self, other):
        """å®ç° | æ“ä½œç¬¦"""
        return RunnableSequence(first=self, last=coerce_to_runnable(other))

    def __ror__(self, other):
        """å®ç°åå‘ | æ“ä½œç¬¦"""
        return RunnableSequence(first=coerce_to_runnable(other), last=self)

def coerce_to_runnable(thing):
    """å°†å„ç§ç±»å‹è½¬æ¢ä¸º Runnable"""
    if isinstance(thing, Runnable):
        return thing
    elif callable(thing):
        return RunnableLambda(thing)
    elif isinstance(thing, dict):
        return RunnableParallel(thing)
    else:
        raise TypeError(f"Cannot coerce {type(thing)} to Runnable")
```

---

### æ ¸å¿ƒæ¦‚å¿µ3ï¼šRunnableParallel å¹¶è¡Œæ‰§è¡Œ ğŸ”€

**RunnableParallel è®©å¤šä¸ª Runnable åŒæ—¶æ‰§è¡Œï¼Œç»“æœåˆå¹¶ä¸ºå­—å…¸**

```python
from langchain_core.runnables import RunnableParallel, RunnablePassthrough

# åœºæ™¯ï¼šåŒæ—¶æ‰§è¡Œç¿»è¯‘å’Œæ‘˜è¦
translate_chain = translate_prompt | llm | StrOutputParser()
summary_chain = summary_prompt | llm | StrOutputParser()

# å¹¶è¡Œæ‰§è¡Œ
parallel = RunnableParallel({
    "translation": translate_chain,
    "summary": summary_chain
})

# æ‰§è¡Œ
result = parallel.invoke({"text": "è¿™æ˜¯ä¸€æ®µä¸­æ–‡"})
# result = {
#     "translation": "This is a Chinese text",
#     "summary": "A short Chinese passage"
# }
```

**RAG ä¸­çš„å…¸å‹ç”¨æ³•ï¼š**

```python
from langchain_core.runnables import RunnablePassthrough

# RAG Chainï¼šæ£€ç´¢å’Œé—®é¢˜å¹¶è¡Œä¼ é€’
rag_chain = (
    {"context": retriever, "question": RunnablePassthrough()}
    | prompt
    | llm
    | StrOutputParser()
)

# æ‰§è¡Œ
# 1. retriever æ£€ç´¢ç›¸å…³æ–‡æ¡£
# 2. RunnablePassthrough ç›´æ¥ä¼ é€’åŸå§‹é—®é¢˜
# 3. ä¸¤è€…åˆå¹¶åä¼ ç»™ prompt
result = rag_chain.invoke("ä»€ä¹ˆæ˜¯ LangChainï¼Ÿ")
```

**æ•°æ®æµè½¬ç¤ºæ„ï¼š**

```
è¾“å…¥: "ä»€ä¹ˆæ˜¯ LangChainï¼Ÿ"
         â†“
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
    â†“         â†“
[retriever] [passthrough]
    â†“         â†“
 [docs]    "ä»€ä¹ˆæ˜¯..."
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
         â†“
{"context": docs, "question": "ä»€ä¹ˆæ˜¯..."}
         â†“
    [prompt | llm | parser]
         â†“
    è¾“å‡º: "ç­”æ¡ˆ..."
```

---

### æ‰©å±•æ¦‚å¿µ4ï¼šRunnableBranch æ¡ä»¶åˆ†æ”¯ ğŸ”€

**RunnableBranch æ ¹æ®æ¡ä»¶é€‰æ‹©ä¸åŒçš„æ‰§è¡Œè·¯å¾„**

```python
from langchain_core.runnables import RunnableBranch

# å®šä¹‰æ¡ä»¶åˆ†æ”¯
branch = RunnableBranch(
    # (æ¡ä»¶, æ‰§è¡Œçš„ Runnable)
    (lambda x: "ç¿»è¯‘" in x["task"], translate_chain),
    (lambda x: "æ‘˜è¦" in x["task"], summary_chain),
    # é»˜è®¤åˆ†æ”¯
    default_chain
)

# æ ¹æ®è¾“å…¥é€‰æ‹©åˆ†æ”¯
result = branch.invoke({"task": "ç¿»è¯‘è¿™æ®µè¯", "text": "..."})
```

---

### æ‰©å±•æ¦‚å¿µ5ï¼šRunnablePassthrough é€ä¼  â¡ï¸

**RunnablePassthrough ç›´æ¥ä¼ é€’è¾“å…¥ï¼Œå¸¸ç”¨äºå¹¶è¡Œæ—¶ä¿ç•™åŸå§‹æ•°æ®**

```python
from langchain_core.runnables import RunnablePassthrough

# åŸºç¡€ç”¨æ³•ï¼šç›´æ¥ä¼ é€’
passthrough = RunnablePassthrough()
result = passthrough.invoke("hello")  # "hello"

# å¸¦èµ‹å€¼çš„é€ä¼ 
chain = RunnablePassthrough.assign(
    enhanced=lambda x: x["text"].upper()
)
result = chain.invoke({"text": "hello"})
# {"text": "hello", "enhanced": "HELLO"}
```

---

### æ‰©å±•æ¦‚å¿µ6ï¼šRunnableLambda å‡½æ•°åŒ…è£… Î»

**RunnableLambda å°†æ™®é€šå‡½æ•°åŒ…è£…ä¸º Runnable**

```python
from langchain_core.runnables import RunnableLambda

# åŒ…è£…åŒæ­¥å‡½æ•°
def process(text: str) -> str:
    return text.strip().lower()

runnable = RunnableLambda(process)
result = runnable.invoke("  HELLO  ")  # "hello"

# åŒ…è£…å¼‚æ­¥å‡½æ•°
async def async_process(text: str) -> str:
    await asyncio.sleep(0.1)
    return text.upper()

async_runnable = RunnableLambda(async_process)
result = await async_runnable.ainvoke("hello")  # "HELLO"
```

---

## 4. ã€æœ€å°å¯ç”¨ã€‘

æŒæ¡ä»¥ä¸‹å†…å®¹ï¼Œå°±èƒ½åœ¨ LangChain ä¸­æ„å»º Chainï¼š

### 4.1 åŸºç¡€ Chain ç»„åˆ

```python
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_openai import ChatOpenAI

# ä¸‰æ­¥èµ°ï¼šPrompt â†’ LLM â†’ Parser
prompt = ChatPromptTemplate.from_template("å›ç­”é—®é¢˜ï¼š{question}")
llm = ChatOpenAI()
parser = StrOutputParser()

# ä½¿ç”¨ | ç»„åˆ
chain = prompt | llm | parser

# è°ƒç”¨
result = chain.invoke({"question": "ä»€ä¹ˆæ˜¯ Pythonï¼Ÿ"})
```

### 4.2 å¹¶è¡Œæ‰§è¡Œ

```python
from langchain_core.runnables import RunnableParallel

# å¤šä¸ªä»»åŠ¡å¹¶è¡Œ
parallel = RunnableParallel({
    "answer": qa_chain,
    "sources": retriever
})

result = parallel.invoke({"question": "..."})
# result["answer"] å’Œ result["sources"] åŒæ—¶è®¡ç®—
```

### 4.3 RAG Chain æ¨¡æ¿

```python
from langchain_core.runnables import RunnablePassthrough

# æ ‡å‡† RAG Chain
rag_chain = (
    {"context": retriever, "question": RunnablePassthrough()}
    | prompt
    | llm
    | StrOutputParser()
)

result = rag_chain.invoke("ä½ çš„é—®é¢˜")
```

### 4.4 æµå¼è¾“å‡º

```python
# ä½¿ç”¨ stream æ–¹æ³•
for chunk in chain.stream({"question": "..."}):
    print(chunk, end="", flush=True)
```

**è¿™äº›çŸ¥è¯†è¶³ä»¥ï¼š**
- æ„å»º Prompt â†’ LLM â†’ Parser çš„åŸºç¡€ Chain
- å®ç°å¹¶è¡Œæ‰§è¡Œæé«˜æ•ˆç‡
- æ„å»º RAG åº”ç”¨
- å®ç°æµå¼è¾“å‡ºæå‡ç”¨æˆ·ä½“éªŒ

---

## 5. ã€1ä¸ªç±»æ¯”ã€‘ï¼ˆåŒè½¨åˆ¶ï¼‰

### ç±»æ¯”1ï¼šChain æ˜¯æµæ°´çº¿

#### ğŸ¨ å‰ç«¯è§†è§’ï¼šRedux Middleware / RxJS pipe

Chain å°±åƒ Redux ä¸­é—´ä»¶æˆ– RxJS çš„ pipeï¼Œæ•°æ®ä¾æ¬¡ç»è¿‡æ¯ä¸ªå¤„ç†ç¯èŠ‚ã€‚

```javascript
// Redux Middleware é“¾
const store = createStore(
  reducer,
  applyMiddleware(logger, thunk, api)  // ä¸­é—´ä»¶é“¾
);

// RxJS pipe
observable.pipe(
  map(x => x * 2),
  filter(x => x > 10),
  take(5)
);
```

```python
# LangChain Chain
chain = prompt | llm | parser

# æ•°æ®æµï¼šinput â†’ prompt â†’ llm â†’ parser â†’ output
```

**å…³é”®ç›¸ä¼¼ç‚¹ï¼š**
- éƒ½æ˜¯æ•°æ®çš„å•å‘æµåŠ¨
- æ¯ä¸ªç¯èŠ‚åªå…³å¿ƒè‡ªå·±çš„å¤„ç†
- é€šè¿‡ç»„åˆå®ç°å¤æ‚åŠŸèƒ½

#### ğŸ§’ å°æœ‹å‹è§†è§’ï¼šå·¥å‚æµæ°´çº¿

Chain å°±åƒå·¥å‚çš„æµæ°´çº¿ï¼š

```
åŸææ–™ â†’ [åˆ‡å‰²æœº] â†’ [æ‰“ç£¨æœº] â†’ [ä¸Šè‰²æœº] â†’ æˆå“

ä¸€ä¸ªé›¶ä»¶ä¾æ¬¡ç»è¿‡æ¯å°æœºå™¨ï¼š
1. åˆ‡å‰²æœºæŠŠåŸææ–™åˆ‡æˆå½¢çŠ¶
2. æ‰“ç£¨æœºæŠŠè¾¹ç¼˜ç£¨å…‰æ»‘
3. ä¸Šè‰²æœºæ¶‚ä¸Šæ¼‚äº®çš„é¢œè‰²
4. æœ€åå˜æˆæˆå“ï¼

æ¯å°æœºå™¨åªåšä¸€ä»¶äº‹ï¼Œä½†ç»„åˆèµ·æ¥å°±èƒ½åšå‡ºå¤æ‚çš„äº§å“ã€‚
```

**ç”Ÿæ´»ä¾‹å­ï¼š**
```
åšä¸‰æ˜æ²»ï¼š
é¢åŒ… â†’ [åˆ‡å¼€] â†’ [æ¶‚é…±] â†’ [æ”¾è‚‰] â†’ [æ”¾èœ] â†’ [åˆä¸Š] â†’ ä¸‰æ˜æ²»

æ¯ä¸€æ­¥éƒ½å¾ˆç®€å•ï¼Œä½†æŒ‰é¡ºåºç»„åˆå°±èƒ½åšå‡ºç¾å‘³çš„ä¸‰æ˜æ²»ï¼
```

---

### ç±»æ¯”2ï¼špipe æ“ä½œç¬¦æ˜¯ä¼ é€å¸¦

#### ğŸ¨ å‰ç«¯è§†è§’ï¼šPromise.then é“¾ / Unix ç®¡é“

pipe æ“ä½œç¬¦å°±åƒ Promise.then æˆ– Unix ç®¡é“ï¼Œè¿æ¥å¤šä¸ªå¤„ç†æ­¥éª¤ã€‚

```javascript
// Promise.then é“¾
fetch(url)
  .then(response => response.json())
  .then(data => process(data))
  .then(result => display(result));

// Unix ç®¡é“
// cat file.txt | grep "error" | wc -l
```

```python
# LangChain pipe
chain = prompt | llm | parser
# ç­‰ä»·äº Unix: prompt | llm | parser
```

#### ğŸ§’ å°æœ‹å‹è§†è§’ï¼šä¼ é€å¸¦

pipe å°±åƒè¶…å¸‚çš„ä¼ é€å¸¦ï¼š

```
ä½ æŠŠå•†å“æ”¾ä¸Šä¼ é€å¸¦ï¼š
è‹¹æœ â†’ ã€æ‰«ç ã€‘ â†’ ã€ç§°é‡ã€‘ â†’ ã€è£…è¢‹ã€‘ â†’ æ‹¿èµ°

å•†å“è‡ªåŠ¨ä»ä¸€ä¸ªç«™ç‚¹ä¼ åˆ°ä¸‹ä¸€ä¸ªï¼Œ
æ¯ä¸ªç«™ç‚¹åšè‡ªå·±çš„äº‹æƒ…ï¼Œ
æœ€åä½ æ‹¿åˆ°å¤„ç†å¥½çš„å•†å“ã€‚
```

---

### ç±»æ¯”3ï¼šRunnableParallel æ˜¯å¹¶è¡Œè½¦é“

#### ğŸ¨ å‰ç«¯è§†è§’ï¼šPromise.all

RunnableParallel å°±åƒ Promise.allï¼ŒåŒæ—¶æ‰§è¡Œå¤šä¸ªä»»åŠ¡ã€‚

```javascript
// Promise.all å¹¶è¡Œæ‰§è¡Œ
const [users, posts, comments] = await Promise.all([
  fetchUsers(),
  fetchPosts(),
  fetchComments()
]);
```

```python
# LangChain RunnableParallel
parallel = RunnableParallel({
    "translation": translate_chain,
    "summary": summary_chain
})
```

#### ğŸ§’ å°æœ‹å‹è§†è§’ï¼šå¤šäººåŒæ—¶åšäº‹

RunnableParallel å°±åƒåˆ†å·¥åˆä½œï¼š

```
è€å¸ˆè¯´ï¼šæŠŠè¿™ç¯‡æ–‡ç« ç¿»è¯‘æˆè‹±æ–‡ï¼Œç„¶åå†™ä¸€ä¸ªæ‘˜è¦

âŒ ä¸€ä¸ªäººåšï¼šå…ˆç¿»è¯‘ï¼ˆ10åˆ†é’Ÿï¼‰â†’ å†å†™æ‘˜è¦ï¼ˆ10åˆ†é’Ÿï¼‰= 20åˆ†é’Ÿ

âœ… ä¸¤ä¸ªäººåšï¼š
   å°æ˜ç¿»è¯‘ï¼ˆ10åˆ†é’Ÿï¼‰â”€â”€â”
                      â”œâ†’ åˆå¹¶ç»“æœ = 10åˆ†é’Ÿ
   å°çº¢å†™æ‘˜è¦ï¼ˆ10åˆ†é’Ÿï¼‰â”€â”˜

ä¸¤ä¸ªä»»åŠ¡åŒæ—¶è¿›è¡Œï¼Œæ—¶é—´å‡åŠï¼
```

---

### ç±»æ¯”æ€»ç»“è¡¨

| LangChain æ¦‚å¿µ | å‰ç«¯ç±»æ¯” | å°æœ‹å‹ç±»æ¯” |
|---------------|---------|-----------|
| Chain | Redux middleware / RxJS pipe | å·¥å‚æµæ°´çº¿ |
| pipe æ“ä½œç¬¦ | Promise.then / Unix ç®¡é“ | ä¼ é€å¸¦ |
| RunnableSequence | åŒæ­¥å‡½æ•°è°ƒç”¨é“¾ | æ¥åŠ›èµ›è·‘ |
| RunnableParallel | Promise.all | å¤šäººåŒæ—¶åšäº‹ |
| RunnablePassthrough | æ’ç­‰å‡½æ•° / identity | ç›´æ¥ä¼ é€’ä¸æ”¹å˜ |
| RunnableBranch | if-else / switch | èµ°ä¸åŒçš„è·¯ |
| RunnableLambda | é«˜é˜¶å‡½æ•° | æŠŠæ™®é€šäº‹æƒ…å˜æˆæ ‡å‡†æµç¨‹ |

---

## 6. ã€åç›´è§‰ç‚¹ã€‘

### è¯¯åŒº1ï¼šChain åªèƒ½é¡ºåºæ‰§è¡Œ âŒ

**ä¸ºä»€ä¹ˆé”™ï¼Ÿ**
- RunnableParallel æ”¯æŒå¹¶è¡Œæ‰§è¡Œ
- RunnableBranch æ”¯æŒæ¡ä»¶åˆ†æ”¯
- å¯ä»¥ç»„åˆå‡ºå¤æ‚çš„æ‰§è¡Œæ‹“æ‰‘

**ä¸ºä»€ä¹ˆäººä»¬å®¹æ˜“è¿™æ ·é”™ï¼Ÿ**
"Chain"ï¼ˆé“¾ï¼‰è¿™ä¸ªè¯æš—ç¤ºçº¿æ€§ç»“æ„ï¼Œä½†å®é™…ä¸Š LCEL æ”¯æŒæ›´å¤æ‚çš„ç»„åˆã€‚

**æ­£ç¡®ç†è§£ï¼š**

```python
# ä¸åªæ˜¯é¡ºåº
# 1. å¹¶è¡Œæ‰§è¡Œ
parallel = RunnableParallel({
    "a": chain_a,
    "b": chain_b
})

# 2. æ¡ä»¶åˆ†æ”¯
branch = RunnableBranch(
    (condition1, chain1),
    (condition2, chain2),
    default_chain
)

# 3. å¤æ‚æ‹“æ‰‘
complex_chain = (
    {"context": retriever, "question": RunnablePassthrough()}
    | RunnableParallel({
        "answer": qa_chain,
        "summary": summary_chain
    })
)
```

---

### è¯¯åŒº2ï¼špipe æ“ä½œç¬¦åªæ˜¯è¯­æ³•ç³– âŒ

**ä¸ºä»€ä¹ˆé”™ï¼Ÿ**
- pipe ä¸ä»…æ˜¯è¯­æ³•ç³–ï¼Œè¿˜å®ç°äº†ï¼š
  - è‡ªåŠ¨ç±»å‹è½¬æ¢ï¼ˆdict â†’ RunnableParallelï¼Œfunction â†’ RunnableLambdaï¼‰
  - é…ç½®ä¼ é€’ï¼ˆcallbacks, tags, metadataï¼‰
  - æµå¼æ”¯æŒ
  - æ‰¹é‡æ‰§è¡Œä¼˜åŒ–

**ä¸ºä»€ä¹ˆäººä»¬å®¹æ˜“è¿™æ ·é”™ï¼Ÿ**
å› ä¸º `a | b` çœ‹èµ·æ¥å’Œ `RunnableSequence(a, b)` æ•ˆæœä¸€æ ·ã€‚

**æ­£ç¡®ç†è§£ï¼š**

```python
# pipe çš„éšè—èƒ½åŠ›

# 1. è‡ªåŠ¨ç±»å‹è½¬æ¢
chain = prompt | llm | (lambda x: x.content)
# lambda è‡ªåŠ¨è½¬æ¢ä¸º RunnableLambda

chain = {"a": step1} | step2
# dict è‡ªåŠ¨è½¬æ¢ä¸º RunnableParallel

# 2. é…ç½®è‡ªåŠ¨ä¼ é€’
result = chain.invoke(
    input,
    config={"callbacks": [handler]}  # ä¼ é€’ç»™æ‰€æœ‰æ­¥éª¤
)

# 3. æµå¼è‡ªåŠ¨ä¸²è”
for chunk in chain.stream(input):
    # æ¯ä¸ªæ­¥éª¤çš„æµå¼è¾“å‡ºè‡ªåŠ¨è¿æ¥
    print(chunk)
```

---

### è¯¯åŒº3ï¼šChain å’Œ Agent æ˜¯ä¸€æ ·çš„ âŒ

**ä¸ºä»€ä¹ˆé”™ï¼Ÿ**
- Chainï¼šç¡®å®šæ€§æ‰§è¡Œï¼Œæµç¨‹å›ºå®š
- Agentï¼šåŠ¨æ€å†³ç­–ï¼ŒLLM å†³å®šä¸‹ä¸€æ­¥

**ä¸ºä»€ä¹ˆäººä»¬å®¹æ˜“è¿™æ ·é”™ï¼Ÿ**
ä¸¤è€…éƒ½æ˜¯"å¤šæ­¥éª¤æ‰§è¡Œ"ï¼Œä½†æ‰§è¡Œé€»è¾‘å®Œå…¨ä¸åŒã€‚

**æ­£ç¡®ç†è§£ï¼š**

```python
# Chainï¼šæµç¨‹å›ºå®šï¼Œæ¯æ¬¡æ‰§è¡Œè·¯å¾„ç›¸åŒ
chain = prompt | llm | parser
# æ°¸è¿œæ˜¯ï¼šprompt â†’ llm â†’ parser

# Agentï¼šåŠ¨æ€å†³ç­–ï¼Œæ¯æ¬¡å¯èƒ½ä¸åŒ
# å¾ªç¯ï¼šLLMå†³å®š â†’ æ‰§è¡Œå·¥å…· â†’ è§‚å¯Ÿç»“æœ â†’ LLMå†³å®š â†’ ...
# å¯èƒ½è°ƒç”¨1ä¸ªå·¥å…·ï¼Œå¯èƒ½è°ƒç”¨10ä¸ªï¼Œç”± LLM å†³å®š

# é€‰æ‹©æ ‡å‡†
# å›ºå®šæµç¨‹ â†’ Chainï¼ˆå¯é¢„æµ‹ã€æ˜“è°ƒè¯•ï¼‰
# éœ€è¦å†³ç­– â†’ Agentï¼ˆçµæ´»ã€ä¸å¯é¢„æµ‹ï¼‰
```

| ç‰¹æ€§ | Chain | Agent |
|-----|-------|-------|
| æ‰§è¡Œè·¯å¾„ | å›ºå®š | åŠ¨æ€ |
| å¯é¢„æµ‹æ€§ | é«˜ | ä½ |
| è°ƒè¯•éš¾åº¦ | ä½ | é«˜ |
| é€‚ç”¨åœºæ™¯ | å›ºå®šæµç¨‹ | éœ€è¦å†³ç­– |
| æˆæœ¬æ§åˆ¶ | æ˜“ | éš¾ |

---

## 7. ã€å®æˆ˜ä»£ç ã€‘

```python
"""
ç¤ºä¾‹ï¼šChain é“¾å¼è°ƒç”¨å®Œæ•´æ¼”ç¤º
å±•ç¤º LangChain ä¸­ Chain çš„æ ¸å¿ƒç”¨æ³•
"""

from typing import Dict, List, Any
from dataclasses import dataclass

# ===== 1. æ¨¡æ‹Ÿ LangChain æ ¸å¿ƒç»„ä»¶ =====
print("=== 1. æ¨¡æ‹Ÿ Runnable åŸºç±» ===")

class Runnable:
    """Runnable åŸºç±»"""

    def invoke(self, input: Any) -> Any:
        raise NotImplementedError

    def __or__(self, other: "Runnable") -> "RunnableSequence":
        """å®ç° | æ“ä½œç¬¦"""
        return RunnableSequence([self, other])

    def __ror__(self, other) -> "RunnableSequence":
        """å®ç°åå‘ | æ“ä½œç¬¦"""
        if isinstance(other, dict):
            return RunnableSequence([RunnableParallel(other), self])
        return RunnableSequence([other, self])


class RunnableSequence(Runnable):
    """é¡ºåºæ‰§è¡Œ"""

    def __init__(self, steps: List[Runnable]):
        self.steps = steps

    def invoke(self, input: Any) -> Any:
        result = input
        for step in self.steps:
            result = step.invoke(result)
        return result

    def __or__(self, other: Runnable) -> "RunnableSequence":
        return RunnableSequence(self.steps + [other])


class RunnableLambda(Runnable):
    """åŒ…è£…æ™®é€šå‡½æ•°"""

    def __init__(self, func):
        self.func = func

    def invoke(self, input: Any) -> Any:
        return self.func(input)


class RunnableParallel(Runnable):
    """å¹¶è¡Œæ‰§è¡Œ"""

    def __init__(self, branches: Dict[str, Runnable]):
        self.branches = branches

    def invoke(self, input: Any) -> Dict[str, Any]:
        return {
            key: branch.invoke(input)
            for key, branch in self.branches.items()
        }


class RunnablePassthrough(Runnable):
    """ç›´æ¥ä¼ é€’"""

    def invoke(self, input: Any) -> Any:
        return input


# ===== 2. åŸºç¡€ Chain ç»„åˆ =====
print("\n=== 2. åŸºç¡€ Chain ç»„åˆ ===")

# æ¨¡æ‹Ÿ Prompt
class PromptTemplate(Runnable):
    def __init__(self, template: str):
        self.template = template

    def invoke(self, input: Dict[str, Any]) -> str:
        return self.template.format(**input)

# æ¨¡æ‹Ÿ LLM
class MockLLM(Runnable):
    def invoke(self, input: str) -> str:
        # ç®€å•æ¨¡æ‹Ÿ LLM å“åº”
        if "ç¿»è¯‘" in input:
            return "Translation: Hello World"
        return f"LLM Response to: {input[:50]}..."

# æ¨¡æ‹Ÿ Parser
class StrOutputParser(Runnable):
    def invoke(self, input: str) -> str:
        return input.strip()

# åˆ›å»ºç»„ä»¶
prompt = PromptTemplate("è¯·ç¿»è¯‘ä»¥ä¸‹å†…å®¹ï¼š{text}")
llm = MockLLM()
parser = StrOutputParser()

# ä½¿ç”¨ pipe ç»„åˆ
chain = prompt | llm | parser

# æ‰§è¡Œ
result = chain.invoke({"text": "ä½ å¥½ä¸–ç•Œ"})
print(f"åŸºç¡€ Chain ç»“æœ: {result}")

# ===== 3. å¹¶è¡Œæ‰§è¡Œ =====
print("\n=== 3. å¹¶è¡Œæ‰§è¡Œ ===")

# åˆ›å»ºä¸¤ä¸ªå¤„ç†åˆ†æ”¯
translate_chain = RunnableLambda(lambda x: f"ç¿»è¯‘: {x}")
summary_chain = RunnableLambda(lambda x: f"æ‘˜è¦: {x[:20]}...")

# å¹¶è¡Œæ‰§è¡Œ
parallel = RunnableParallel({
    "translation": translate_chain,
    "summary": summary_chain
})

result = parallel.invoke("è¿™æ˜¯ä¸€æ®µéœ€è¦å¤„ç†çš„ä¸­æ–‡æ–‡æœ¬å†…å®¹")
print(f"å¹¶è¡Œæ‰§è¡Œç»“æœ: {result}")

# ===== 4. RAG Chain æ¨¡å¼ =====
print("\n=== 4. RAG Chain æ¨¡å¼ ===")

# æ¨¡æ‹Ÿ Retriever
class MockRetriever(Runnable):
    def __init__(self, docs: List[str]):
        self.docs = docs

    def invoke(self, query: str) -> str:
        # ç®€å•è¿”å›æ‰€æœ‰æ–‡æ¡£
        return "\n".join(self.docs)

# åˆ›å»ºç»„ä»¶
retriever = MockRetriever([
    "LangChain æ˜¯ä¸€ä¸ª LLM åº”ç”¨æ¡†æ¶",
    "å®ƒæä¾›äº† Chainã€Agentã€Memory ç­‰ç»„ä»¶"
])

rag_prompt = PromptTemplate(
    "åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡å›ç­”é—®é¢˜:\n{context}\n\né—®é¢˜: {question}"
)

# æ„å»º RAG Chain
# æ³¨æ„ï¼šè¿™é‡Œç®€åŒ–äº†å®ç°ï¼Œå®é™… LangChain ä¸­ dict ä¼šè‡ªåŠ¨è½¬æ¢
context_and_question = RunnableParallel({
    "context": retriever,
    "question": RunnablePassthrough()
})

rag_chain = context_and_question | rag_prompt | llm | parser

result = rag_chain.invoke("ä»€ä¹ˆæ˜¯ LangChainï¼Ÿ")
print(f"RAG Chain ç»“æœ: {result}")

# ===== 5. å¤æ‚ Chain ç»„åˆ =====
print("\n=== 5. å¤æ‚ Chain ç»„åˆ ===")

# å®šä¹‰å¤šä¸ªå¤„ç†æ­¥éª¤
step1 = RunnableLambda(lambda x: x.strip())
step2 = RunnableLambda(lambda x: x.lower())
step3 = RunnableLambda(lambda x: x.replace(" ", "_"))
step4 = RunnableLambda(lambda x: f"processed_{x}")

# ç»„åˆæˆå¤æ‚ Chain
processing_chain = step1 | step2 | step3 | step4

result = processing_chain.invoke("  Hello World  ")
print(f"å¤æ‚å¤„ç†ç»“æœ: {result}")

# ===== 6. æ•°æ®æµè¿½è¸ª =====
print("\n=== 6. æ•°æ®æµè¿½è¸ª ===")

class TracingRunnable(Runnable):
    """å¸¦è¿½è¸ªçš„ Runnable"""

    def __init__(self, name: str, func):
        self.name = name
        self.func = func

    def invoke(self, input: Any) -> Any:
        print(f"  [{self.name}] è¾“å…¥: {input}")
        result = self.func(input)
        print(f"  [{self.name}] è¾“å‡º: {result}")
        return result

# åˆ›å»ºå¸¦è¿½è¸ªçš„ Chain
traced_chain = (
    TracingRunnable("Step1", lambda x: x + 10) |
    TracingRunnable("Step2", lambda x: x * 2) |
    TracingRunnable("Step3", lambda x: x - 5)
)

print("æ‰§è¡Œè¿½è¸ª:")
result = traced_chain.invoke(5)
print(f"æœ€ç»ˆç»“æœ: {result}")  # (5 + 10) * 2 - 5 = 25

# ===== 7. æ¡ä»¶åˆ†æ”¯æ¨¡æ‹Ÿ =====
print("\n=== 7. æ¡ä»¶åˆ†æ”¯ ===")

class RunnableBranch(Runnable):
    """æ¡ä»¶åˆ†æ”¯"""

    def __init__(self, branches, default):
        self.branches = branches  # [(condition, runnable), ...]
        self.default = default

    def invoke(self, input: Any) -> Any:
        for condition, runnable in self.branches:
            if condition(input):
                return runnable.invoke(input)
        return self.default.invoke(input)

# åˆ›å»ºåˆ†æ”¯
branch = RunnableBranch(
    branches=[
        (lambda x: x.get("type") == "translate",
         RunnableLambda(lambda x: f"ç¿»è¯‘: {x['text']}")),
        (lambda x: x.get("type") == "summary",
         RunnableLambda(lambda x: f"æ‘˜è¦: {x['text'][:10]}...")),
    ],
    default=RunnableLambda(lambda x: f"é»˜è®¤å¤„ç†: {x['text']}")
)

# æµ‹è¯•ä¸åŒåˆ†æ”¯
print(branch.invoke({"type": "translate", "text": "Hello"}))
print(branch.invoke({"type": "summary", "text": "This is a long text"}))
print(branch.invoke({"type": "other", "text": "Unknown type"}))

# ===== 8. æ‰¹é‡æ‰§è¡Œæ¨¡æ‹Ÿ =====
print("\n=== 8. æ‰¹é‡æ‰§è¡Œ ===")

class BatchableRunnable(Runnable):
    """æ”¯æŒæ‰¹é‡æ‰§è¡Œçš„ Runnable"""

    def __init__(self, func):
        self.func = func

    def invoke(self, input: Any) -> Any:
        return self.func(input)

    def batch(self, inputs: List[Any]) -> List[Any]:
        return [self.invoke(input) for input in inputs]

# åˆ›å»º Chain
batch_chain = BatchableRunnable(lambda x: x * 2)

# æ‰¹é‡æ‰§è¡Œ
inputs = [1, 2, 3, 4, 5]
results = batch_chain.batch(inputs)
print(f"æ‰¹é‡æ‰§è¡Œç»“æœ: {results}")

# ===== 9. å®é™… LangChain é£æ ¼çš„å®Œæ•´ç¤ºä¾‹ =====
print("\n=== 9. å®Œæ•´ RAG ç¤ºä¾‹ ===")

# æ¨¡æ‹Ÿå®Œæ•´çš„ RAG åœºæ™¯
documents = [
    "Python æ˜¯ä¸€ç§è§£é‡Šå‹ç¼–ç¨‹è¯­è¨€",
    "LangChain ä½¿ç”¨ Python å¼€å‘",
    "LCEL æ˜¯ LangChain Expression Language"
]

class SimpleRAG:
    """ç®€å•çš„ RAG å®ç°"""

    def __init__(self, docs: List[str]):
        self.docs = docs

    def retrieve(self, query: str) -> List[str]:
        """ç®€å•çš„å…³é”®è¯åŒ¹é…æ£€ç´¢"""
        results = []
        query_words = query.lower().split()
        for doc in self.docs:
            if any(word in doc.lower() for word in query_words):
                results.append(doc)
        return results if results else self.docs[:1]

    def generate(self, context: str, question: str) -> str:
        """ç”Ÿæˆå›ç­”ï¼ˆæ¨¡æ‹Ÿï¼‰"""
        return f"æ ¹æ®ä¸Šä¸‹æ–‡ '{context[:30]}...'ï¼Œå›ç­”é—®é¢˜ '{question}' çš„ç­”æ¡ˆæ˜¯ï¼šè¿™æ˜¯ä¸€ä¸ªæ¨¡æ‹Ÿå›ç­”ã€‚"

    def query(self, question: str) -> str:
        """å®Œæ•´çš„ RAG æµç¨‹"""
        # 1. æ£€ç´¢
        relevant_docs = self.retrieve(question)
        context = "\n".join(relevant_docs)

        # 2. ç”Ÿæˆ
        answer = self.generate(context, question)

        return answer

rag = SimpleRAG(documents)
answer = rag.query("ä»€ä¹ˆæ˜¯ LangChainï¼Ÿ")
print(f"RAG å›ç­”: {answer}")

print("\n=== å®Œæˆï¼===")
```

**è¿è¡Œè¾“å‡ºç¤ºä¾‹ï¼š**
```
=== 1. æ¨¡æ‹Ÿ Runnable åŸºç±» ===

=== 2. åŸºç¡€ Chain ç»„åˆ ===
åŸºç¡€ Chain ç»“æœ: Translation: Hello World

=== 3. å¹¶è¡Œæ‰§è¡Œ ===
å¹¶è¡Œæ‰§è¡Œç»“æœ: {'translation': 'ç¿»è¯‘: è¿™æ˜¯ä¸€æ®µéœ€è¦å¤„ç†çš„ä¸­æ–‡æ–‡æœ¬å†…å®¹', 'summary': 'æ‘˜è¦: è¿™æ˜¯ä¸€æ®µéœ€è¦å¤„ç†çš„ä¸­æ–‡æ–‡æœ¬å†…å®¹...'}

=== 4. RAG Chain æ¨¡å¼ ===
RAG Chain ç»“æœ: LLM Response to: åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡å›ç­”é—®é¢˜:
LangChain æ˜¯ä¸€ä¸ª LLM åº”ç”¨æ¡†...

=== 5. å¤æ‚ Chain ç»„åˆ ===
å¤æ‚å¤„ç†ç»“æœ: processed_hello_world

=== 6. æ•°æ®æµè¿½è¸ª ===
æ‰§è¡Œè¿½è¸ª:
  [Step1] è¾“å…¥: 5
  [Step1] è¾“å‡º: 15
  [Step2] è¾“å…¥: 15
  [Step2] è¾“å‡º: 30
  [Step3] è¾“å…¥: 30
  [Step3] è¾“å‡º: 25
æœ€ç»ˆç»“æœ: 25

=== 7. æ¡ä»¶åˆ†æ”¯ ===
ç¿»è¯‘: Hello
æ‘˜è¦: This is a ...
é»˜è®¤å¤„ç†: Unknown type

=== 8. æ‰¹é‡æ‰§è¡Œ ===
æ‰¹é‡æ‰§è¡Œç»“æœ: [2, 4, 6, 8, 10]

=== 9. å®Œæ•´ RAG ç¤ºä¾‹ ===
RAG å›ç­”: æ ¹æ®ä¸Šä¸‹æ–‡ 'LangChain ä½¿ç”¨ Python å¼€å‘...'ï¼Œå›ç­”é—®é¢˜ 'ä»€ä¹ˆæ˜¯ LangChainï¼Ÿ' çš„ç­”æ¡ˆæ˜¯ï¼šè¿™æ˜¯ä¸€ä¸ªæ¨¡æ‹Ÿå›ç­”ã€‚

=== å®Œæˆï¼===
```

---

## 8. ã€é¢è¯•å¿…é—®ã€‘

### é—®é¢˜1ï¼š"ä»€ä¹ˆæ˜¯ LCELï¼Ÿå®ƒå’Œä¼ ç»Ÿçš„ Chain æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ"

**æ™®é€šå›ç­”ï¼ˆâŒ ä¸å‡ºå½©ï¼‰ï¼š**
"LCEL æ˜¯ LangChain Expression Languageï¼Œç”¨ | æ“ä½œç¬¦è¿æ¥ç»„ä»¶ã€‚"

**å‡ºå½©å›ç­”ï¼ˆâœ… æ¨èï¼‰ï¼š**

> **LCEL (LangChain Expression Language) æ˜¯ LangChain 0.1+ ç‰ˆæœ¬å¼•å…¥çš„å£°æ˜å¼ Chain æ„å»ºæ–¹å¼ï¼š**
>
> **1. è¯­æ³•å±‚é¢**
> ```python
> # ä¼ ç»Ÿ Chain
> chain = LLMChain(llm=llm, prompt=prompt, output_parser=parser)
>
> # LCEL
> chain = prompt | llm | parser
> ```
>
> **2. æ ¸å¿ƒä¼˜åŠ¿**
> - **ç»Ÿä¸€æ¥å£**ï¼šæ‰€æœ‰ç»„ä»¶å®ç° Runnable æ¥å£ï¼Œæ”¯æŒ invoke/stream/batch
> - **ç±»å‹å®‰å…¨**ï¼šè‡ªåŠ¨æ¨æ–­è¾“å…¥è¾“å‡ºç±»å‹
> - **é…ç½®ä¼ é€’**ï¼šcallbacksã€tags ç­‰è‡ªåŠ¨æµè½¬
> - **æµå¼åŸç”Ÿ**ï¼šå¤©ç„¶æ”¯æŒæµå¼è¾“å‡º
>
> **3. æ¶æ„å·®å¼‚**
> - ä¼ ç»Ÿ Chainï¼šç»§æ‰¿å¼ï¼Œæ¯ç§ Chain æ˜¯ç‹¬ç«‹ç±»
> - LCELï¼šç»„åˆå¼ï¼Œé€šè¿‡ pipe ç»„åˆ Runnable
>
> **4. å®é™…ä½“éªŒ**
> åœ¨æˆ‘çš„é¡¹ç›®ä¸­ï¼Œç”¨ LCEL é‡æ„åä»£ç é‡å‡å°‘ 40%ï¼Œè°ƒè¯•æ›´ç›´è§‚ï¼Œå› ä¸ºæ¯ä¸ªæ­¥éª¤éƒ½æ˜¯ç‹¬ç«‹çš„ Runnableã€‚

**ä¸ºä»€ä¹ˆè¿™ä¸ªå›ç­”å‡ºå½©ï¼Ÿ**
1. âœ… å±•ç¤ºäº†æ–°æ—§ä¸¤ç§å†™æ³•çš„å¯¹æ¯”
2. âœ… æ€»ç»“äº†æ ¸å¿ƒä¼˜åŠ¿
3. âœ… è§£é‡Šäº†æ¶æ„å±‚é¢çš„å·®å¼‚
4. âœ… æœ‰å®é™…é¡¹ç›®ç»éªŒ

---

### é—®é¢˜2ï¼š"å¦‚ä½•é€‰æ‹© Chain å’Œ Agentï¼Ÿ"

**æ™®é€šå›ç­”ï¼ˆâŒ ä¸å‡ºå½©ï¼‰ï¼š**
"ç®€å•ä»»åŠ¡ç”¨ Chainï¼Œå¤æ‚ä»»åŠ¡ç”¨ Agentã€‚"

**å‡ºå½©å›ç­”ï¼ˆâœ… æ¨èï¼‰ï¼š**

> **é€‰æ‹©ä¾æ®æ˜¯ã€Œæµç¨‹æ˜¯å¦ç¡®å®šã€ï¼š**
>
> **ä½¿ç”¨ Chain çš„åœºæ™¯ï¼š**
> - æµç¨‹å›ºå®šï¼šç¿»è¯‘ã€æ‘˜è¦ã€æ ¼å¼è½¬æ¢
> - éœ€è¦å¯é¢„æµ‹æ€§ï¼šç”Ÿäº§ç¯å¢ƒã€æˆæœ¬æ•æ„Ÿ
> - æ˜“äºè°ƒè¯•ï¼šæ¯ä¸ªæ­¥éª¤è¾“å…¥è¾“å‡ºæ˜ç¡®
>
> ```python
> # Chainï¼šå›ºå®šæµç¨‹
> chain = prompt | llm | parser  # æ°¸è¿œè¿™ä¸‰æ­¥
> ```
>
> **ä½¿ç”¨ Agent çš„åœºæ™¯ï¼š**
> - éœ€è¦åŠ¨æ€å†³ç­–ï¼šæ™ºèƒ½åŠ©æ‰‹ã€ç ”ç©¶ä»»åŠ¡
> - å·¥å…·é€‰æ‹©ä¸ç¡®å®šï¼šå¯èƒ½ç”¨æœç´¢ï¼Œå¯èƒ½ç”¨è®¡ç®—å™¨
> - ä»»åŠ¡å¤æ‚åº¦æœªçŸ¥ï¼šå¯èƒ½ä¸€æ­¥å®Œæˆï¼Œå¯èƒ½åæ­¥
>
> ```python
> # Agentï¼šåŠ¨æ€å†³ç­–
> # LLM å†³å®šï¼šè¦ä¸è¦ç”¨å·¥å…·ï¼Ÿç”¨å“ªä¸ªï¼Ÿä»€ä¹ˆæ—¶å€™ç»“æŸï¼Ÿ
> ```
>
> **æˆ‘çš„ç»éªŒæ³•åˆ™ï¼š**
> 1. å¦‚æœä½ èƒ½ç”»å‡ºç¡®å®šçš„æµç¨‹å›¾ â†’ Chain
> 2. å¦‚æœæµç¨‹å›¾æœ‰"æ ¹æ®æƒ…å†µå†³å®š" â†’ Agent
> 3. ä¸ç¡®å®šæ—¶å…ˆç”¨ Chainï¼Œé‡åˆ°ç“¶é¢ˆå†è€ƒè™‘ Agent
>
> **æˆæœ¬è€ƒè™‘ï¼š**
> Agent çš„ LLM è°ƒç”¨æ¬¡æ•°ä¸ç¡®å®šï¼Œç”Ÿäº§ç¯å¢ƒè¦è®¾ç½® max_iterations å’Œè¶…æ—¶ã€‚

---

## 9. ã€åŒ–éª¨ç»µæŒã€‘

### å¡ç‰‡1ï¼šChain æ˜¯ä»€ä¹ˆï¼Ÿ ğŸ¯

**ä¸€å¥è¯ï¼š** Chain æ˜¯å¤šä¸ªå¤„ç†æ­¥éª¤çš„æœ‰åºç»„åˆï¼Œè¾“å…¥ä¾æ¬¡æµç»æ¯ä¸ªæ­¥éª¤ã€‚

**ä¸¾ä¾‹ï¼š**
```python
chain = prompt | llm | parser
# è¾“å…¥ â†’ prompt â†’ llm â†’ parser â†’ è¾“å‡º
```

**åº”ç”¨ï¼š** LangChain ä¸­æ„å»º LLM åº”ç”¨çš„æ ¸å¿ƒæ¨¡å¼ã€‚

---

### å¡ç‰‡2ï¼šLCEL æ˜¯ä»€ä¹ˆï¼Ÿ ğŸ“

**ä¸€å¥è¯ï¼š** LCEL (LangChain Expression Language) æ˜¯ç”¨ `|` æ“ä½œç¬¦å£°æ˜å¼æ„å»º Chain çš„è¯­æ³•ã€‚

**ä¸¾ä¾‹ï¼š**
```python
# ç”¨ | è¿æ¥ç»„ä»¶
chain = component1 | component2 | component3
```

**åº”ç”¨ï¼š** LangChain 0.1+ ç‰ˆæœ¬çš„æ ‡å‡†å†™æ³•ã€‚

---

### å¡ç‰‡3ï¼špipe æ“ä½œç¬¦ | ğŸ“

**ä¸€å¥è¯ï¼š** `|` é€šè¿‡ Python çš„ `__or__` é­”æ³•æ–¹æ³•å®ç°ï¼Œåˆ›å»º RunnableSequenceã€‚

**ä¸¾ä¾‹ï¼š**
```python
a | b  # ç­‰ä»·äº RunnableSequence([a, b])
```

**åº”ç”¨ï¼š** è®© Chain ç»„åˆåƒ Unix ç®¡é“ä¸€æ ·ç›´è§‚ã€‚

---

### å¡ç‰‡4ï¼šRunnableSequence é¡ºåºæ‰§è¡Œ ğŸ”—

**ä¸€å¥è¯ï¼š** å¤šä¸ª Runnable æŒ‰é¡ºåºæ‰§è¡Œï¼Œå‰ä¸€ä¸ªçš„è¾“å‡ºæ˜¯åä¸€ä¸ªçš„è¾“å…¥ã€‚

**ä¸¾ä¾‹ï¼š**
```python
chain = step1 | step2 | step3
result = chain.invoke(input)
# step1(input) â†’ step2 â†’ step3 â†’ result
```

**åº”ç”¨ï¼š** Prompt â†’ LLM â†’ Parser çš„å…¸å‹æ¨¡å¼ã€‚

---

### å¡ç‰‡5ï¼šRunnableParallel å¹¶è¡Œæ‰§è¡Œ ğŸ”€

**ä¸€å¥è¯ï¼š** å¤šä¸ª Runnable åŒæ—¶æ‰§è¡Œï¼Œç»“æœåˆå¹¶ä¸ºå­—å…¸ã€‚

**ä¸¾ä¾‹ï¼š**
```python
parallel = RunnableParallel({
    "a": chain_a,
    "b": chain_b
})
# result = {"a": ..., "b": ...}
```

**åº”ç”¨ï¼š** åŒæ—¶æ‰§è¡Œç¿»è¯‘å’Œæ‘˜è¦ï¼Œæé«˜æ•ˆç‡ã€‚

---

### å¡ç‰‡6ï¼šRunnablePassthrough é€ä¼  â¡ï¸

**ä¸€å¥è¯ï¼š** ç›´æ¥ä¼ é€’è¾“å…¥ä¸åšä¿®æ”¹ï¼Œå¸¸ç”¨äºå¹¶è¡Œæ—¶ä¿ç•™åŸå§‹æ•°æ®ã€‚

**ä¸¾ä¾‹ï¼š**
```python
chain = {"context": retriever, "question": RunnablePassthrough()}
# é—®é¢˜åŸæ ·ä¼ é€’ï¼ŒåŒæ—¶æ£€ç´¢ä¸Šä¸‹æ–‡
```

**åº”ç”¨ï¼š** RAG Chain ä¸­ä¿ç•™åŸå§‹é—®é¢˜ã€‚

---

### å¡ç‰‡7ï¼šRunnableLambda å‡½æ•°åŒ…è£… Î»

**ä¸€å¥è¯ï¼š** å°†æ™®é€š Python å‡½æ•°åŒ…è£…ä¸º Runnableã€‚

**ä¸¾ä¾‹ï¼š**
```python
step = RunnableLambda(lambda x: x.upper())
# æˆ–ç›´æ¥åœ¨ Chain ä¸­ä½¿ç”¨
chain = prompt | llm | (lambda x: x.content)
```

**åº”ç”¨ï¼š** åœ¨ Chain ä¸­æ’å…¥è‡ªå®šä¹‰å¤„ç†é€»è¾‘ã€‚

---

### å¡ç‰‡8ï¼šRAG Chain æ¨¡æ¿ ğŸ“š

**ä¸€å¥è¯ï¼š** æ£€ç´¢å¢å¼ºç”Ÿæˆçš„æ ‡å‡† Chain æ¨¡å¼ï¼šæ£€ç´¢ + é—®é¢˜ â†’ ç”Ÿæˆã€‚

**ä¸¾ä¾‹ï¼š**
```python
rag_chain = (
    {"context": retriever, "question": RunnablePassthrough()}
    | prompt
    | llm
    | StrOutputParser()
)
```

**åº”ç”¨ï¼š** çŸ¥è¯†åº“é—®ç­”ç³»ç»Ÿçš„æ ¸å¿ƒæ¨¡å¼ã€‚

---

### å¡ç‰‡9ï¼šChain vs Agent âš–ï¸

**ä¸€å¥è¯ï¼š** Chain æ˜¯ç¡®å®šæ€§æµæ°´çº¿ï¼ŒAgent æ˜¯åŠ¨æ€å†³ç­–å¾ªç¯ã€‚

**ä¸¾ä¾‹ï¼š**
```python
# Chainï¼šå›ºå®šè·¯å¾„
chain = prompt | llm | parser

# Agentï¼šLLM å†³å®šè·¯å¾„
# è§‚å¯Ÿ â†’ å†³ç­– â†’ è¡ŒåŠ¨ â†’ è§‚å¯Ÿ â†’ ...
```

**åº”ç”¨ï¼š** å›ºå®šæµç¨‹ç”¨ Chainï¼Œéœ€è¦å†³ç­–ç”¨ Agentã€‚

---

### å¡ç‰‡10ï¼šChain åœ¨ LangChain æºç ä¸­çš„ä½ç½® â­

**ä¸€å¥è¯ï¼š** Chain åŸºäº Runnable åè®®ï¼Œæ˜¯ LCEL çš„æ ¸å¿ƒå®ç°ã€‚

**ä¸¾ä¾‹ï¼š**
```python
# langchain_core/runnables/base.py
class RunnableSequence(Runnable):
    def invoke(self, input, config=None):
        for step in self.steps:
            input = step.invoke(input, config)
        return input
```

**åº”ç”¨ï¼š** ç†è§£ Chain å°±ç†è§£äº† LCEL çš„æ‰§è¡Œæœºåˆ¶ã€‚

---

## 10. ã€ä¸€å¥è¯æ€»ç»“ã€‘

**Chain æ˜¯ LangChain ä¸­å°†å¤šä¸ªç»„ä»¶ä¸²è”æˆæµæ°´çº¿çš„æ ¸å¿ƒæœºåˆ¶ï¼Œé€šè¿‡ LCEL çš„ pipe(|) æ“ä½œç¬¦å®ç°å£°æ˜å¼ç»„åˆï¼Œæ”¯æŒé¡ºåºæ‰§è¡Œã€å¹¶è¡Œæ‰§è¡Œå’Œæ¡ä»¶åˆ†æ”¯ï¼Œæ˜¯æ„å»º LLM åº”ç”¨çš„åŸºç¡€æ¨¡å¼ã€‚**

---

## ğŸ“š å­¦ä¹ æ£€æŸ¥æ¸…å•

- [ ] ç†è§£ Chain çš„æœ¬è´¨æ˜¯å¤šæ­¥éª¤çš„æœ‰åºç»„åˆ
- [ ] ä¼šä½¿ç”¨ `|` æ“ä½œç¬¦ç»„åˆ Runnable
- [ ] ç†è§£ RunnableSequence å’Œ RunnableParallel çš„åŒºåˆ«
- [ ] èƒ½å¤Ÿæ„å»º RAG Chain æ¨¡æ¿
- [ ] çŸ¥é“ä½•æ—¶é€‰æ‹© Chain vs Agent
- [ ] äº†è§£ LCEL ç›¸æ¯”ä¼ ç»Ÿ Chain çš„ä¼˜åŠ¿

## ğŸ”— ä¸‹ä¸€æ­¥å­¦ä¹ 

- **Agent ä»£ç†æ¨¡å¼**ï¼šåŠ¨æ€å†³ç­–çš„ LLM åº”ç”¨
- **Runnable åè®®**ï¼šLCEL çš„åº•å±‚å®ç°
- **æµå¼è¾“å‡º**ï¼šChain çš„ stream æ–¹æ³•æ·±å…¥

---

**ç‰ˆæœ¬ï¼š** v1.0
**æœ€åæ›´æ–°ï¼š** 2025-01-14
