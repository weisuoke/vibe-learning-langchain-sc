# ä¾èµ–æ³¨å…¥åŸç† (Dependency Injection)

> åŸå­åŒ–çŸ¥è¯†ç‚¹ | è½¯ä»¶å·¥ç¨‹åŸºç¡€ | LangChain æºç å­¦ä¹ å‰ç½®çŸ¥è¯†

---

## 1. ã€30å­—æ ¸å¿ƒã€‘

**ä¾èµ–æ³¨å…¥æ˜¯å°†å¯¹è±¡çš„ä¾èµ–ä»å†…éƒ¨åˆ›å»ºæ”¹ä¸ºå¤–éƒ¨ä¼ å…¥ï¼Œå®ç°ç»„ä»¶é—´æ¾è€¦åˆï¼Œæ˜¯ LangChain Chain ç»„åˆ LLMã€Retrieverã€Memory çš„æ ¸å¿ƒæœºåˆ¶ã€‚**

---

## 2. ã€ç¬¬ä¸€æ€§åŸç†ã€‘

### ä»€ä¹ˆæ˜¯ç¬¬ä¸€æ€§åŸç†ï¼Ÿ

**ç¬¬ä¸€æ€§åŸç†**ï¼šå›åˆ°äº‹ç‰©æœ€åŸºæœ¬çš„çœŸç†ï¼Œä»æºå¤´æ€è€ƒé—®é¢˜

### ä¾èµ–æ³¨å…¥çš„ç¬¬ä¸€æ€§åŸç† ğŸ¯

#### 1. æœ€åŸºç¡€çš„å®šä¹‰

**ä¾èµ–æ³¨å…¥ = ä¸è‡ªå·±åˆ›å»ºä¾èµ– + ä»å¤–éƒ¨æ¥æ”¶ä¾èµ–**

ä»…æ­¤è€Œå·²ï¼æ²¡æœ‰æ›´åŸºç¡€çš„äº†ã€‚

- **ä¾èµ–**ï¼šä¸€ä¸ªå¯¹è±¡éœ€è¦ä½¿ç”¨çš„å…¶ä»–å¯¹è±¡
- **æ³¨å…¥**ï¼šä»å¤–éƒ¨ä¼ å…¥è€Œä¸æ˜¯å†…éƒ¨åˆ›å»º
- **æ§åˆ¶åè½¬**ï¼šç”±å¤–éƒ¨å†³å®šä½¿ç”¨å“ªä¸ªå®ç°

#### 2. ä¸ºä»€ä¹ˆéœ€è¦ä¾èµ–æ³¨å…¥ï¼Ÿ

**æ ¸å¿ƒé—®é¢˜ï¼šå¦‚ä½•è®©ç»„ä»¶ä¹‹é—´çš„ä¾èµ–å…³ç³»å˜å¾—çµæ´»å¯é…ç½®ï¼Ÿ**

```python
# æ²¡æœ‰ä¾èµ–æ³¨å…¥ï¼šç¡¬ç¼–ç ä¾èµ–ï¼Œç´§è€¦åˆ
class QAChain:
    def __init__(self):
        # å†…éƒ¨åˆ›å»ºä¾èµ– - é—®é¢˜ï¼
        self.llm = ChatOpenAI(model="gpt-4")           # ç¡¬ç¼–ç  OpenAI
        self.retriever = ChromaRetriever()             # ç¡¬ç¼–ç  Chroma
        self.memory = ConversationBufferMemory()       # ç¡¬ç¼–ç  Memory

    def run(self, question: str) -> str:
        context = self.retriever.retrieve(question)
        history = self.memory.get_history()
        response = self.llm.invoke(f"{history}\n{context}\n{question}")
        self.memory.save(question, response)
        return response

# é—®é¢˜ï¼š
# 1. æƒ³æ¢æˆ Anthropicï¼Ÿè¦æ”¹ QAChain ä»£ç 
# 2. æƒ³ç”¨ Pinecone æ›¿ä»£ Chromaï¼Ÿè¦æ”¹ QAChain ä»£ç 
# 3. æµ‹è¯•æ—¶æƒ³ç”¨ Mockï¼Ÿè¦æ”¹ QAChain ä»£ç 
# 4. ä¸åŒåœºæ™¯ç”¨ä¸åŒé…ç½®ï¼Ÿè¦åˆ›å»ºå¤šä¸ª QAChain ç±»
```

```python
# ä½¿ç”¨ä¾èµ–æ³¨å…¥ï¼šå¤–éƒ¨ä¼ å…¥ä¾èµ–ï¼Œæ¾è€¦åˆ
from abc import ABC, abstractmethod

class BaseLLM(ABC):
    @abstractmethod
    def invoke(self, input: str) -> str: pass

class BaseRetriever(ABC):
    @abstractmethod
    def retrieve(self, query: str) -> str: pass

class BaseMemory(ABC):
    @abstractmethod
    def get_history(self) -> str: pass
    @abstractmethod
    def save(self, q: str, a: str): pass

class QAChain:
    def __init__(self,
                 llm: BaseLLM,              # ä¾èµ–æ³¨å…¥ï¼
                 retriever: BaseRetriever,   # ä¾èµ–æ³¨å…¥ï¼
                 memory: BaseMemory):        # ä¾èµ–æ³¨å…¥ï¼
        self.llm = llm
        self.retriever = retriever
        self.memory = memory

    def run(self, question: str) -> str:
        context = self.retriever.retrieve(question)
        history = self.memory.get_history()
        response = self.llm.invoke(f"{history}\n{context}\n{question}")
        self.memory.save(question, response)
        return response

# ä½¿ç”¨ï¼šåœ¨å¤–éƒ¨å†³å®šç”¨ä»€ä¹ˆå®ç°
chain = QAChain(
    llm=ChatOpenAI(model="gpt-4"),        # å¯ä»¥æ¢æˆä»»ä½• LLM
    retriever=ChromaRetriever(),          # å¯ä»¥æ¢æˆä»»ä½• Retriever
    memory=ConversationBufferMemory()     # å¯ä»¥æ¢æˆä»»ä½• Memory
)

# æ¢æˆ Anthropicï¼Ÿåªéœ€è¦ï¼š
chain = QAChain(
    llm=ChatAnthropic(model="claude-3"),  # æ¢ï¼
    retriever=ChromaRetriever(),
    memory=ConversationBufferMemory()
)

# æµ‹è¯•æ—¶ç”¨ Mockï¼Ÿåªéœ€è¦ï¼š
chain = QAChain(
    llm=MockLLM(),                        # Mockï¼
    retriever=MockRetriever(),
    memory=MockMemory()
)
```

#### 3. ä¾èµ–æ³¨å…¥çš„ä¸‰å±‚ä»·å€¼

##### ä»·å€¼1ï¼šè§£è€¦ - ç»„ä»¶ä¸ä¾èµ–å…·ä½“å®ç°

```python
class QAChain:
    def __init__(self, llm: BaseLLM):  # ä¾èµ–æŠ½è±¡æ¥å£
        self.llm = llm

# QAChain ä¸çŸ¥é“ï¼ˆä¹Ÿä¸å…³å¿ƒï¼‰llm æ˜¯ OpenAI è¿˜æ˜¯ Anthropic
# å®ƒåªçŸ¥é“ llm æœ‰ invoke() æ–¹æ³•
```

##### ä»·å€¼2ï¼šå¯æµ‹è¯• - è½»æ¾ä½¿ç”¨ Mock

```python
class MockLLM(BaseLLM):
    def invoke(self, input: str) -> str:
        return "Mock response"

# æµ‹è¯•æ—¶æ³¨å…¥ Mock
def test_qa_chain():
    chain = QAChain(llm=MockLLM())
    result = chain.run("test question")
    assert result == "Mock response"
```

##### ä»·å€¼3ï¼šå¯é…ç½® - è¿è¡Œæ—¶åˆ‡æ¢å®ç°

```python
# æ ¹æ®é…ç½®é€‰æ‹©ä¸åŒå®ç°
config = load_config()

if config.provider == "openai":
    llm = ChatOpenAI()
elif config.provider == "anthropic":
    llm = ChatAnthropic()
else:
    llm = LocalLLM()

chain = QAChain(llm=llm)  # è¿è¡Œæ—¶å†³å®š
```

#### 4. ä»ç¬¬ä¸€æ€§åŸç†æ¨å¯¼ LangChain æºç åº”ç”¨

**æ¨ç†é“¾ï¼š**

```
1. LangChain éœ€è¦æ”¯æŒå¤šç§ LLMã€å¤šç§å‘é‡æ•°æ®åº“ã€å¤šç§ Memory
   â†“
2. å¦‚æœ Chain å†…éƒ¨ç¡¬ç¼–ç è¿™äº›ä¾èµ–ï¼Œæ¯æ¢ä¸€ä¸ªå°±è¦æ”¹ Chain ä»£ç 
   â†“
3. éœ€è¦è®© Chain ä¸ä¾èµ–å…·ä½“å®ç°ï¼Œåªä¾èµ–æŠ½è±¡æ¥å£
   â†“
4. ä¾èµ–æ³¨å…¥å®Œç¾åŒ¹é…ï¼šChain æ¥æ”¶ä¾èµ–ï¼Œä¸åˆ›å»ºä¾èµ–
   â†“
5. LangChain è®¾è®¡äº† BaseChatModelã€BaseRetrieverã€BaseMemory ç­‰æŠ½è±¡
   â†“
6. Chain çš„æ„é€ å‡½æ•°æ¥æ”¶è¿™äº›æŠ½è±¡ç±»å‹
   â†“
7. ç”¨æˆ·åœ¨åˆ›å»º Chain æ—¶ä¼ å…¥å…·ä½“å®ç°
   â†“
8. LCEL çš„ `|` æ“ä½œç¬¦æœ¬è´¨ä¸Šä¹Ÿæ˜¯ä¾èµ–ç»„åˆ
   â†“
9. å®ç°äº†ï¼šæ ¸å¿ƒé€»è¾‘ä¸å˜ï¼Œä¾èµ–å¯æ’æ‹”
```

#### 5. ä¸€å¥è¯æ€»ç»“ç¬¬ä¸€æ€§åŸç†

**ä¾èµ–æ³¨å…¥é€šè¿‡"å¤–éƒ¨ä¼ å…¥ä¾èµ–"æ›¿ä»£"å†…éƒ¨åˆ›å»ºä¾èµ–"ï¼Œè®©ç»„ä»¶åªä¾èµ–æŠ½è±¡æ¥å£è€Œéå…·ä½“å®ç°ï¼Œæ˜¯ LangChain èƒ½å¤Ÿçµæ´»ç»„åˆä¸åŒ LLMã€Retrieverã€Memory çš„æ¶æ„åŸºç¡€ã€‚**

---

## 3. ã€æ ¸å¿ƒæ¦‚å¿µï¼ˆå…¨é¢è¦†ç›–ï¼‰ã€‘

### æ ¸å¿ƒæ¦‚å¿µ1ï¼šæ„é€ å‡½æ•°æ³¨å…¥ ğŸ—ï¸

**æœ€å¸¸ç”¨çš„ä¾èµ–æ³¨å…¥æ–¹å¼ï¼Œé€šè¿‡æ„é€ å‡½æ•°å‚æ•°ä¼ å…¥ä¾èµ–**

```python
from abc import ABC, abstractmethod
from typing import Optional, List, Dict, Any

# ===== ä¾èµ–æ¥å£å®šä¹‰ =====

class BaseLLM(ABC):
    """LLM æŠ½è±¡æ¥å£"""

    @abstractmethod
    def invoke(self, input: str) -> str:
        pass

class BaseRetriever(ABC):
    """æ£€ç´¢å™¨æŠ½è±¡æ¥å£"""

    @abstractmethod
    def retrieve(self, query: str) -> List[str]:
        pass

class BaseMemory(ABC):
    """è®°å¿†æŠ½è±¡æ¥å£"""

    @abstractmethod
    def load(self) -> str:
        pass

    @abstractmethod
    def save(self, input: str, output: str):
        pass

# ===== ä½¿ç”¨æ„é€ å‡½æ•°æ³¨å…¥ =====

class ConversationalRetrievalChain:
    """
    å¯¹è¯æ£€ç´¢é“¾ - å±•ç¤ºæ„é€ å‡½æ•°æ³¨å…¥

    ç±»ä¼¼ LangChain çš„ ConversationalRetrievalChain
    """

    def __init__(
        self,
        llm: BaseLLM,                           # å¿…éœ€ä¾èµ–
        retriever: BaseRetriever,               # å¿…éœ€ä¾èµ–
        memory: Optional[BaseMemory] = None,    # å¯é€‰ä¾èµ–
        verbose: bool = False                   # é…ç½®å‚æ•°
    ):
        """
        æ„é€ å‡½æ•°æ³¨å…¥

        Args:
            llm: è¯­è¨€æ¨¡å‹ï¼ˆå¿…éœ€ï¼‰
            retriever: æ£€ç´¢å™¨ï¼ˆå¿…éœ€ï¼‰
            memory: è®°å¿†ç»„ä»¶ï¼ˆå¯é€‰ï¼Œé»˜è®¤æ— ï¼‰
            verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯
        """
        self.llm = llm
        self.retriever = retriever
        self.memory = memory
        self.verbose = verbose

    def run(self, question: str) -> str:
        """æ‰§è¡Œå¯¹è¯æ£€ç´¢"""
        # 1. åŠ è½½å†å²è®°å½•
        history = ""
        if self.memory:
            history = self.memory.load()

        # 2. æ£€ç´¢ç›¸å…³æ–‡æ¡£
        docs = self.retriever.retrieve(question)
        context = "\n".join(docs)

        # 3. æ„å»º prompt
        prompt = f"History:\n{history}\n\nContext:\n{context}\n\nQuestion: {question}"

        if self.verbose:
            print(f"[Chain] Prompt: {prompt[:100]}...")

        # 4. è°ƒç”¨ LLM
        response = self.llm.invoke(prompt)

        # 5. ä¿å­˜åˆ°è®°å¿†
        if self.memory:
            self.memory.save(question, response)

        return response

# ===== å…·ä½“å®ç° =====

class FakeOpenAI(BaseLLM):
    def invoke(self, input: str) -> str:
        return f"[OpenAI] Response to: {input[:50]}..."

class FakeRetriever(BaseRetriever):
    def __init__(self, docs: List[str]):
        self.docs = docs

    def retrieve(self, query: str) -> List[str]:
        return [d for d in self.docs if query.lower() in d.lower()]

class SimpleMemory(BaseMemory):
    def __init__(self):
        self.history = []

    def load(self) -> str:
        return "\n".join(self.history)

    def save(self, input: str, output: str):
        self.history.append(f"Q: {input}\nA: {output}")

# ===== ä½¿ç”¨ï¼šåœ¨å¤–éƒ¨ç»„è£…ä¾èµ– =====

# åˆ›å»ºå…·ä½“å®ç°
llm = FakeOpenAI()
retriever = FakeRetriever(["Python is a programming language", "AI uses Python"])
memory = SimpleMemory()

# é€šè¿‡æ„é€ å‡½æ•°æ³¨å…¥
chain = ConversationalRetrievalChain(
    llm=llm,
    retriever=retriever,
    memory=memory,
    verbose=True
)

# ä½¿ç”¨
result = chain.run("What is Python?")
print(result)
```

**æ„é€ å‡½æ•°æ³¨å…¥çš„ç‰¹ç‚¹ï¼š**

| ç‰¹ç‚¹ | è¯´æ˜ | ç¤ºä¾‹ |
|------|------|------|
| æ˜ç¡®ä¾èµ– | æ‰€æœ‰ä¾èµ–åœ¨æ„é€ æ—¶å£°æ˜ | `def __init__(self, llm, retriever)` |
| ä¸å¯å˜ | ä¾èµ–åœ¨åˆ›å»ºåé€šå¸¸ä¸å˜ | `self.llm = llm` |
| å¿…éœ€ä¾èµ– | æ²¡æœ‰é»˜è®¤å€¼çš„å‚æ•°æ˜¯å¿…éœ€çš„ | `llm: BaseLLM` |
| å¯é€‰ä¾èµ– | æœ‰é»˜è®¤å€¼çš„å‚æ•°æ˜¯å¯é€‰çš„ | `memory: Optional[BaseMemory] = None` |

**åœ¨ LangChain æºç ä¸­çš„åº”ç”¨ï¼š**

```python
# langchain/chains/conversational_retrieval/base.py ç®€åŒ–ç‰ˆ
class ConversationalRetrievalChain(Chain):
    """LangChain çš„å¯¹è¯æ£€ç´¢é“¾"""

    llm: BaseLanguageModel               # æ„é€ å‡½æ•°æ³¨å…¥
    retriever: BaseRetriever             # æ„é€ å‡½æ•°æ³¨å…¥
    memory: Optional[BaseMemory] = None  # å¯é€‰æ³¨å…¥
    combine_docs_chain: BaseCombineDocumentsChain  # æ³¨å…¥

    def __init__(
        self,
        llm: BaseLanguageModel,
        retriever: BaseRetriever,
        **kwargs
    ):
        # ä¾èµ–ä»å¤–éƒ¨ä¼ å…¥
        super().__init__(llm=llm, retriever=retriever, **kwargs)
```

---

### æ ¸å¿ƒæ¦‚å¿µ2ï¼šæ–¹æ³•/å±æ€§æ³¨å…¥ ğŸ“

**é€šè¿‡æ–¹æ³•æˆ–å±æ€§è®¾ç½®ä¾èµ–ï¼Œæ”¯æŒè¿è¡Œæ—¶æ›´æ¢**

```python
from typing import Optional

class FlexibleChain:
    """
    çµæ´»çš„é“¾ - å±•ç¤ºæ–¹æ³•/å±æ€§æ³¨å…¥

    æ”¯æŒè¿è¡Œæ—¶æ›´æ¢ä¾èµ–
    """

    def __init__(self):
        self._llm: Optional[BaseLLM] = None
        self._retriever: Optional[BaseRetriever] = None

    # ===== å±æ€§æ³¨å…¥ =====

    @property
    def llm(self) -> Optional[BaseLLM]:
        return self._llm

    @llm.setter
    def llm(self, value: BaseLLM):
        """é€šè¿‡å±æ€§æ³¨å…¥ LLM"""
        print(f"[FlexibleChain] LLM è®¾ç½®ä¸º: {value.__class__.__name__}")
        self._llm = value

    @property
    def retriever(self) -> Optional[BaseRetriever]:
        return self._retriever

    @retriever.setter
    def retriever(self, value: BaseRetriever):
        """é€šè¿‡å±æ€§æ³¨å…¥ Retriever"""
        print(f"[FlexibleChain] Retriever è®¾ç½®ä¸º: {value.__class__.__name__}")
        self._retriever = value

    # ===== æ–¹æ³•æ³¨å…¥ =====

    def with_llm(self, llm: BaseLLM) -> 'FlexibleChain':
        """
        æ–¹æ³•æ³¨å…¥ï¼šè¿”å›è‡ªèº«ï¼Œæ”¯æŒé“¾å¼è°ƒç”¨

        ç±»ä¼¼ LangChain çš„ .bind() æ–¹æ³•
        """
        self._llm = llm
        return self

    def with_retriever(self, retriever: BaseRetriever) -> 'FlexibleChain':
        """æ–¹æ³•æ³¨å…¥ï¼šé“¾å¼è°ƒç”¨"""
        self._retriever = retriever
        return self

    def run(self, question: str) -> str:
        if not self._llm:
            raise ValueError("LLM æœªæ³¨å…¥")
        if not self._retriever:
            raise ValueError("Retriever æœªæ³¨å…¥")

        docs = self._retriever.retrieve(question)
        context = "\n".join(docs)
        return self._llm.invoke(f"{context}\n{question}")

# ===== ä½¿ç”¨æ–¹å¼1ï¼šå±æ€§æ³¨å…¥ =====

chain = FlexibleChain()
chain.llm = FakeOpenAI()           # å±æ€§æ³¨å…¥
chain.retriever = FakeRetriever([]) # å±æ€§æ³¨å…¥

# ===== ä½¿ç”¨æ–¹å¼2ï¼šæ–¹æ³•æ³¨å…¥ï¼ˆé“¾å¼è°ƒç”¨ï¼‰=====

chain = (FlexibleChain()
         .with_llm(FakeOpenAI())
         .with_retriever(FakeRetriever([])))

# ===== è¿è¡Œæ—¶åˆ‡æ¢ =====

chain.llm = FakeAnthropic()  # è¿è¡Œæ—¶æ›´æ¢ï¼

# ===== ç±»ä¼¼ LangChain çš„ bind æ–¹æ³• =====

class Runnable:
    """å¯è¿è¡Œç»„ä»¶"""

    def bind(self, **kwargs) -> 'BoundRunnable':
        """
        ç»‘å®šå‚æ•° - æ–¹æ³•æ³¨å…¥çš„å˜ä½“

        è¿”å›ä¸€ä¸ªæ–°çš„åŒ…è£…å¯¹è±¡
        """
        return BoundRunnable(self, kwargs)

class BoundRunnable:
    """ç»‘å®šäº†å‚æ•°çš„ Runnable"""

    def __init__(self, runnable: Runnable, bound_kwargs: dict):
        self._runnable = runnable
        self._bound_kwargs = bound_kwargs

    def invoke(self, input, **kwargs):
        merged = {**self._bound_kwargs, **kwargs}
        return self._runnable.invoke(input, **merged)
```

**æ–¹æ³•/å±æ€§æ³¨å…¥çš„ç‰¹ç‚¹ï¼š**

| ç‰¹ç‚¹ | è¯´æ˜ | é€‚ç”¨åœºæ™¯ |
|------|------|---------|
| çµæ´» | å¯ä»¥è¿è¡Œæ—¶æ›´æ¢ | éœ€è¦åŠ¨æ€åˆ‡æ¢ä¾èµ– |
| å¯é€‰ | ä¾èµ–å¯ä»¥åç»­è®¾ç½® | ä¾èµ–åˆå§‹åŒ–è¾ƒå¤æ‚ |
| é“¾å¼ | æ–¹æ³•æ³¨å…¥æ”¯æŒé“¾å¼è°ƒç”¨ | æµç•…çš„ API |
| é£é™© | å¯èƒ½å¿˜è®°è®¾ç½®ä¾èµ– | éœ€è¦é¢å¤–æ£€æŸ¥ |

**åœ¨ LangChain æºç ä¸­çš„åº”ç”¨ï¼š**

```python
# langchain_core/runnables/base.py
class Runnable(ABC):
    """LangChain çš„ Runnable ä½¿ç”¨ bind æ–¹æ³•æ³¨å…¥é…ç½®"""

    def bind(self, **kwargs):
        """
        ç»‘å®šå‚æ•°åˆ° Runnable

        è¿™æ˜¯æ–¹æ³•æ³¨å…¥çš„ä¸€ç§å½¢å¼
        """
        return RunnableBinding(self, kwargs)

# ä½¿ç”¨
model = ChatOpenAI()
bound_model = model.bind(temperature=0.5)  # æ–¹æ³•æ³¨å…¥
```

---

### æ ¸å¿ƒæ¦‚å¿µ3ï¼šå·¥å‚æ¨¡å¼ä¸ä¾èµ–æ³¨å…¥ ğŸ­

**ä½¿ç”¨å·¥å‚æ¨¡å¼åˆ›å»ºå’Œç»„è£…ä¾èµ–**

```python
from abc import ABC, abstractmethod
from typing import Dict, Type
from dataclasses import dataclass

# ===== é…ç½®ç±» =====

@dataclass
class ChainConfig:
    """é“¾é…ç½®"""
    llm_type: str = "openai"
    llm_model: str = "gpt-4"
    retriever_type: str = "chroma"
    use_memory: bool = True

# ===== å·¥å‚ç±» =====

class LLMFactory:
    """LLM å·¥å‚ - æ ¹æ®é…ç½®åˆ›å»º LLM"""

    _registry: Dict[str, Type[BaseLLM]] = {}

    @classmethod
    def register(cls, name: str, llm_class: Type[BaseLLM]):
        """æ³¨å†Œ LLM ç±»å‹"""
        cls._registry[name] = llm_class

    @classmethod
    def create(cls, config: ChainConfig) -> BaseLLM:
        """æ ¹æ®é…ç½®åˆ›å»º LLM"""
        llm_class = cls._registry.get(config.llm_type)
        if not llm_class:
            raise ValueError(f"æœªçŸ¥çš„ LLM ç±»å‹: {config.llm_type}")
        return llm_class(model=config.llm_model)

class RetrieverFactory:
    """Retriever å·¥å‚"""

    _registry: Dict[str, Type[BaseRetriever]] = {}

    @classmethod
    def register(cls, name: str, retriever_class: Type[BaseRetriever]):
        cls._registry[name] = retriever_class

    @classmethod
    def create(cls, config: ChainConfig) -> BaseRetriever:
        retriever_class = cls._registry.get(config.retriever_type)
        if not retriever_class:
            raise ValueError(f"æœªçŸ¥çš„ Retriever ç±»å‹: {config.retriever_type}")
        return retriever_class()

# ===== Chain å·¥å‚ =====

class ChainFactory:
    """
    Chain å·¥å‚ - ç»„è£…å®Œæ•´çš„ Chain

    è´Ÿè´£åˆ›å»ºæ‰€æœ‰ä¾èµ–å¹¶æ³¨å…¥åˆ° Chain
    """

    @staticmethod
    def create(config: ChainConfig) -> ConversationalRetrievalChain:
        """æ ¹æ®é…ç½®åˆ›å»ºå®Œæ•´çš„ Chain"""
        # ä½¿ç”¨å­å·¥å‚åˆ›å»ºå„ä¸ªä¾èµ–
        llm = LLMFactory.create(config)
        retriever = RetrieverFactory.create(config)
        memory = SimpleMemory() if config.use_memory else None

        # ç»„è£…å¹¶è¿”å›
        return ConversationalRetrievalChain(
            llm=llm,
            retriever=retriever,
            memory=memory
        )

# ===== æ³¨å†Œå®ç° =====

class FakeAnthropic(BaseLLM):
    def __init__(self, model: str = "claude-3"):
        self.model = model

    def invoke(self, input: str) -> str:
        return f"[{self.model}] Response"

class ChromaRetriever(BaseRetriever):
    def retrieve(self, query: str) -> List[str]:
        return [f"Chroma result for: {query}"]

class PineconeRetriever(BaseRetriever):
    def retrieve(self, query: str) -> List[str]:
        return [f"Pinecone result for: {query}"]

# æ³¨å†Œåˆ°å·¥å‚
LLMFactory.register("openai", FakeOpenAI)
LLMFactory.register("anthropic", FakeAnthropic)
RetrieverFactory.register("chroma", ChromaRetriever)
RetrieverFactory.register("pinecone", PineconeRetriever)

# ===== ä½¿ç”¨å·¥å‚ =====

# é…ç½®é©±åŠ¨
config = ChainConfig(
    llm_type="anthropic",
    llm_model="claude-3-opus",
    retriever_type="pinecone",
    use_memory=True
)

chain = ChainFactory.create(config)
result = chain.run("What is AI?")
print(result)
```

**å·¥å‚æ¨¡å¼ + ä¾èµ–æ³¨å…¥çš„ç‰¹ç‚¹ï¼š**

| ç‰¹ç‚¹ | è¯´æ˜ | ä¼˜åŠ¿ |
|------|------|------|
| é›†ä¸­åˆ›å»º | æ‰€æœ‰ä¾èµ–åœ¨å·¥å‚ä¸­åˆ›å»º | ç»Ÿä¸€ç®¡ç† |
| é…ç½®é©±åŠ¨ | æ ¹æ®é…ç½®å†³å®šå®ç° | çµæ´»åˆ‡æ¢ |
| æ³¨å†Œæœºåˆ¶ | åŠ¨æ€æ³¨å†Œå®ç°ç±» | å¯æ‰©å±• |
| éšè—å¤æ‚æ€§ | ä½¿ç”¨è€…ä¸éœ€è¦çŸ¥é“åˆ›å»ºç»†èŠ‚ | ç®€åŒ–ä½¿ç”¨ |

**åœ¨ LangChain æºç ä¸­çš„åº”ç”¨ï¼š**

```python
# langchain/llms/__init__.py
# LangChain ä½¿ç”¨ç±»ä¼¼å·¥å‚çš„æ–¹å¼æ ¹æ®ç±»å‹åˆ›å»º LLM

def get_llm(llm_type: str, **kwargs):
    """è·å– LLM å®ä¾‹"""
    if llm_type == "openai":
        from langchain_openai import ChatOpenAI
        return ChatOpenAI(**kwargs)
    elif llm_type == "anthropic":
        from langchain_anthropic import ChatAnthropic
        return ChatAnthropic(**kwargs)
    # ...
```

---

### æ‰©å±•æ¦‚å¿µ4ï¼šä¾èµ–æ³¨å…¥å®¹å™¨ ğŸ“¦

```python
from typing import Dict, Type, Any, Callable, Optional
from dataclasses import dataclass

class DIContainer:
    """
    ä¾èµ–æ³¨å…¥å®¹å™¨

    ç®¡ç†ä¾èµ–çš„æ³¨å†Œå’Œè§£æ
    """

    def __init__(self):
        self._registry: Dict[Type, Callable] = {}
        self._singletons: Dict[Type, Any] = {}

    def register(self, interface: Type, factory: Callable, singleton: bool = False):
        """
        æ³¨å†Œä¾èµ–

        Args:
            interface: æ¥å£ç±»å‹
            factory: åˆ›å»ºå®ä¾‹çš„å·¥å‚å‡½æ•°
            singleton: æ˜¯å¦å•ä¾‹
        """
        self._registry[interface] = (factory, singleton)

    def register_instance(self, interface: Type, instance: Any):
        """æ³¨å†Œå·²æœ‰å®ä¾‹ï¼ˆå•ä¾‹ï¼‰"""
        self._singletons[interface] = instance

    def resolve(self, interface: Type) -> Any:
        """
        è§£æä¾èµ–

        è¿”å›æ¥å£å¯¹åº”çš„å®ç°å®ä¾‹
        """
        # å…ˆæ£€æŸ¥å•ä¾‹ç¼“å­˜
        if interface in self._singletons:
            return self._singletons[interface]

        # ä»æ³¨å†Œè¡¨è·å–å·¥å‚
        if interface not in self._registry:
            raise ValueError(f"æœªæ³¨å†Œçš„ä¾èµ–: {interface}")

        factory, singleton = self._registry[interface]

        # åˆ›å»ºå®ä¾‹
        instance = factory(self)  # ä¼ å…¥å®¹å™¨ï¼Œæ”¯æŒåµŒå¥—è§£æ

        # å¦‚æœæ˜¯å•ä¾‹ï¼Œç¼“å­˜èµ·æ¥
        if singleton:
            self._singletons[interface] = instance

        return instance

    def create(self, cls: Type) -> Any:
        """
        è‡ªåŠ¨åˆ›å»ºå®ä¾‹

        è‡ªåŠ¨è§£ææ„é€ å‡½æ•°ä¸­çš„ä¾èµ–
        """
        import inspect

        # è·å–æ„é€ å‡½æ•°å‚æ•°
        sig = inspect.signature(cls.__init__)
        kwargs = {}

        for name, param in sig.parameters.items():
            if name == 'self':
                continue

            # è·å–å‚æ•°çš„ç±»å‹æ³¨è§£
            if param.annotation != inspect.Parameter.empty:
                # å°è¯•ä»å®¹å™¨è§£æ
                try:
                    kwargs[name] = self.resolve(param.annotation)
                except ValueError:
                    # å¦‚æœæœ‰é»˜è®¤å€¼ï¼Œä½¿ç”¨é»˜è®¤å€¼
                    if param.default != inspect.Parameter.empty:
                        kwargs[name] = param.default
                    else:
                        raise

        return cls(**kwargs)

# ===== ä½¿ç”¨ä¾èµ–æ³¨å…¥å®¹å™¨ =====

# åˆ›å»ºå®¹å™¨
container = DIContainer()

# æ³¨å†Œä¾èµ–
container.register(
    BaseLLM,
    lambda c: FakeOpenAI(),
    singleton=True  # å•ä¾‹
)

container.register(
    BaseRetriever,
    lambda c: FakeRetriever(["doc1", "doc2"]),
    singleton=False  # æ¯æ¬¡æ–°å»º
)

container.register(
    BaseMemory,
    lambda c: SimpleMemory(),
    singleton=True
)

# è§£æä¾èµ–
llm = container.resolve(BaseLLM)
retriever = container.resolve(BaseRetriever)

# è‡ªåŠ¨åˆ›å»ºï¼ˆè‡ªåŠ¨è§£ææ„é€ å‡½æ•°ä¾èµ–ï¼‰
chain = container.create(ConversationalRetrievalChain)
```

---

### æ‰©å±•æ¦‚å¿µ5ï¼šLCEL ä¸­çš„ä¾èµ–ç»„åˆ ğŸ”—

```python
from abc import ABC, abstractmethod
from typing import Any, Union

class Runnable(ABC):
    """ç®€åŒ–çš„ Runnable åŸºç±»"""

    @abstractmethod
    def invoke(self, input: Any) -> Any:
        pass

    def __or__(self, other: 'Runnable') -> 'RunnableSequence':
        """
        | æ“ä½œç¬¦ï¼šç®¡é“ç»„åˆ

        è¿™æœ¬è´¨ä¸Šæ˜¯ä¸€ç§ä¾èµ–æ³¨å…¥ï¼š
        å‰ä¸€ä¸ªç»„ä»¶çš„è¾“å‡ºæ³¨å…¥åˆ°åä¸€ä¸ªç»„ä»¶
        """
        return RunnableSequence(self, other)

    def __ror__(self, other: Any) -> 'RunnableSequence':
        """æ”¯æŒ input | runnable"""
        return RunnableSequence(RunnablePassthrough(other), self)

class RunnableSequence(Runnable):
    """
    Runnable åºåˆ— - LCEL ç®¡é“çš„æ ¸å¿ƒ

    é€šè¿‡ç»„åˆå®ç°ä¾èµ–æ³¨å…¥
    """

    def __init__(self, first: Runnable, second: Runnable):
        self.first = first
        self.second = second

    def invoke(self, input: Any) -> Any:
        # ç¬¬ä¸€ä¸ªçš„è¾“å‡ºä½œä¸ºç¬¬äºŒä¸ªçš„è¾“å…¥
        # è¿™å°±æ˜¯ä¾èµ–æ³¨å…¥ï¼
        intermediate = self.first.invoke(input)
        return self.second.invoke(intermediate)

class RunnablePassthrough(Runnable):
    """é€ä¼  Runnable"""

    def __init__(self, value: Any = None):
        self.value = value

    def invoke(self, input: Any) -> Any:
        return self.value if self.value is not None else input

# ===== å…·ä½“å®ç° =====

class PromptTemplate(Runnable):
    def __init__(self, template: str):
        self.template = template

    def invoke(self, input: dict) -> str:
        return self.template.format(**input)

class LLMRunnable(Runnable):
    def __init__(self, llm: BaseLLM):
        self.llm = llm  # æ„é€ å‡½æ•°æ³¨å…¥

    def invoke(self, input: str) -> str:
        return self.llm.invoke(input)

class OutputParser(Runnable):
    def invoke(self, input: str) -> dict:
        return {"response": input, "length": len(input)}

# ===== LCEL ç®¡é“ =====

# åˆ›å»ºç»„ä»¶ï¼ˆæ¯ä¸ªç»„ä»¶çš„ä¾èµ–åœ¨æ„é€ æ—¶æ³¨å…¥ï¼‰
prompt = PromptTemplate("Question: {question}\nAnswer:")
llm = LLMRunnable(FakeOpenAI())
parser = OutputParser()

# ä½¿ç”¨ | ç»„åˆï¼ˆç®¡é“ç»„åˆä¹Ÿæ˜¯ä¸€ç§ä¾èµ–æ³¨å…¥ï¼‰
chain = prompt | llm | parser

# ä½¿ç”¨
result = chain.invoke({"question": "What is Python?"})
print(result)
# {'response': '[OpenAI] Response to: Question: What is Python?...', 'length': 55}
```

---

## 4. ã€æœ€å°å¯ç”¨ã€‘

æŒæ¡ä»¥ä¸‹å†…å®¹ï¼Œå°±èƒ½ç†è§£ LangChain ä¸­çš„ä¾èµ–æ³¨å…¥è®¾è®¡ï¼š

### 4.1 æ„é€ å‡½æ•°æ³¨å…¥ï¼ˆæœ€å¸¸ç”¨ï¼‰

```python
class QAChain:
    def __init__(self,
                 llm: BaseLLM,        # ä¾èµ–æ³¨å…¥
                 retriever: BaseRetriever):
        self.llm = llm
        self.retriever = retriever
```

### 4.2 ä¾èµ–æŠ½è±¡æ¥å£

```python
from abc import ABC, abstractmethod

class BaseLLM(ABC):
    @abstractmethod
    def invoke(self, input: str) -> str:
        pass

# Chain ä¾èµ– BaseLLMï¼ˆæŠ½è±¡ï¼‰ï¼Œä¸ä¾èµ– ChatOpenAIï¼ˆå…·ä½“ï¼‰
```

### 4.3 å¤–éƒ¨ç»„è£…

```python
# åœ¨å¤–éƒ¨åˆ›å»ºä¾èµ–
llm = ChatOpenAI()
retriever = ChromaRetriever()

# æ³¨å…¥åˆ° Chain
chain = QAChain(llm=llm, retriever=retriever)
```

### 4.4 LCEL ç®¡é“ç»„åˆ

```python
# | æ“ä½œç¬¦ä¹Ÿæ˜¯ä¾èµ–ç»„åˆçš„ä¸€ç§å½¢å¼
chain = prompt | llm | parser
```

**è¿™äº›çŸ¥è¯†è¶³ä»¥ï¼š**
- ç†è§£ LangChain Chain çš„æ„é€ æ–¹å¼
- ç†è§£ä¸ºä»€ä¹ˆå¯ä»¥éšæ„åˆ‡æ¢ LLM
- ç†è§£ LCEL `|` ç®¡é“çš„å·¥ä½œåŸç†
- åˆ›å»ºè‡ªå®šä¹‰çš„å¯ç»„åˆç»„ä»¶

---

## 5. ã€1ä¸ªç±»æ¯”ã€‘ï¼ˆåŒè½¨åˆ¶ï¼‰

### ç±»æ¯”1ï¼šä¾èµ–æ³¨å…¥ = å¤–åŒ… vs è‡ªå»º

#### ğŸ¨ å‰ç«¯è§†è§’ï¼šReact Props

ä¾èµ–æ³¨å…¥å°±åƒ React ç»„ä»¶é€šè¿‡ Props æ¥æ”¶ä¾èµ–ã€‚

```typescript
// æ²¡æœ‰ä¾èµ–æ³¨å…¥ï¼šç»„ä»¶å†…éƒ¨åˆ›å»ºä¾èµ–
function BadComponent() {
  // ç¡¬ç¼–ç ä¾èµ–ï¼
  const api = new OpenAIApi();
  const storage = new LocalStorage();

  return <div>{api.call()}</div>;
}

// ä¾èµ–æ³¨å…¥ï¼šé€šè¿‡ Props æ¥æ”¶
interface Props {
  api: ApiInterface;      // æ³¨å…¥ API
  storage: StorageInterface; // æ³¨å…¥å­˜å‚¨
}

function GoodComponent({ api, storage }: Props) {
  return <div>{api.call()}</div>;
}

// ä½¿ç”¨æ—¶å†³å®šå…·ä½“å®ç°
<GoodComponent
  api={new OpenAIApi()}
  storage={new LocalStorage()}
/>

// æµ‹è¯•æ—¶ç”¨ Mock
<GoodComponent
  api={new MockApi()}
  storage={new MockStorage()}
/>
```

```python
# Python å¯¹åº”
class QAChain:
    def __init__(self,
                 llm: BaseLLM,       # ç±»ä¼¼ Props
                 retriever: BaseRetriever):
        self.llm = llm
        self.retriever = retriever

# ä½¿ç”¨æ—¶å†³å®šå®ç°
chain = QAChain(
    llm=ChatOpenAI(),
    retriever=ChromaRetriever()
)
```

#### ğŸ§’ å°æœ‹å‹è§†è§’ï¼šè‡ªå¸¦æ–‡å…· vs å­¦æ ¡å‘

ä¾èµ–æ³¨å…¥å°±åƒä¸Šå­¦æ—¶å¸¦è‡ªå·±çš„æ–‡å…·ã€‚

**ç”Ÿæ´»ä¾‹å­ï¼š**
```
æ²¡æœ‰ä¾èµ–æ³¨å…¥ï¼ˆå­¦æ ¡å‘æ–‡å…·ï¼‰ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           å­¦æ ¡æ•™å®¤                   â”‚
â”‚                                     â”‚
â”‚   æ¯ä¸ªå­¦ç”Ÿå›ºå®šå‘ï¼š                    â”‚
â”‚   - 2B é“…ç¬”ï¼ˆä¸èƒ½æ¢ï¼‰                â”‚
â”‚   - æ©¡çš®æ“¦ï¼ˆä¸èƒ½æ¢ï¼‰                 â”‚
â”‚   - ä¸‰è§’å°ºï¼ˆä¸èƒ½æ¢ï¼‰                 â”‚
â”‚                                     â”‚
â”‚   é—®é¢˜ï¼š                            â”‚
â”‚   - æƒ³ç”¨é’¢ç¬”ï¼Ÿä¸è¡Œï¼                 â”‚
â”‚   - æƒ³ç”¨åˆ«çš„æ©¡çš®ï¼Ÿä¸è¡Œï¼             â”‚
â”‚   - è€ƒè¯•æ—¶æƒ³ç”¨ä¸åŒçš„ï¼Ÿä¸è¡Œï¼          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ä¾èµ–æ³¨å…¥ï¼ˆè‡ªå¸¦æ–‡å…·ï¼‰ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           å­¦æ ¡æ•™å®¤                   â”‚
â”‚                                     â”‚
â”‚   å­¦ç”Ÿè‡ªå¸¦æ–‡å…·ï¼š                     â”‚
â”‚   - å°æ˜å¸¦äº†é’¢ç¬”                    â”‚
â”‚   - å°çº¢å¸¦äº†è‡ªåŠ¨é“…ç¬”                 â”‚
â”‚   - å°åå¸¦äº†å½©è‰²ç¬”                   â”‚
â”‚                                     â”‚
â”‚   ä¼˜ç‚¹ï¼š                            â”‚
â”‚   - æƒ³ç”¨ä»€ä¹ˆç”¨ä»€ä¹ˆ                   â”‚
â”‚   - æ¯ä¸ªäººå¯ä»¥ä¸åŒ                   â”‚
â”‚   - è€ƒè¯•æ—¶å¯ä»¥æ¢                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

æ•™å®¤ï¼ˆChainï¼‰ä¸ç®¡ä½ ç”¨ä»€ä¹ˆç¬”ï¼Œåªè¦èƒ½å†™å­—å°±è¡Œï¼
ç¬”ï¼ˆLLMï¼‰æ˜¯ä½ è‡ªå·±å¸¦æ¥çš„ï¼ˆæ³¨å…¥çš„ï¼‰
```

---

### ç±»æ¯”2ï¼šæ¥å£ä¾èµ– = æ’å¤´æ ‡å‡†

#### ğŸ¨ å‰ç«¯è§†è§’ï¼šTypeScript æ¥å£

```typescript
// å®šä¹‰æ¥å£ï¼ˆæ’å¤´æ ‡å‡†ï¼‰
interface PowerSocket {
  getVoltage(): number;
  connect(): void;
}

// ç»„ä»¶ä¾èµ–æ¥å£ï¼Œä¸ä¾èµ–å…·ä½“å®ç°
class Device {
  constructor(private socket: PowerSocket) {}  // ä¾èµ–æ¥å£

  start() {
    this.socket.connect();
    console.log(`Using ${this.socket.getVoltage()}V`);
  }
}

// ä¸åŒçš„å®ç°ï¼ˆä¸åŒå›½å®¶çš„æ’åº§ï¼‰
class USSocket implements PowerSocket {
  getVoltage() { return 110; }
  connect() { console.log("US socket connected"); }
}

class CNSocket implements PowerSocket {
  getVoltage() { return 220; }
  connect() { console.log("CN socket connected"); }
}

// ä½¿ç”¨
const device = new Device(new USSocket());  // ç¾å›½æ’åº§
const device2 = new Device(new CNSocket()); // ä¸­å›½æ’åº§
```

```python
# Python å¯¹åº”
class BaseLLM(ABC):
    @abstractmethod
    def invoke(self, input: str) -> str:
        pass

class Chain:
    def __init__(self, llm: BaseLLM):  # ä¾èµ–æŠ½è±¡
        self.llm = llm

# ä¸åŒå®ç°
chain1 = Chain(llm=ChatOpenAI())
chain2 = Chain(llm=ChatAnthropic())
```

#### ğŸ§’ å°æœ‹å‹è§†è§’ï¼šå……ç”µå™¨å’Œæ‰‹æœº

```
æ‰‹æœºå……ç”µï¼ˆä¾èµ–æ¥å£ï¼‰ï¼š

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           æ‰‹æœºï¼ˆChainï¼‰              â”‚
â”‚                                     â”‚
â”‚   å……ç”µå£æ ‡å‡†ï¼šType-Cï¼ˆæ¥å£ï¼‰          â”‚
â”‚                                     â”‚
â”‚   å¯ä»¥ç”¨çš„å……ç”µå™¨ï¼š                    â”‚
â”‚   - åŸè£…å……ç”µå™¨ âœ“                    â”‚
â”‚   - ç¬¬ä¸‰æ–¹å……ç”µå™¨ âœ“                  â”‚
â”‚   - å……ç”µå® âœ“                        â”‚
â”‚   - è½¦è½½å……ç”µå™¨ âœ“                    â”‚
â”‚                                     â”‚
â”‚   åªè¦æ˜¯ Type-C æ¥å£å°±è¡Œï¼            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

æ‰‹æœºä¸å…³å¿ƒå……ç”µå™¨æ˜¯ä»€ä¹ˆç‰Œå­ï¼ˆå…·ä½“å®ç°ï¼‰
åªå…³å¿ƒæ¥å£å¯¹ä¸å¯¹ï¼ˆæŠ½è±¡æ¥å£ï¼‰
```

---

### ç±»æ¯”3ï¼šå·¥å‚æ¨¡å¼ = ç‚¹èœ

#### ğŸ¨ å‰ç«¯è§†è§’ï¼šå·¥å‚å‡½æ•°

```typescript
// å·¥å‚å‡½æ•°
function createApi(type: string): ApiInterface {
  switch (type) {
    case "openai":
      return new OpenAIApi();
    case "anthropic":
      return new AnthropicApi();
    default:
      throw new Error("Unknown type");
  }
}

// ä½¿ç”¨å·¥å‚
const api = createApi("openai");
const component = new Component(api);
```

```python
# Python å¯¹åº”
class LLMFactory:
    @staticmethod
    def create(llm_type: str) -> BaseLLM:
        if llm_type == "openai":
            return ChatOpenAI()
        elif llm_type == "anthropic":
            return ChatAnthropic()

# ä½¿ç”¨
llm = LLMFactory.create("openai")
chain = Chain(llm=llm)
```

#### ğŸ§’ å°æœ‹å‹è§†è§’ï¼šé¤å…ç‚¹èœ

```
é¤å…ç‚¹èœï¼ˆå·¥å‚æ¨¡å¼ï¼‰ï¼š

ä½ ï¼ˆä½¿ç”¨è€…ï¼‰ï¼šæˆ‘è¦ä¸€ä»½ç‰›è‚‰é¢ï¼

æœåŠ¡å‘˜ï¼ˆå·¥å‚ï¼‰ï¼šå¥½çš„ï¼
  â†“
å¨æˆ¿æ ¹æ®"ç‰›è‚‰é¢"åšå‡ºä¸€ç¢—é¢
  â†“
æœåŠ¡å‘˜æŠŠé¢ç«¯ç»™ä½ 

ä½ ä¸éœ€è¦çŸ¥é“ï¼š
- é¢æ€ä¹ˆåšçš„
- ç”¨äº†ä»€ä¹ˆå¨å…·
- å¨å¸ˆæ˜¯è°

ä½ åªéœ€è¦è¯´"æˆ‘è¦ç‰›è‚‰é¢"ï¼ˆé…ç½®ï¼‰
å·¥å‚å¸®ä½ åˆ›å»ºå¥½ï¼ˆåˆ›å»ºä¾èµ–ï¼‰
```

---

### ç±»æ¯”4ï¼šLCEL ç®¡é“ = æµæ°´çº¿

#### ğŸ¨ å‰ç«¯è§†è§’ï¼šRxJS ç®¡é“

```typescript
// RxJS ç®¡é“æ“ä½œ
const result = source$.pipe(
  map(x => x * 2),        // ç¬¬ä¸€æ­¥
  filter(x => x > 10),    // ç¬¬äºŒæ­¥
  reduce((a, b) => a + b) // ç¬¬ä¸‰æ­¥
);

// æ¯ä¸€æ­¥çš„è¾“å‡ºæ˜¯ä¸‹ä¸€æ­¥çš„è¾“å…¥
// è¿™å°±æ˜¯ä¾èµ–ç»„åˆï¼
```

```python
# Python å¯¹åº”ï¼šLCEL
chain = prompt | llm | parser

# ç­‰ä»·äºï¼š
# result = parser(llm(prompt(input)))
# æ¯ä¸€æ­¥çš„è¾“å‡ºæ³¨å…¥åˆ°ä¸‹ä¸€æ­¥
```

#### ğŸ§’ å°æœ‹å‹è§†è§’ï¼šå·¥å‚æµæ°´çº¿

```
ç©å…·å·¥å‚æµæ°´çº¿ï¼ˆLCEL ç®¡é“ï¼‰ï¼š

åŸææ–™ â†’ [åˆ‡å‰²æœº] â†’ [ç»„è£…æœº] â†’ [å–·æ¼†æœº] â†’ æˆå“ç©å…·

    â”‚        â”‚          â”‚          â”‚
    â”‚        â”‚          â”‚          â”‚
    â†“        â†“          â†“          â†“
  æœ¨å¤´    åˆ‡å¥½çš„é›¶ä»¶   ç»„è£…å¥½çš„    ä¸Šäº†è‰²çš„
                      åŠæˆå“      æˆå“

æ¯ä¸ªæœºå™¨ï¼ˆç»„ä»¶ï¼‰ï¼š
- æ¥æ”¶ä¸Šä¸€æ­¥çš„äº§å‡ºï¼ˆè¾“å…¥ï¼‰
- å¤„ç†åä¼ ç»™ä¸‹ä¸€æ­¥ï¼ˆè¾“å‡ºï¼‰
- ä¸å…³å¿ƒå‰åæ˜¯ä»€ä¹ˆæœºå™¨

è¿™å°±æ˜¯ prompt | llm | parser çš„å·¥ä½œæ–¹å¼ï¼
```

---

### ç±»æ¯”æ€»ç»“è¡¨

| ä¾èµ–æ³¨å…¥æ¦‚å¿µ | å‰ç«¯ç±»æ¯” | å°æœ‹å‹ç±»æ¯” |
|-------------|---------|-----------|
| ä¾èµ–æ³¨å…¥ | React Props | è‡ªå¸¦æ–‡å…·ä¸Šå­¦ |
| æ¥å£ä¾èµ– | TypeScript Interface | Type-C å……ç”µå£ |
| æ„é€ å‡½æ•°æ³¨å…¥ | constructor(props) | å¼€å­¦æ—¶å‡†å¤‡æ–‡å…· |
| æ–¹æ³•æ³¨å…¥ | setter / åŠ¨æ€ props | ä¸´æ—¶å€Ÿæ–‡å…· |
| å·¥å‚æ¨¡å¼ | createXxx() å‡½æ•° | é¤å…ç‚¹èœ |
| DI å®¹å™¨ | Angular DI | æ–‡å…·åº—ï¼ˆç»Ÿä¸€ä¾›åº”ï¼‰|
| LCEL ç®¡é“ | RxJS pipe | å·¥å‚æµæ°´çº¿ |

---

## 6. ã€åç›´è§‰ç‚¹ã€‘

### è¯¯åŒº1ï¼šä¾èµ–æ³¨å…¥åªæ˜¯æŠŠ new ç§»åˆ°å¤–é¢ âŒ

**ä¸ºä»€ä¹ˆé”™ï¼Ÿ**
- ä¾èµ–æ³¨å…¥çš„æ ¸å¿ƒæ˜¯**ä¾èµ–æŠ½è±¡è€Œéå…·ä½“**
- åªæ˜¯ç§»åŠ¨ new çš„ä½ç½®ï¼Œä½†è¿˜æ˜¯ä¾èµ–å…·ä½“ç±»ï¼Œæ²¡æœ‰è§£è€¦
- çœŸæ­£çš„ä¾èµ–æ³¨å…¥æ˜¯ä¾èµ–**æ¥å£/æŠ½è±¡ç±»**

**ä¸ºä»€ä¹ˆäººä»¬å®¹æ˜“è¿™æ ·é”™ï¼Ÿ**
å› ä¸ºä¾èµ–æ³¨å…¥æœ€è¡¨é¢çš„è¡¨ç°å°±æ˜¯"æŠŠ new å†™åœ¨å¤–é¢"ï¼Œä½†è¿™åªæ˜¯å½¢å¼ï¼Œä¸æ˜¯æœ¬è´¨ã€‚

**æ­£ç¡®ç†è§£ï¼š**

```python
# é”™è¯¯ç†è§£ï¼šåªæ˜¯ç§»åŠ¨ newï¼ˆè¿˜æ˜¯ä¾èµ–å…·ä½“ç±»ï¼‰
class Chain:
    def __init__(self, llm: ChatOpenAI):  # ä¾èµ–å…·ä½“ç±»ï¼
        self.llm = llm

chain = Chain(ChatOpenAI())  # new åœ¨å¤–é¢ï¼Œä½†è¿˜æ˜¯ç´§è€¦åˆ

# æ­£ç¡®ç†è§£ï¼šä¾èµ–æŠ½è±¡
class Chain:
    def __init__(self, llm: BaseLLM):  # ä¾èµ–æŠ½è±¡æ¥å£
        self.llm = llm

# ç°åœ¨å¯ä»¥ä¼ å…¥ä»»ä½• BaseLLM å®ç°
chain = Chain(ChatOpenAI())
chain = Chain(ChatAnthropic())
chain = Chain(MockLLM())

# å…³é”®åŒºåˆ«ï¼š
# - é”™è¯¯ç‰ˆæœ¬ï¼šChain çŸ¥é“å…·ä½“æ˜¯ ChatOpenAI
# - æ­£ç¡®ç‰ˆæœ¬ï¼šChain åªçŸ¥é“æ˜¯æŸä¸ª BaseLLMï¼Œä¸å…³å¿ƒå…·ä½“æ˜¯ä»€ä¹ˆ
```

---

### è¯¯åŒº2ï¼šä¾èµ–æ³¨å…¥ä¼šè®©ä»£ç å˜å¤æ‚ âŒ

**ä¸ºä»€ä¹ˆé”™ï¼Ÿ**
- çŸ­æœŸçœ‹ï¼šç¡®å®å¤šäº†æ¥å£å®šä¹‰å’Œå‚æ•°ä¼ é€’
- é•¿æœŸçœ‹ï¼šå¤§å¤§é™ä½äº†ä¿®æ”¹æˆæœ¬å’Œæµ‹è¯•éš¾åº¦
- å¤æ‚åº¦ä»"åˆ†æ•£åœ¨å„å¤„"å˜æˆ"é›†ä¸­åœ¨ç»„è£…ç‚¹"

**ä¸ºä»€ä¹ˆäººä»¬å®¹æ˜“è¿™æ ·é”™ï¼Ÿ**
åœ¨å°é¡¹ç›®æˆ–ç®€å•åœºæ™¯ä¸‹ï¼Œç›´æ¥ new ç¡®å®æ›´ç®€å•ã€‚ä½†é¡¹ç›®å˜å¤§åï¼Œæ²¡æœ‰ä¾èµ–æ³¨å…¥çš„ä»£ç ä¼šå˜æˆ"æ„å¤§åˆ©é¢æ¡"ã€‚

**æ­£ç¡®ç†è§£ï¼š**

```python
# "ç®€å•"ä½†éš¾ä»¥ç»´æŠ¤
class OldChain:
    def __init__(self):
        self.llm = ChatOpenAI(
            api_key=os.getenv("OPENAI_KEY"),
            model="gpt-4",
            temperature=0.7
        )
        self.retriever = ChromaRetriever(
            embedding=OpenAIEmbedding()
        )

    def run(self, q):
        return self.llm.invoke(self.retriever.retrieve(q))

# é—®é¢˜ï¼š
# 1. æµ‹è¯•æ—¶æ€ä¹ˆ Mockï¼Ÿå¾ˆéš¾
# 2. æƒ³æ¢ Anthropicï¼Ÿæ”¹å†…éƒ¨ä»£ç 
# 3. ä¸åŒç¯å¢ƒç”¨ä¸åŒé…ç½®ï¼Ÿå†™ä¸€å † if-else

# "å¤æ‚"ä½†æ˜“äºç»´æŠ¤
class NewChain:
    def __init__(self, llm: BaseLLM, retriever: BaseRetriever):
        self.llm = llm
        self.retriever = retriever

    def run(self, q):
        return self.llm.invoke(self.retriever.retrieve(q))

# ç»„è£…é€»è¾‘é›†ä¸­åœ¨ä¸€å¤„
def create_chain(env: str) -> NewChain:
    if env == "test":
        return NewChain(MockLLM(), MockRetriever())
    elif env == "prod":
        return NewChain(ChatOpenAI(...), ChromaRetriever(...))
```

---

### è¯¯åŒº3ï¼šæ‰€æœ‰ä¾èµ–éƒ½åº”è¯¥æ³¨å…¥ âŒ

**ä¸ºä»€ä¹ˆé”™ï¼Ÿ**
- ä¸æ˜¯æ‰€æœ‰ä¸œè¥¿éƒ½éœ€è¦æ³¨å…¥
- **ç¨³å®šçš„ã€ä¸ä¼šå˜åŒ–çš„ä¾èµ–**å¯ä»¥ç›´æ¥åˆ›å»º
- åªæœ‰**å¯èƒ½å˜åŒ–çš„ã€éœ€è¦æµ‹è¯•çš„**æ‰éœ€è¦æ³¨å…¥
- è¿‡åº¦æ³¨å…¥ä¼šå¯¼è‡´å‚æ•°çˆ†ç‚¸

**ä¸ºä»€ä¹ˆäººä»¬å®¹æ˜“è¿™æ ·é”™ï¼Ÿ**
å­¦äº†ä¾èµ–æ³¨å…¥åï¼Œè§‰å¾—è¿™æ˜¯"æ­£ç¡®çš„åšæ³•"ï¼Œäºæ˜¯ä»€ä¹ˆéƒ½æ³¨å…¥ã€‚

**æ­£ç¡®ç†è§£ï¼š**

```python
import logging
from datetime import datetime

class Chain:
    def __init__(
        self,
        llm: BaseLLM,              # éœ€è¦æ³¨å…¥ï¼šå¯èƒ½æ¢ä¸åŒ LLM
        retriever: BaseRetriever,  # éœ€è¦æ³¨å…¥ï¼šå¯èƒ½æ¢ä¸åŒæ£€ç´¢å™¨
        # logger: logging.Logger,  # ä¸éœ€è¦æ³¨å…¥ï¼šlogging æ˜¯ç¨³å®šçš„
        # datetime_module,         # ä¸éœ€è¦æ³¨å…¥ï¼šdatetime ä¸ä¼šå˜
    ):
        self.llm = llm
        self.retriever = retriever
        self.logger = logging.getLogger(__name__)  # å†…éƒ¨åˆ›å»ºå³å¯

    def run(self, q):
        self.logger.info(f"Running at {datetime.now()}")  # ç›´æ¥ç”¨
        return self.llm.invoke(q)

# æ³¨å…¥åˆ¤æ–­æ ‡å‡†ï¼š
# 1. ä¼šå˜åŒ–å—ï¼Ÿï¼ˆä¸åŒç¯å¢ƒã€ä¸åŒåœºæ™¯ï¼‰â†’ æ³¨å…¥
# 2. éœ€è¦æµ‹è¯•/Mock å—ï¼Ÿâ†’ æ³¨å…¥
# 3. æ˜¯æ ¸å¿ƒä¸šåŠ¡ä¾èµ–å—ï¼Ÿâ†’ æ³¨å…¥
# 4. æ˜¯å·¥å…·ç±»/æ ‡å‡†åº“ï¼Ÿâ†’ é€šå¸¸ä¸ç”¨æ³¨å…¥
```

---

## 7. ã€å®æˆ˜ä»£ç ã€‘

```python
"""
ç¤ºä¾‹ï¼šæ„å»º LangChain é£æ ¼çš„ä¾èµ–æ³¨å…¥ç³»ç»Ÿ
æ¼”ç¤ºä¾èµ–æ³¨å…¥åœ¨ LLM åº”ç”¨æ¡†æ¶ä¸­çš„æ ¸å¿ƒç”¨æ³•
"""

from abc import ABC, abstractmethod
from typing import Any, Dict, List, Optional, Type, Callable
from dataclasses import dataclass
from datetime import datetime

# ===== 1. ä¾èµ–æ¥å£å®šä¹‰ =====
print("=== 1. ä¾èµ–æ¥å£å®šä¹‰ ===")

class BaseLLM(ABC):
    """LLM æŠ½è±¡æ¥å£"""

    @property
    @abstractmethod
    def model_name(self) -> str:
        pass

    @abstractmethod
    def invoke(self, input: str) -> str:
        pass

class BaseRetriever(ABC):
    """æ£€ç´¢å™¨æŠ½è±¡æ¥å£"""

    @abstractmethod
    def retrieve(self, query: str) -> List[str]:
        pass

class BaseMemory(ABC):
    """è®°å¿†æŠ½è±¡æ¥å£"""

    @abstractmethod
    def load(self) -> str:
        pass

    @abstractmethod
    def save(self, input_text: str, output_text: str):
        pass

    @abstractmethod
    def clear(self):
        pass

class BasePromptTemplate(ABC):
    """Prompt æ¨¡æ¿æŠ½è±¡æ¥å£"""

    @abstractmethod
    def format(self, **kwargs) -> str:
        pass

# ===== 2. å…·ä½“å®ç° =====
print("\n=== 2. å…·ä½“å®ç° ===")

class FakeOpenAI(BaseLLM):
    """æ¨¡æ‹Ÿ OpenAI"""

    def __init__(self, model: str = "gpt-4", temperature: float = 0.7):
        self._model = model
        self.temperature = temperature

    @property
    def model_name(self) -> str:
        return self._model

    def invoke(self, input: str) -> str:
        return f"[{self._model}] Response: {input[:50]}..."

class FakeAnthropic(BaseLLM):
    """æ¨¡æ‹Ÿ Anthropic"""

    def __init__(self, model: str = "claude-3-opus"):
        self._model = model

    @property
    def model_name(self) -> str:
        return self._model

    def invoke(self, input: str) -> str:
        return f"[{self._model}] I'll help with: {input[:50]}..."

class MockLLM(BaseLLM):
    """æµ‹è¯•ç”¨ Mock LLM"""

    @property
    def model_name(self) -> str:
        return "mock"

    def invoke(self, input: str) -> str:
        return "Mock response"

class SimpleRetriever(BaseRetriever):
    """ç®€å•æ£€ç´¢å™¨"""

    def __init__(self, documents: List[str]):
        self.documents = documents

    def retrieve(self, query: str) -> List[str]:
        return [doc for doc in self.documents if query.lower() in doc.lower()]

class ConversationMemory(BaseMemory):
    """å¯¹è¯è®°å¿†"""

    def __init__(self, max_history: int = 10):
        self.history: List[str] = []
        self.max_history = max_history

    def load(self) -> str:
        return "\n".join(self.history[-self.max_history:])

    def save(self, input_text: str, output_text: str):
        self.history.append(f"Human: {input_text}")
        self.history.append(f"AI: {output_text}")

    def clear(self):
        self.history.clear()

class StringPromptTemplate(BasePromptTemplate):
    """å­—ç¬¦ä¸² Prompt æ¨¡æ¿"""

    def __init__(self, template: str):
        self.template = template

    def format(self, **kwargs) -> str:
        return self.template.format(**kwargs)

# ===== 3. Chain å®ç°ï¼ˆä½¿ç”¨ä¾èµ–æ³¨å…¥ï¼‰=====
print("\n=== 3. Chain å®ç° ===")

class ConversationalRetrievalChain:
    """
    å¯¹è¯æ£€ç´¢ Chain - å±•ç¤ºæ„é€ å‡½æ•°æ³¨å…¥

    ç±»ä¼¼ LangChain çš„ ConversationalRetrievalChain
    """

    def __init__(
        self,
        llm: BaseLLM,                              # å¿…éœ€æ³¨å…¥
        retriever: BaseRetriever,                  # å¿…éœ€æ³¨å…¥
        memory: Optional[BaseMemory] = None,       # å¯é€‰æ³¨å…¥
        prompt_template: Optional[BasePromptTemplate] = None,  # å¯é€‰æ³¨å…¥
        verbose: bool = False
    ):
        """
        æ„é€ å‡½æ•°æ³¨å…¥

        æ‰€æœ‰æ ¸å¿ƒä¾èµ–ä»å¤–éƒ¨ä¼ å…¥ï¼ŒChain æœ¬èº«ä¸åˆ›å»ºä»»ä½•ä¾èµ–
        """
        self.llm = llm
        self.retriever = retriever
        self.memory = memory
        self.prompt_template = prompt_template or StringPromptTemplate(
            "Context: {context}\n\nHistory: {history}\n\nQuestion: {question}\n\nAnswer:"
        )
        self.verbose = verbose

    def run(self, question: str) -> str:
        """æ‰§è¡Œ Chain"""
        # 1. è·å–å†å²
        history = self.memory.load() if self.memory else ""

        # 2. æ£€ç´¢æ–‡æ¡£
        docs = self.retriever.retrieve(question)
        context = "\n".join(docs) if docs else "No relevant documents found."

        # 3. æ„å»º prompt
        prompt = self.prompt_template.format(
            context=context,
            history=history,
            question=question
        )

        if self.verbose:
            print(f"[Chain] Prompt:\n{prompt[:200]}...")

        # 4. è°ƒç”¨ LLM
        response = self.llm.invoke(prompt)

        # 5. ä¿å­˜åˆ°è®°å¿†
        if self.memory:
            self.memory.save(question, response)

        return response

    def __repr__(self):
        return f"ConversationalRetrievalChain(llm={self.llm.model_name})"

# ===== 4. ä½¿ç”¨ç¤ºä¾‹ =====
print("\n=== 4. ä½¿ç”¨ç¤ºä¾‹ ===")

# åˆ›å»ºä¾èµ–
openai = FakeOpenAI(model="gpt-4")
retriever = SimpleRetriever([
    "Python is a programming language.",
    "Python is great for AI and machine learning.",
    "LangChain is a framework for LLM applications.",
])
memory = ConversationMemory()

# æ³¨å…¥ä¾èµ–
chain = ConversationalRetrievalChain(
    llm=openai,
    retriever=retriever,
    memory=memory,
    verbose=True
)

# ä½¿ç”¨
print("\nç¬¬ä¸€æ¬¡å¯¹è¯ï¼š")
result1 = chain.run("What is Python?")
print(f"Response: {result1}")

print("\nç¬¬äºŒæ¬¡å¯¹è¯ï¼ˆå¸¦å†å²ï¼‰ï¼š")
result2 = chain.run("Tell me more about it")
print(f"Response: {result2}")

# ===== 5. åˆ‡æ¢ä¸åŒçš„ LLM =====
print("\n=== 5. åˆ‡æ¢ LLM ===")

# åˆ‡æ¢åˆ° Anthropic
anthropic = FakeAnthropic(model="claude-3-opus")
chain_anthropic = ConversationalRetrievalChain(
    llm=anthropic,  # æ¢ï¼
    retriever=retriever,
    memory=ConversationMemory()
)

result = chain_anthropic.run("What is LangChain?")
print(f"Anthropic Response: {result}")

# ===== 6. æµ‹è¯•æ—¶ä½¿ç”¨ Mock =====
print("\n=== 6. æµ‹è¯•ç”¨ Mock ===")

def test_chain():
    """æµ‹è¯• Chain çš„åŠŸèƒ½"""
    # ä½¿ç”¨ Mock
    chain = ConversationalRetrievalChain(
        llm=MockLLM(),
        retriever=SimpleRetriever(["test doc"]),
        memory=ConversationMemory()
    )

    result = chain.run("test question")
    assert result == "Mock response"
    print("æµ‹è¯•é€šè¿‡ï¼")

test_chain()

# ===== 7. å·¥å‚æ¨¡å¼ =====
print("\n=== 7. å·¥å‚æ¨¡å¼ ===")

@dataclass
class ChainConfig:
    """Chain é…ç½®"""
    llm_type: str = "openai"
    llm_model: str = "gpt-4"
    retriever_docs: List[str] = None
    use_memory: bool = True

    def __post_init__(self):
        if self.retriever_docs is None:
            self.retriever_docs = []

class LLMFactory:
    """LLM å·¥å‚"""

    _registry: Dict[str, Type[BaseLLM]] = {
        "openai": FakeOpenAI,
        "anthropic": FakeAnthropic,
        "mock": MockLLM,
    }

    @classmethod
    def create(cls, config: ChainConfig) -> BaseLLM:
        llm_class = cls._registry.get(config.llm_type)
        if not llm_class:
            raise ValueError(f"Unknown LLM type: {config.llm_type}")

        if config.llm_type in ("openai", "anthropic"):
            return llm_class(model=config.llm_model)
        return llm_class()

class ChainFactory:
    """Chain å·¥å‚"""

    @staticmethod
    def create(config: ChainConfig) -> ConversationalRetrievalChain:
        llm = LLMFactory.create(config)
        retriever = SimpleRetriever(config.retriever_docs)
        memory = ConversationMemory() if config.use_memory else None

        return ConversationalRetrievalChain(
            llm=llm,
            retriever=retriever,
            memory=memory
        )

# ä½¿ç”¨å·¥å‚
config = ChainConfig(
    llm_type="anthropic",
    llm_model="claude-3-sonnet",
    retriever_docs=["AI is transforming the world."],
    use_memory=True
)

chain = ChainFactory.create(config)
print(f"Factory created: {chain}")
print(f"Result: {chain.run('What is AI?')}")

# ===== 8. ä¾èµ–æ³¨å…¥å®¹å™¨ =====
print("\n=== 8. ä¾èµ–æ³¨å…¥å®¹å™¨ ===")

class DIContainer:
    """ç®€å•çš„ä¾èµ–æ³¨å…¥å®¹å™¨"""

    def __init__(self):
        self._registry: Dict[Type, Callable] = {}
        self._singletons: Dict[Type, Any] = {}

    def register(self, interface: Type, factory: Callable, singleton: bool = False):
        """æ³¨å†Œä¾èµ–"""
        self._registry[interface] = (factory, singleton)

    def resolve(self, interface: Type) -> Any:
        """è§£æä¾èµ–"""
        if interface in self._singletons:
            return self._singletons[interface]

        if interface not in self._registry:
            raise ValueError(f"Unregistered dependency: {interface}")

        factory, singleton = self._registry[interface]
        instance = factory()

        if singleton:
            self._singletons[interface] = instance

        return instance

# é…ç½®å®¹å™¨
container = DIContainer()
container.register(BaseLLM, lambda: FakeOpenAI(), singleton=True)
container.register(BaseRetriever, lambda: SimpleRetriever(["doc1", "doc2"]))
container.register(BaseMemory, lambda: ConversationMemory(), singleton=True)

# ä»å®¹å™¨è§£æä¾èµ–
llm = container.resolve(BaseLLM)
retriever = container.resolve(BaseRetriever)
memory = container.resolve(BaseMemory)

# åˆ›å»º Chain
chain = ConversationalRetrievalChain(
    llm=llm,
    retriever=retriever,
    memory=memory
)

print(f"Container created chain with: {llm.model_name}")

# ===== 9. LCEL é£æ ¼çš„ç®¡é“ç»„åˆ =====
print("\n=== 9. LCEL é£æ ¼ç®¡é“ ===")

class Runnable(ABC):
    """å¯è¿è¡Œç»„ä»¶åŸºç±»"""

    @abstractmethod
    def invoke(self, input: Any) -> Any:
        pass

    def __or__(self, other: 'Runnable') -> 'RunnableSequence':
        """| æ“ä½œç¬¦ï¼šç®¡é“ç»„åˆ"""
        return RunnableSequence(self, other)

class RunnableSequence(Runnable):
    """Runnable åºåˆ—"""

    def __init__(self, first: Runnable, second: Runnable):
        self.first = first
        self.second = second

    def invoke(self, input: Any) -> Any:
        intermediate = self.first.invoke(input)
        return self.second.invoke(intermediate)

class PromptRunnable(Runnable):
    """Prompt ç»„ä»¶"""

    def __init__(self, template: str):
        self.template = template

    def invoke(self, input: Dict[str, Any]) -> str:
        return self.template.format(**input)

class LLMRunnable(Runnable):
    """LLM ç»„ä»¶ - æ¥å—æ³¨å…¥çš„ LLM"""

    def __init__(self, llm: BaseLLM):
        self.llm = llm  # ä¾èµ–æ³¨å…¥

    def invoke(self, input: str) -> str:
        return self.llm.invoke(input)

class OutputParserRunnable(Runnable):
    """è¾“å‡ºè§£æç»„ä»¶"""

    def invoke(self, input: str) -> Dict[str, Any]:
        return {"response": input, "timestamp": datetime.now().isoformat()}

# åˆ›å»ºç®¡é“
prompt = PromptRunnable("Question: {question}\nAnswer:")
llm_runnable = LLMRunnable(FakeOpenAI())  # æ³¨å…¥ LLM
parser = OutputParserRunnable()

# ç»„åˆç®¡é“ï¼ˆè¿™ä¹Ÿæ˜¯ä¸€ç§ä¾èµ–ç»„åˆï¼‰
chain = prompt | llm_runnable | parser

# ä½¿ç”¨
result = chain.invoke({"question": "What is Python?"})
print(f"Pipeline result: {result}")

# ===== 10. æ–¹æ³•æ³¨å…¥ =====
print("\n=== 10. æ–¹æ³•æ³¨å…¥ ===")

class FlexibleChain(Runnable):
    """æ”¯æŒæ–¹æ³•æ³¨å…¥çš„ Chain"""

    def __init__(self):
        self._llm: Optional[BaseLLM] = None

    def with_llm(self, llm: BaseLLM) -> 'FlexibleChain':
        """æ–¹æ³•æ³¨å…¥ï¼šé“¾å¼è°ƒç”¨"""
        self._llm = llm
        return self

    def invoke(self, input: str) -> str:
        if not self._llm:
            raise ValueError("LLM not injected")
        return self._llm.invoke(input)

# ä½¿ç”¨æ–¹æ³•æ³¨å…¥
flexible_chain = FlexibleChain().with_llm(FakeAnthropic())
print(f"Method injection result: {flexible_chain.invoke('Hello')}")

print("\n=== å®Œæˆ ===")
```

**è¿è¡Œè¾“å‡ºç¤ºä¾‹ï¼š**
```
=== 1. ä¾èµ–æ¥å£å®šä¹‰ ===

=== 2. å…·ä½“å®ç° ===

=== 3. Chain å®ç° ===

=== 4. ä½¿ç”¨ç¤ºä¾‹ ===

ç¬¬ä¸€æ¬¡å¯¹è¯ï¼š
[Chain] Prompt:
Context: Python is a programming language.
Python is great for AI and machine learning.

History:

Question: What is Python?

Answer:...
Response: [gpt-4] Response: Context: Python is a programming ...

ç¬¬äºŒæ¬¡å¯¹è¯ï¼ˆå¸¦å†å²ï¼‰ï¼š
[Chain] Prompt:
Context: Python is a programming language.
Python is great for AI and machine learning.

History: Human: What is Python?
AI: [gpt-4] Response...
Response: [gpt-4] Response: Context: Python is a programming ...

=== 5. åˆ‡æ¢ LLM ===
Anthropic Response: [claude-3-opus] I'll help with: Context: LangChain is a framework for LLM app...

=== 6. æµ‹è¯•ç”¨ Mock ===
æµ‹è¯•é€šè¿‡ï¼

=== 7. å·¥å‚æ¨¡å¼ ===
Factory created: ConversationalRetrievalChain(llm=claude-3-sonnet)
Result: [claude-3-sonnet] I'll help with: Context: AI is transforming the world...

=== 8. ä¾èµ–æ³¨å…¥å®¹å™¨ ===
Container created chain with: gpt-4

=== 9. LCEL é£æ ¼ç®¡é“ ===
Pipeline result: {'response': '[gpt-4] Response: Question: What is Python?...', 'timestamp': '2024-01-15T10:30:45.123456'}

=== 10. æ–¹æ³•æ³¨å…¥ ===
Method injection result: [claude-3-opus] I'll help with: Hello...

=== å®Œæˆ ===
```

---

## 8. ã€é¢è¯•å¿…é—®ã€‘

### é—®é¢˜ï¼š"ä»€ä¹ˆæ˜¯ä¾èµ–æ³¨å…¥ï¼Ÿåœ¨ LangChain ä¸­æ˜¯æ€ä¹ˆåº”ç”¨çš„ï¼Ÿ"

**æ™®é€šå›ç­”ï¼ˆâŒ ä¸å‡ºå½©ï¼‰ï¼š**
"ä¾èµ–æ³¨å…¥å°±æ˜¯æŠŠå¯¹è±¡çš„ä¾èµ–ä»å¤–éƒ¨ä¼ å…¥è€Œä¸æ˜¯å†…éƒ¨åˆ›å»ºã€‚LangChain çš„ Chain æ„é€ å‡½æ•°æ¥æ”¶ LLM å‚æ•°ï¼Œå°±æ˜¯ä¾èµ–æ³¨å…¥ã€‚"

**å‡ºå½©å›ç­”ï¼ˆâœ… æ¨èï¼‰ï¼š**

> **ä¾èµ–æ³¨å…¥æœ‰ä¸‰å±‚ç†è§£ï¼š**
>
> 1. **å½¢å¼å±‚é¢**ï¼š
>    - å°†ä¾èµ–ä»"å†…éƒ¨åˆ›å»º"æ”¹ä¸º"å¤–éƒ¨ä¼ å…¥"
>    - æœ€å¸¸è§çš„æ˜¯æ„é€ å‡½æ•°æ³¨å…¥ï¼š`def __init__(self, llm: BaseLLM)`
>
> 2. **æœ¬è´¨å±‚é¢**ï¼š
>    - æ ¸å¿ƒæ˜¯**ä¾èµ–æŠ½è±¡è€Œéå…·ä½“**
>    - ç»„ä»¶ä¾èµ–æ¥å£ï¼ˆBaseLLMï¼‰ï¼Œä¸ä¾èµ–å®ç°ï¼ˆChatOpenAIï¼‰
>    - å®ç°äº†æ§åˆ¶åè½¬ï¼šç”±å¤–éƒ¨å†³å®šä½¿ç”¨å“ªä¸ªå®ç°
>
> 3. **ä»·å€¼å±‚é¢**ï¼š
>    - **è§£è€¦**ï¼šChain ä¸çŸ¥é“å…·ä½“ç”¨çš„æ˜¯å“ªä¸ª LLM
>    - **å¯æµ‹è¯•**ï¼šæµ‹è¯•æ—¶å¯ä»¥æ³¨å…¥ Mock
>    - **å¯é…ç½®**ï¼šè¿è¡Œæ—¶å†³å®šä½¿ç”¨å“ªä¸ªå®ç°
>
> **åœ¨ LangChain ä¸­çš„åº”ç”¨ï¼š**
>
> ```python
> # æ„é€ å‡½æ•°æ³¨å…¥
> class ConversationalRetrievalChain:
>     def __init__(self,
>                  llm: BaseLanguageModel,    # æ³¨å…¥ LLM
>                  retriever: BaseRetriever,  # æ³¨å…¥æ£€ç´¢å™¨
>                  memory: BaseMemory = None): # å¯é€‰æ³¨å…¥
>         ...
>
> # ä½¿ç”¨æ—¶ç»„è£…
> chain = ConversationalRetrievalChain(
>     llm=ChatOpenAI(),
>     retriever=ChromaRetriever()
> )
>
> # LCEL ç®¡é“ä¹Ÿæ˜¯ä¾èµ–ç»„åˆ
> chain = prompt | llm | parser
> # å‰ä¸€ä¸ªçš„è¾“å‡ºæ³¨å…¥åˆ°åä¸€ä¸ª
> ```
>
> **è®¾è®¡ä¼˜åŠ¿**ï¼š
> - å¯ä»¥éšæ„åˆ‡æ¢ LLMï¼ˆOpenAI â†’ Anthropicï¼‰
> - å¯ä»¥ç»„åˆä¸åŒçš„ Retrieverã€Memory
> - æµ‹è¯•æ—¶ç”¨ Mock æ›¿ä»£çœŸå® API

**ä¸ºä»€ä¹ˆè¿™ä¸ªå›ç­”å‡ºå½©ï¼Ÿ**
1. âœ… å¤šå±‚æ¬¡è§£é‡Šï¼ˆå½¢å¼/æœ¬è´¨/ä»·å€¼ï¼‰
2. âœ… å¼ºè°ƒ"ä¾èµ–æŠ½è±¡"è¿™ä¸ªæ ¸å¿ƒ
3. âœ… ç»“åˆ LangChain çœŸå®ä»£ç 
4. âœ… æåˆ° LCEL ç®¡é“

---

### é—®é¢˜ï¼š"ä¾èµ–æ³¨å…¥å’Œå·¥å‚æ¨¡å¼æœ‰ä»€ä¹ˆå…³ç³»ï¼Ÿ"

**æ™®é€šå›ç­”ï¼ˆâŒ ä¸å‡ºå½©ï¼‰ï¼š**
"å·¥å‚æ¨¡å¼ç”¨æ¥åˆ›å»ºå¯¹è±¡ï¼Œä¾èµ–æ³¨å…¥ç”¨æ¥ä¼ é€’å¯¹è±¡ã€‚å®ƒä»¬å¯ä»¥ä¸€èµ·ç”¨ã€‚"

**å‡ºå½©å›ç­”ï¼ˆâœ… æ¨èï¼‰ï¼š**

> **ä¸¤è€…æ˜¯äº’è¡¥çš„å…³ç³»ï¼š**
>
> | æ¨¡å¼ | èŒè´£ | å…³æ³¨ç‚¹ |
> |------|------|--------|
> | ä¾èµ–æ³¨å…¥ | ä½¿ç”¨ä¾èµ– | "æ€ä¹ˆä¼ å…¥" |
> | å·¥å‚æ¨¡å¼ | åˆ›å»ºä¾èµ– | "æ€ä¹ˆåˆ›å»º" |
>
> **å¸¸è§ç»„åˆæ–¹å¼ï¼š**
>
> ```python
> # å·¥å‚è´Ÿè´£åˆ›å»º
> class LLMFactory:
>     @staticmethod
>     def create(config) -> BaseLLM:
>         if config.type == "openai":
>             return ChatOpenAI(model=config.model)
>         elif config.type == "anthropic":
>             return ChatAnthropic(model=config.model)
>
> # ä¾èµ–æ³¨å…¥ä½¿ç”¨
> class Chain:
>     def __init__(self, llm: BaseLLM):  # ä¾èµ–æ³¨å…¥
>         self.llm = llm
>
> # ç»„åˆä½¿ç”¨
> llm = LLMFactory.create(config)  # å·¥å‚åˆ›å»º
> chain = Chain(llm=llm)           # æ³¨å…¥ä½¿ç”¨
> ```
>
> **LangChain çš„å®è·µ**ï¼š
> - Chain ä½¿ç”¨ä¾èµ–æ³¨å…¥æ¥æ”¶ç»„ä»¶
> - å¯ä»¥ç”¨å·¥å‚/é…ç½®æ¥åˆ›å»ºè¿™äº›ç»„ä»¶
> - LCEL çš„ `|` æ“ä½œç¬¦å°è£…äº†ç»„ä»¶åˆ›å»ºå’Œç»„åˆ
>
> **é€‰æ‹©æ ‡å‡†**ï¼š
> - ç®€å•åœºæ™¯ï¼šç›´æ¥ä¾èµ–æ³¨å…¥
> - å¤æ‚åˆ›å»ºé€»è¾‘ï¼šå·¥å‚ + ä¾èµ–æ³¨å…¥
> - éœ€è¦ç»Ÿä¸€ç®¡ç†ï¼šä¾èµ–æ³¨å…¥å®¹å™¨

---

## 9. ã€åŒ–éª¨ç»µæŒã€‘

### å¡ç‰‡1ï¼šä»€ä¹ˆæ˜¯ä¾èµ–æ³¨å…¥ ğŸ¯

**ä¸€å¥è¯ï¼š** ä¸è‡ªå·±åˆ›å»ºä¾èµ–ï¼Œè€Œæ˜¯ä»å¤–éƒ¨æ¥æ”¶ä¾èµ–ã€‚

**ä¸¾ä¾‹ï¼š**
```python
# å†…éƒ¨åˆ›å»ºï¼ˆä¸å¥½ï¼‰
class Chain:
    def __init__(self):
        self.llm = ChatOpenAI()  # ç¡¬ç¼–ç 

# å¤–éƒ¨æ³¨å…¥ï¼ˆå¥½ï¼‰
class Chain:
    def __init__(self, llm: BaseLLM):
        self.llm = llm  # ä»å¤–éƒ¨ä¼ å…¥
```

**åº”ç”¨ï¼š** LangChain çš„æ‰€æœ‰ Chain éƒ½ä½¿ç”¨ä¾èµ–æ³¨å…¥ã€‚

---

### å¡ç‰‡2ï¼šæ„é€ å‡½æ•°æ³¨å…¥ ğŸ—ï¸

**ä¸€å¥è¯ï¼š** é€šè¿‡æ„é€ å‡½æ•°å‚æ•°ä¼ å…¥ä¾èµ–ï¼Œæœ€å¸¸ç”¨çš„æ³¨å…¥æ–¹å¼ã€‚

**ä¸¾ä¾‹ï¼š**
```python
class QAChain:
    def __init__(self,
                 llm: BaseLLM,        # å¿…éœ€
                 memory: BaseMemory = None):  # å¯é€‰
        self.llm = llm
        self.memory = memory
```

**åº”ç”¨ï¼š** LangChain Chain çš„æ ‡å‡†å†™æ³•ã€‚

---

### å¡ç‰‡3ï¼šä¾èµ–æŠ½è±¡æ¥å£ ğŸ”Œ

**ä¸€å¥è¯ï¼š** ä¾èµ–æ¥å£ï¼ˆæŠ½è±¡ç±»ï¼‰ï¼Œä¸ä¾èµ–å…·ä½“å®ç°ï¼Œæ˜¯ä¾èµ–æ³¨å…¥çš„æ ¸å¿ƒã€‚

**ä¸¾ä¾‹ï¼š**
```python
class Chain:
    def __init__(self, llm: BaseLLM):  # ä¾èµ–æŠ½è±¡
        self.llm = llm

# å¯ä»¥ä¼ å…¥ä»»ä½• BaseLLM å®ç°
Chain(llm=ChatOpenAI())
Chain(llm=ChatAnthropic())
Chain(llm=MockLLM())
```

**åº”ç”¨ï¼š** LangChain å®šä¹‰äº† BaseChatModelã€BaseRetriever ç­‰æŠ½è±¡ã€‚

---

### å¡ç‰‡4ï¼šæ–¹æ³•æ³¨å…¥ ğŸ“

**ä¸€å¥è¯ï¼š** é€šè¿‡æ–¹æ³•æˆ–å±æ€§è®¾ç½®ä¾èµ–ï¼Œæ”¯æŒè¿è¡Œæ—¶æ›´æ¢ã€‚

**ä¸¾ä¾‹ï¼š**
```python
class Chain:
    def with_llm(self, llm: BaseLLM) -> 'Chain':
        self._llm = llm
        return self  # é“¾å¼è°ƒç”¨

chain = Chain().with_llm(ChatOpenAI())
```

**åº”ç”¨ï¼š** LangChain çš„ `bind()` æ–¹æ³•ã€‚

---

### å¡ç‰‡5ï¼šå·¥å‚ + æ³¨å…¥ ğŸ­

**ä¸€å¥è¯ï¼š** å·¥å‚è´Ÿè´£åˆ›å»ºä¾èµ–ï¼Œä¾èµ–æ³¨å…¥è´Ÿè´£ä½¿ç”¨ä¾èµ–ã€‚

**ä¸¾ä¾‹ï¼š**
```python
# å·¥å‚åˆ›å»º
llm = LLMFactory.create(config)

# æ³¨å…¥ä½¿ç”¨
chain = Chain(llm=llm)
```

**åº”ç”¨ï¼š** LangChain çš„é…ç½®ç³»ç»Ÿã€‚

---

### å¡ç‰‡6ï¼šå¯æµ‹è¯•æ€§ ğŸ§ª

**ä¸€å¥è¯ï¼š** ä¾èµ–æ³¨å…¥è®©æµ‹è¯•å˜å¾—ç®€å•ï¼Œå¯ä»¥è½»æ¾ä½¿ç”¨ Mockã€‚

**ä¸¾ä¾‹ï¼š**
```python
class MockLLM(BaseLLM):
    def invoke(self, input): return "mock"

def test_chain():
    chain = Chain(llm=MockLLM())  # æ³¨å…¥ Mock
    assert chain.run("test") == "mock"
```

**åº”ç”¨ï¼š** æµ‹è¯• LangChain åº”ç”¨æ—¶æ›¿æ¢çœŸå® APIã€‚

---

### å¡ç‰‡7ï¼šLCEL ç®¡é“ ğŸ”—

**ä¸€å¥è¯ï¼š** `|` æ“ä½œç¬¦ä¹Ÿæ˜¯ä¾èµ–ç»„åˆï¼Œå‰ä¸€ä¸ªçš„è¾“å‡ºæ³¨å…¥åˆ°åä¸€ä¸ªã€‚

**ä¸¾ä¾‹ï¼š**
```python
chain = prompt | llm | parser

# ç­‰ä»·äºï¼š
# output = parser(llm(prompt(input)))
```

**åº”ç”¨ï¼š** LangChain Expression Language çš„æ ¸å¿ƒæœºåˆ¶ã€‚

---

### å¡ç‰‡8ï¼šæ§åˆ¶åè½¬ ğŸ”„

**ä¸€å¥è¯ï¼š** ä¾èµ–çš„æ§åˆ¶æƒä»ç»„ä»¶å†…éƒ¨è½¬ç§»åˆ°å¤–éƒ¨ï¼Œç”±å¤–éƒ¨å†³å®šä½¿ç”¨ä»€ä¹ˆã€‚

**ä¸¾ä¾‹ï¼š**
```python
# ç»„ä»¶ä¸æ§åˆ¶ï¼ˆå¥½ï¼‰
class Chain:
    def __init__(self, llm): ...  # å¤–éƒ¨å†³å®š

# ç»„ä»¶æ§åˆ¶ï¼ˆä¸å¥½ï¼‰
class Chain:
    def __init__(self):
        self.llm = ChatOpenAI()  # å†…éƒ¨å†³å®š
```

**åº”ç”¨ï¼š** è¿™å°±æ˜¯ä¸ºä»€ä¹ˆå¯ä»¥éšæ„åˆ‡æ¢ LLMã€‚

---

### å¡ç‰‡9ï¼šä¸æ˜¯æ‰€æœ‰éƒ½è¦æ³¨å…¥ âš ï¸

**ä¸€å¥è¯ï¼š** åªæ³¨å…¥å¯èƒ½å˜åŒ–ã€éœ€è¦æµ‹è¯•çš„ä¾èµ–ï¼Œå·¥å…·ç±»ä¸ç”¨æ³¨å…¥ã€‚

**åˆ¤æ–­æ ‡å‡†ï¼š**
- âœ… æ ¸å¿ƒä¸šåŠ¡ä¾èµ–ï¼ˆLLMã€Retrieverï¼‰â†’ æ³¨å…¥
- âŒ å·¥å…·ç±»ï¼ˆloggingã€datetimeï¼‰â†’ ä¸ç”¨æ³¨å…¥

**åº”ç”¨ï¼š** é¿å…è¿‡åº¦è®¾è®¡ã€‚

---

### å¡ç‰‡10ï¼šä¾èµ–æ³¨å…¥æ€»ç»“ â­

**ä¸€å¥è¯ï¼š** å¤–éƒ¨ä¼ å…¥ + ä¾èµ–æŠ½è±¡ = æ¾è€¦åˆ + å¯æµ‹è¯• + å¯é…ç½®ã€‚

**æ ¸å¿ƒè¦ç‚¹ï¼š**
1. ä¾èµ–ä»æ„é€ å‡½æ•°ä¼ å…¥
2. ä¾èµ–ç±»å‹æ˜¯æŠ½è±¡æ¥å£
3. å·¥å‚å¯ä»¥å¸®åŠ©åˆ›å»ºä¾èµ–
4. LCEL `|` ä¹Ÿæ˜¯ä¾èµ–ç»„åˆ
5. åªæ³¨å…¥éœ€è¦å˜åŒ–çš„ä¾èµ–

**è®°ä½ï¼š** çœ‹åˆ° `def __init__(self, xxx: BaseXxx)` å°±æ˜¯ä¾èµ–æ³¨å…¥ï¼

---

## 10. ã€ä¸€å¥è¯æ€»ç»“ã€‘

**ä¾èµ–æ³¨å…¥é€šè¿‡å°†ä¾èµ–ä»å†…éƒ¨åˆ›å»ºæ”¹ä¸ºå¤–éƒ¨ä¼ å…¥ã€ä¾èµ–æŠ½è±¡æ¥å£è€Œéå…·ä½“å®ç°ï¼Œå®ç°äº†ç»„ä»¶é—´çš„æ¾è€¦åˆï¼Œæ˜¯ LangChain èƒ½å¤Ÿçµæ´»ç»„åˆä¸åŒ LLMã€Retrieverã€Memory çš„æ¶æ„åŸºç¡€ï¼Œä¹Ÿæ˜¯ LCEL ç®¡é“ç»„åˆèƒ½å¤Ÿå·¥ä½œçš„æ ¸å¿ƒæœºåˆ¶ã€‚**

---

## ğŸ“š å­¦ä¹ æ£€æŸ¥æ¸…å•

- [ ] ç†è§£ä¾èµ–æ³¨å…¥çš„æ ¸å¿ƒæ€æƒ³ï¼ˆå¤–éƒ¨ä¼ å…¥ + ä¾èµ–æŠ½è±¡ï¼‰
- [ ] èƒ½ä½¿ç”¨æ„é€ å‡½æ•°æ³¨å…¥è®¾è®¡ç»„ä»¶
- [ ] ç†è§£ä¾èµ–æŠ½è±¡æ¥å£çš„ä»·å€¼
- [ ] èƒ½åŒºåˆ†æ„é€ å‡½æ•°æ³¨å…¥å’Œæ–¹æ³•æ³¨å…¥
- [ ] ç†è§£å·¥å‚æ¨¡å¼ä¸ä¾èµ–æ³¨å…¥çš„é…åˆ
- [ ] èƒ½è¯†åˆ« LangChain æºç ä¸­çš„ä¾èµ–æ³¨å…¥æ¨¡å¼
- [ ] ç†è§£ LCEL `|` ç®¡é“çš„ä¾èµ–ç»„åˆæœ¬è´¨
- [ ] èƒ½å¤Ÿä½¿ç”¨ä¾èµ–æ³¨å…¥æé«˜ä»£ç å¯æµ‹è¯•æ€§

## ğŸ”— ä¸‹ä¸€æ­¥å­¦ä¹ 

- **Runnable åè®®**ï¼šLangChain ä¾èµ–æ³¨å…¥çš„ä¸»è¦æ¥å£
- **LCEL è¡¨è¾¾å¼è¯­è¨€**ï¼šä¾èµ–ç»„åˆçš„é«˜çº§å½¢å¼
- **Chain é“¾å¼è°ƒç”¨**ï¼šä¾èµ–æ³¨å…¥çš„å®é™…åº”ç”¨
- **Callback å›è°ƒç³»ç»Ÿ**ï¼šå¦ä¸€ç§"æ³¨å…¥"é’©å­çš„æ–¹å¼

---

**ç‰ˆæœ¬ï¼š** v1.0
**æœ€åæ›´æ–°ï¼š** 2025-12-12
