# è§‚å¯Ÿè€…æ¨¡å¼ (Observer Pattern)

> åŸå­åŒ–çŸ¥è¯†ç‚¹ | è½¯ä»¶å·¥ç¨‹åŸºç¡€ | LangChain æºç å­¦ä¹ å‰ç½®çŸ¥è¯†

---

## 1. ã€30å­—æ ¸å¿ƒã€‘

**è§‚å¯Ÿè€…æ¨¡å¼å®šä¹‰å¯¹è±¡é—´ä¸€å¯¹å¤šçš„ä¾èµ–å…³ç³»ï¼Œå½“è¢«è§‚å¯Ÿè€…çŠ¶æ€æ”¹å˜æ—¶è‡ªåŠ¨é€šçŸ¥æ‰€æœ‰è§‚å¯Ÿè€…ï¼Œæ˜¯ LangChain Callback ç³»ç»Ÿçš„æ ¸å¿ƒåŸºç¡€ã€‚**

---

## 2. ã€ç¬¬ä¸€æ€§åŸç†ã€‘

### ä»€ä¹ˆæ˜¯ç¬¬ä¸€æ€§åŸç†ï¼Ÿ

**ç¬¬ä¸€æ€§åŸç†**ï¼šå›åˆ°äº‹ç‰©æœ€åŸºæœ¬çš„çœŸç†ï¼Œä»æºå¤´æ€è€ƒé—®é¢˜

### è§‚å¯Ÿè€…æ¨¡å¼çš„ç¬¬ä¸€æ€§åŸç† ğŸ¯

#### 1. æœ€åŸºç¡€çš„å®šä¹‰

**è§‚å¯Ÿè€…æ¨¡å¼ = å‘å¸ƒè€… + è®¢é˜…è€… + è‡ªåŠ¨é€šçŸ¥**

ä»…æ­¤è€Œå·²ï¼æ²¡æœ‰æ›´åŸºç¡€çš„äº†ã€‚

- **å‘å¸ƒè€…ï¼ˆSubject/Observableï¼‰**ï¼šçŠ¶æ€å‘ç”Ÿå˜åŒ–çš„å¯¹è±¡
- **è®¢é˜…è€…ï¼ˆObserverï¼‰**ï¼šå…³å¿ƒçŠ¶æ€å˜åŒ–çš„å¯¹è±¡
- **è‡ªåŠ¨é€šçŸ¥**ï¼šçŠ¶æ€å˜åŒ–æ—¶è‡ªåŠ¨å‘ŠçŸ¥æ‰€æœ‰è®¢é˜…è€…

#### 2. ä¸ºä»€ä¹ˆéœ€è¦è§‚å¯Ÿè€…æ¨¡å¼ï¼Ÿ

**æ ¸å¿ƒé—®é¢˜ï¼šå¦‚ä½•åœ¨ä¸€ä¸ªå¯¹è±¡çŠ¶æ€å˜åŒ–æ—¶ï¼Œè®©å¤šä¸ªç›¸å…³å¯¹è±¡åŒæ­¥å“åº”ï¼Ÿ**

```python
# æ²¡æœ‰è§‚å¯Ÿè€…æ¨¡å¼ï¼šç¡¬ç¼–ç ä¾èµ–ï¼Œç´§è€¦åˆ
class LLMModel:
    def __init__(self):
        self.logger = Logger()      # ç¡¬ç¼–ç ä¾èµ–
        self.monitor = Monitor()    # ç¡¬ç¼–ç ä¾èµ–
        self.cache = Cache()        # ç¡¬ç¼–ç ä¾èµ–

    def generate(self, prompt: str) -> str:
        # å¼€å§‹æ—¶æ‰‹åŠ¨é€šçŸ¥æ¯ä¸ªä¾èµ–
        self.logger.log_start(prompt)      # æ‰‹åŠ¨è°ƒç”¨
        self.monitor.record_start()         # æ‰‹åŠ¨è°ƒç”¨

        result = self._call_api(prompt)

        # ç»“æŸæ—¶æ‰‹åŠ¨é€šçŸ¥æ¯ä¸ªä¾èµ–
        self.logger.log_end(result)         # æ‰‹åŠ¨è°ƒç”¨
        self.monitor.record_end()           # æ‰‹åŠ¨è°ƒç”¨
        self.cache.store(prompt, result)    # æ‰‹åŠ¨è°ƒç”¨

        return result

# é—®é¢˜ï¼š
# 1. LLMModel å¿…é¡»çŸ¥é“æ‰€æœ‰ä¾èµ–çš„å…·ä½“ç±»å‹
# 2. æ·»åŠ æ–°çš„ç›‘å¬è€…éœ€è¦ä¿®æ”¹ LLMModel ä»£ç 
# 3. æ— æ³•åŠ¨æ€æ·»åŠ /ç§»é™¤ç›‘å¬è€…
# 4. è¿åå¼€é—­åŸåˆ™
```

```python
# ä½¿ç”¨è§‚å¯Ÿè€…æ¨¡å¼ï¼šæ¾è€¦åˆï¼Œå¯æ‰©å±•
from abc import ABC, abstractmethod
from typing import List

class LLMCallback(ABC):
    """è§‚å¯Ÿè€…æ¥å£"""
    @abstractmethod
    def on_start(self, prompt: str): pass

    @abstractmethod
    def on_end(self, result: str): pass

class LLMModel:
    """è¢«è§‚å¯Ÿè€…"""
    def __init__(self):
        self.callbacks: List[LLMCallback] = []  # åªä¾èµ–æŠ½è±¡æ¥å£

    def add_callback(self, callback: LLMCallback):
        self.callbacks.append(callback)

    def remove_callback(self, callback: LLMCallback):
        self.callbacks.remove(callback)

    def generate(self, prompt: str) -> str:
        # ç»Ÿä¸€é€šçŸ¥æ‰€æœ‰è§‚å¯Ÿè€…
        for cb in self.callbacks:
            cb.on_start(prompt)

        result = self._call_api(prompt)

        for cb in self.callbacks:
            cb.on_end(result)

        return result

# å…·ä½“è§‚å¯Ÿè€…
class LoggingCallback(LLMCallback):
    def on_start(self, prompt): print(f"[LOG] Start: {prompt}")
    def on_end(self, result): print(f"[LOG] End: {result}")

class MonitorCallback(LLMCallback):
    def on_start(self, prompt): print(f"[MONITOR] Recording...")
    def on_end(self, result): print(f"[MONITOR] Done")

# ä½¿ç”¨ï¼šåŠ¨æ€æ·»åŠ /ç§»é™¤
model = LLMModel()
model.add_callback(LoggingCallback())
model.add_callback(MonitorCallback())
# å¯ä»¥éšæ—¶æ·»åŠ æ–°çš„ Callbackï¼Œæ— éœ€ä¿®æ”¹ LLMModelï¼
```

#### 3. è§‚å¯Ÿè€…æ¨¡å¼çš„ä¸‰å±‚ä»·å€¼

##### ä»·å€¼1ï¼šè§£è€¦ - å‘å¸ƒè€…ä¸å…³å¿ƒè®¢é˜…è€…æ˜¯è°

```python
# å‘å¸ƒè€…åªçŸ¥é“"æœ‰äººè®¢é˜…äº†"ï¼Œä¸çŸ¥é“å…·ä½“æ˜¯è°
class Subject:
    def __init__(self):
        self._observers = []  # åªå­˜å‚¨å¼•ç”¨ï¼Œä¸å…³å¿ƒå…·ä½“ç±»å‹

    def notify(self):
        for observer in self._observers:
            observer.update()  # ç»Ÿä¸€æ¥å£è°ƒç”¨
```

##### ä»·å€¼2ï¼šåŠ¨æ€æ€§ - è¿è¡Œæ—¶æ·»åŠ /ç§»é™¤è§‚å¯Ÿè€…

```python
# å¯ä»¥åœ¨è¿è¡Œæ—¶åŠ¨æ€æ”¹å˜è§‚å¯Ÿè€…
model = LLMModel()
logger = LoggingCallback()

model.add_callback(logger)    # æ·»åŠ 
model.generate("Hello")       # logger ä¼šæ”¶åˆ°é€šçŸ¥

model.remove_callback(logger) # ç§»é™¤
model.generate("World")       # logger ä¸ä¼šæ”¶åˆ°é€šçŸ¥
```

##### ä»·å€¼3ï¼šå¹¿æ’­ - ä¸€æ¬¡çŠ¶æ€å˜åŒ–ï¼Œå¤šæ–¹å“åº”

```python
# ä¸€ä¸ªäº‹ä»¶ï¼Œå¤šä¸ªå“åº”
model.add_callback(LoggingCallback())   # è®°å½•æ—¥å¿—
model.add_callback(MonitorCallback())   # ç›‘æ§æŒ‡æ ‡
model.add_callback(CacheCallback())     # ç¼“å­˜ç»“æœ
model.add_callback(AlertCallback())     # å¼‚å¸¸å‘Šè­¦

model.generate("Test")  # æ‰€æœ‰ callback éƒ½ä¼šè¢«é€šçŸ¥ï¼
```

#### 4. ä»ç¬¬ä¸€æ€§åŸç†æ¨å¯¼ LangChain æºç åº”ç”¨

**æ¨ç†é“¾ï¼š**

```
1. LLM åº”ç”¨éœ€è¦åœ¨æ‰§è¡Œè¿‡ç¨‹ä¸­åšå¾ˆå¤š"å‰¯ä½œç”¨"æ“ä½œ
   â†“
2. è¿™äº›æ“ä½œåŒ…æ‹¬ï¼šæ—¥å¿—ã€ç›‘æ§ã€ç¼“å­˜ã€æµå¼è¾“å‡ºã€æˆæœ¬è®¡ç®—...
   â†“
3. ä¸åŒåœºæ™¯éœ€è¦ä¸åŒçš„ç»„åˆï¼ˆå¼€å‘éœ€è¦æ—¥å¿—ï¼Œç”Ÿäº§éœ€è¦ç›‘æ§ï¼‰
   â†“
4. å¦‚æœç¡¬ç¼–ç è¿™äº›ä¾èµ–ï¼Œä»£ç ä¼šéå¸¸è‡ƒè‚¿ä¸”éš¾ä»¥ç»´æŠ¤
   â†“
5. éœ€è¦ä¸€ç§æœºåˆ¶ï¼šæ ¸å¿ƒé€»è¾‘ä¸å˜ï¼Œå‰¯ä½œç”¨å¯æ’æ‹”
   â†“
6. è§‚å¯Ÿè€…æ¨¡å¼å®Œç¾åŒ¹é…ï¼šLLM æ˜¯è¢«è§‚å¯Ÿè€…ï¼Œå„ç§ Handler æ˜¯è§‚å¯Ÿè€…
   â†“
7. LangChain è®¾è®¡äº† Callback ç³»ç»Ÿ
   â†“
8. BaseCallbackHandler å®šä¹‰è§‚å¯Ÿè€…æ¥å£ï¼ˆon_llm_start, on_llm_end...ï¼‰
   â†“
9. ç”¨æˆ·å¯ä»¥å®ç°è‡ªå·±çš„ Handlerï¼ŒåŠ¨æ€æ³¨å†Œåˆ°ä»»ä½•ç»„ä»¶
   â†“
10. å®ç°äº†ï¼šæ ¸å¿ƒé€»è¾‘ä¸å‰¯ä½œç”¨å®Œå…¨è§£è€¦
```

#### 5. ä¸€å¥è¯æ€»ç»“ç¬¬ä¸€æ€§åŸç†

**è§‚å¯Ÿè€…æ¨¡å¼é€šè¿‡"è®¢é˜…-é€šçŸ¥"æœºåˆ¶å®ç°å¯¹è±¡é—´çš„æ¾è€¦åˆï¼Œè®©çŠ¶æ€å˜åŒ–èƒ½å¤Ÿè‡ªåŠ¨å¹¿æ’­ç»™æ‰€æœ‰å…³å¿ƒå®ƒçš„å¯¹è±¡ï¼Œæ˜¯ LangChain Callback ç³»ç»Ÿå®ç°å¯æ’æ‹”ç›‘æ§ã€æ—¥å¿—ã€æµå¼è¾“å‡ºçš„æ¶æ„åŸºç¡€ã€‚**

---

## 3. ã€æ ¸å¿ƒæ¦‚å¿µï¼ˆå…¨é¢è¦†ç›–ï¼‰ã€‘

### æ ¸å¿ƒæ¦‚å¿µ1ï¼šè¢«è§‚å¯Ÿè€…ï¼ˆSubject/Observableï¼‰ ğŸ¯

**è¢«è§‚å¯Ÿè€…æ˜¯çŠ¶æ€å˜åŒ–çš„æºå¤´ï¼Œè´Ÿè´£ç®¡ç†è§‚å¯Ÿè€…åˆ—è¡¨å¹¶åœ¨çŠ¶æ€å˜åŒ–æ—¶é€šçŸ¥å®ƒä»¬**

```python
from abc import ABC, abstractmethod
from typing import List, Any

class Subject(ABC):
    """
    è¢«è§‚å¯Ÿè€…æŠ½è±¡åŸºç±»

    èŒè´£ï¼š
    1. ç»´æŠ¤è§‚å¯Ÿè€…åˆ—è¡¨
    2. æä¾›æ·»åŠ /ç§»é™¤è§‚å¯Ÿè€…çš„æ–¹æ³•
    3. çŠ¶æ€å˜åŒ–æ—¶é€šçŸ¥æ‰€æœ‰è§‚å¯Ÿè€…
    """

    def __init__(self):
        self._observers: List['Observer'] = []
        self._state: Any = None

    def attach(self, observer: 'Observer') -> None:
        """æ·»åŠ è§‚å¯Ÿè€…"""
        if observer not in self._observers:
            self._observers.append(observer)
            print(f"è§‚å¯Ÿè€… {observer.__class__.__name__} å·²è®¢é˜…")

    def detach(self, observer: 'Observer') -> None:
        """ç§»é™¤è§‚å¯Ÿè€…"""
        if observer in self._observers:
            self._observers.remove(observer)
            print(f"è§‚å¯Ÿè€… {observer.__class__.__name__} å·²å–æ¶ˆè®¢é˜…")

    def notify(self) -> None:
        """é€šçŸ¥æ‰€æœ‰è§‚å¯Ÿè€…"""
        print(f"é€šçŸ¥ {len(self._observers)} ä¸ªè§‚å¯Ÿè€…...")
        for observer in self._observers:
            observer.update(self)

    @property
    def state(self) -> Any:
        return self._state

    @state.setter
    def state(self, value: Any) -> None:
        self._state = value
        self.notify()  # çŠ¶æ€å˜åŒ–æ—¶è‡ªåŠ¨é€šçŸ¥

class LLMSubject(Subject):
    """
    LLM è¢«è§‚å¯Ÿè€… - ç±»ä¼¼ LangChain çš„å¯è§‚å¯Ÿç»„ä»¶

    çŠ¶æ€åŒ…æ‹¬ï¼šå½“å‰ promptã€å“åº”ç»“æœã€æ‰§è¡ŒçŠ¶æ€ç­‰
    """

    def __init__(self, model_name: str = "gpt-4"):
        super().__init__()
        self.model_name = model_name
        self._prompt: str = ""
        self._response: str = ""
        self._status: str = "idle"

    def generate(self, prompt: str) -> str:
        """ç”Ÿæˆå“åº” - åœ¨å…³é”®èŠ‚ç‚¹é€šçŸ¥è§‚å¯Ÿè€…"""
        # å¼€å§‹
        self._prompt = prompt
        self._status = "running"
        self._notify_event("start", {"prompt": prompt})

        # æ¨¡æ‹Ÿç”Ÿæˆ
        self._response = f"[{self.model_name}] Response to: {prompt}"

        # ç»“æŸ
        self._status = "completed"
        self._notify_event("end", {"response": self._response})

        return self._response

    def _notify_event(self, event: str, data: dict) -> None:
        """é€šçŸ¥ç‰¹å®šäº‹ä»¶"""
        for observer in self._observers:
            if hasattr(observer, f"on_{event}"):
                getattr(observer, f"on_{event}")(self, data)
```

**è¢«è§‚å¯Ÿè€…çš„å…³é”®ç‰¹å¾ï¼š**

| ç‰¹å¾ | è¯´æ˜ | ç¤ºä¾‹ |
|------|------|------|
| çŠ¶æ€æŒæœ‰è€… | æ‹¥æœ‰å…¶ä»–å¯¹è±¡å…³å¿ƒçš„çŠ¶æ€ | LLM çš„æ‰§è¡ŒçŠ¶æ€ |
| è§‚å¯Ÿè€…ç®¡ç† | ç»´æŠ¤è§‚å¯Ÿè€…åˆ—è¡¨ | `self._observers` åˆ—è¡¨ |
| ä¸»åŠ¨é€šçŸ¥ | çŠ¶æ€å˜åŒ–æ—¶ä¸»åŠ¨é€šçŸ¥ | `self.notify()` |
| ä¸ä¾èµ–å…·ä½“è§‚å¯Ÿè€… | åªä¾èµ–è§‚å¯Ÿè€…æ¥å£ | `Observer` æŠ½è±¡ç±» |

**åœ¨ LangChain æºç ä¸­çš„åº”ç”¨ï¼š**

```python
# langchain_core/runnables/base.py ç®€åŒ–ç‰ˆ
class Runnable(ABC):
    """LangChain çš„ Runnable å°±æ˜¯ä¸€ç§è¢«è§‚å¯Ÿè€…"""

    def invoke(self, input, config=None):
        """invoke æ–¹æ³•ä¸­ä¼šé€šçŸ¥å„ç§ callback"""
        callbacks = config.get("callbacks", [])

        # é€šçŸ¥å¼€å§‹
        for cb in callbacks:
            cb.on_chain_start(input)

        result = self._invoke(input)

        # é€šçŸ¥ç»“æŸ
        for cb in callbacks:
            cb.on_chain_end(result)

        return result
```

---

### æ ¸å¿ƒæ¦‚å¿µ2ï¼šè§‚å¯Ÿè€…ï¼ˆObserverï¼‰ ğŸ‘€

**è§‚å¯Ÿè€…æ˜¯å…³å¿ƒè¢«è§‚å¯Ÿè€…çŠ¶æ€å˜åŒ–çš„å¯¹è±¡ï¼Œå½“æ”¶åˆ°é€šçŸ¥æ—¶æ‰§è¡Œç›¸åº”çš„å“åº”é€»è¾‘**

```python
from abc import ABC, abstractmethod
from typing import Any, Dict
from datetime import datetime

class Observer(ABC):
    """
    è§‚å¯Ÿè€…æŠ½è±¡åŸºç±»

    å®šä¹‰è§‚å¯Ÿè€…å¿…é¡»å®ç°çš„æ¥å£
    """

    @abstractmethod
    def update(self, subject: 'Subject') -> None:
        """æ”¶åˆ°é€šçŸ¥æ—¶çš„å“åº”æ–¹æ³•"""
        pass

class LLMObserver(ABC):
    """
    LLM è§‚å¯Ÿè€…æ¥å£ - ç±»ä¼¼ LangChain çš„ BaseCallbackHandler

    å®šä¹‰äº† LLM æ‰§è¡Œè¿‡ç¨‹ä¸­å„ä¸ªé˜¶æ®µçš„é’©å­æ–¹æ³•
    """

    def on_start(self, subject: 'LLMSubject', data: Dict[str, Any]) -> None:
        """LLM å¼€å§‹æ‰§è¡Œæ—¶è°ƒç”¨"""
        pass

    def on_end(self, subject: 'LLMSubject', data: Dict[str, Any]) -> None:
        """LLM æ‰§è¡Œç»“æŸæ—¶è°ƒç”¨"""
        pass

    def on_error(self, subject: 'LLMSubject', error: Exception) -> None:
        """LLM æ‰§è¡Œå‡ºé”™æ—¶è°ƒç”¨"""
        pass

    def on_token(self, subject: 'LLMSubject', token: str) -> None:
        """æµå¼è¾“å‡ºæ¯ä¸ª token æ—¶è°ƒç”¨"""
        pass

# ===== å…·ä½“è§‚å¯Ÿè€…å®ç° =====

class LoggingObserver(LLMObserver):
    """æ—¥å¿—è§‚å¯Ÿè€… - è®°å½• LLM æ‰§è¡Œæ—¥å¿—"""

    def __init__(self, log_level: str = "INFO"):
        self.log_level = log_level

    def on_start(self, subject, data):
        timestamp = datetime.now().strftime("%H:%M:%S")
        print(f"[{timestamp}] [{self.log_level}] LLM å¼€å§‹: {data.get('prompt', '')[:50]}...")

    def on_end(self, subject, data):
        timestamp = datetime.now().strftime("%H:%M:%S")
        print(f"[{timestamp}] [{self.log_level}] LLM ç»“æŸ: {data.get('response', '')[:50]}...")

    def on_error(self, subject, error):
        timestamp = datetime.now().strftime("%H:%M:%S")
        print(f"[{timestamp}] [ERROR] LLM é”™è¯¯: {error}")

class MetricsObserver(LLMObserver):
    """æŒ‡æ ‡è§‚å¯Ÿè€… - æ”¶é›†æ€§èƒ½æŒ‡æ ‡"""

    def __init__(self):
        self.call_count = 0
        self.total_tokens = 0
        self.start_time = None

    def on_start(self, subject, data):
        self.start_time = datetime.now()
        self.call_count += 1

    def on_end(self, subject, data):
        if self.start_time:
            duration = (datetime.now() - self.start_time).total_seconds()
            print(f"[METRICS] è°ƒç”¨æ¬¡æ•°: {self.call_count}, è€—æ—¶: {duration:.2f}s")

    def on_token(self, subject, token):
        self.total_tokens += 1

class StreamingObserver(LLMObserver):
    """æµå¼è¾“å‡ºè§‚å¯Ÿè€… - å®æ—¶æ˜¾ç¤ºç”Ÿæˆçš„å†…å®¹"""

    def on_token(self, subject, token):
        print(token, end="", flush=True)

    def on_end(self, subject, data):
        print()  # æ¢è¡Œ

class CostObserver(LLMObserver):
    """æˆæœ¬è§‚å¯Ÿè€… - è®¡ç®— API è°ƒç”¨æˆæœ¬"""

    PRICE_PER_1K_TOKENS = {
        "gpt-4": 0.03,
        "gpt-3.5-turbo": 0.002,
        "claude-3": 0.015,
    }

    def __init__(self):
        self.total_cost = 0.0

    def on_end(self, subject, data):
        model = getattr(subject, 'model_name', 'gpt-3.5-turbo')
        response = data.get('response', '')
        tokens = len(response.split())  # ç®€åŒ–çš„ token è®¡ç®—

        price = self.PRICE_PER_1K_TOKENS.get(model, 0.01)
        cost = (tokens / 1000) * price
        self.total_cost += cost

        print(f"[COST] æœ¬æ¬¡: ${cost:.4f}, ç´¯è®¡: ${self.total_cost:.4f}")
```

**è§‚å¯Ÿè€…çš„è®¾è®¡åŸåˆ™ï¼š**

| åŸåˆ™ | è¯´æ˜ | ç¤ºä¾‹ |
|------|------|------|
| å•ä¸€èŒè´£ | æ¯ä¸ªè§‚å¯Ÿè€…åªåšä¸€ä»¶äº‹ | LoggingObserver åªè®°å½•æ—¥å¿— |
| æ¥å£éš”ç¦» | åªå®ç°å…³å¿ƒçš„æ–¹æ³• | ä¸å…³å¿ƒçš„æ–¹æ³•ä¿æŒé»˜è®¤ç©ºå®ç° |
| æ— çŠ¶æ€æˆ–ç‹¬ç«‹çŠ¶æ€ | è§‚å¯Ÿè€…çš„çŠ¶æ€ä¸å½±å“è¢«è§‚å¯Ÿè€… | MetricsObserver çš„ call_count æ˜¯ç‹¬ç«‹çš„ |
| å¿«é€Ÿå“åº” | update æ–¹æ³•åº”è¯¥å¿«é€Ÿè¿”å› | é¿å…åœ¨å›è°ƒä¸­åšè€—æ—¶æ“ä½œ |

**åœ¨ LangChain æºç ä¸­çš„åº”ç”¨ï¼š**

```python
# langchain_core/callbacks/base.py ç®€åŒ–ç‰ˆ
class BaseCallbackHandler:
    """LangChain çš„ Callback è§‚å¯Ÿè€…åŸºç±»"""

    def on_llm_start(self, serialized, prompts, **kwargs):
        """LLM å¼€å§‹æ—¶è°ƒç”¨"""
        pass

    def on_llm_end(self, response, **kwargs):
        """LLM ç»“æŸæ—¶è°ƒç”¨"""
        pass

    def on_llm_error(self, error, **kwargs):
        """LLM å‡ºé”™æ—¶è°ƒç”¨"""
        pass

    def on_chain_start(self, serialized, inputs, **kwargs):
        """Chain å¼€å§‹æ—¶è°ƒç”¨"""
        pass

    def on_chain_end(self, outputs, **kwargs):
        """Chain ç»“æŸæ—¶è°ƒç”¨"""
        pass

    def on_tool_start(self, serialized, input_str, **kwargs):
        """Tool å¼€å§‹æ—¶è°ƒç”¨"""
        pass

    def on_tool_end(self, output, **kwargs):
        """Tool ç»“æŸæ—¶è°ƒç”¨"""
        pass

# å…·ä½“å®ç°
class StdOutCallbackHandler(BaseCallbackHandler):
    """æ ‡å‡†è¾“å‡º Callback - æ‰“å°æ‰§è¡Œè¿‡ç¨‹"""

    def on_llm_start(self, serialized, prompts, **kwargs):
        print(f"\n\n\033[1m> Entering LLM\033[0m")

    def on_llm_end(self, response, **kwargs):
        print(f"\n\033[1m> Finished LLM\033[0m")
```

---

### æ ¸å¿ƒæ¦‚å¿µ3ï¼šé€šçŸ¥æœºåˆ¶ï¼ˆNotificationï¼‰ ğŸ“¢

**é€šçŸ¥æœºåˆ¶æ˜¯è§‚å¯Ÿè€…æ¨¡å¼çš„æ ¸å¿ƒï¼Œå®šä¹‰äº†è¢«è§‚å¯Ÿè€…å¦‚ä½•å°†çŠ¶æ€å˜åŒ–ä¼ é€’ç»™è§‚å¯Ÿè€…**

```python
from abc import ABC, abstractmethod
from typing import Any, Dict, List, Callable
from enum import Enum
from dataclasses import dataclass

class NotificationType(Enum):
    """é€šçŸ¥ç±»å‹æšä¸¾"""
    PUSH = "push"      # æ¨æ¨¡å¼ï¼šè¢«è§‚å¯Ÿè€…ä¸»åŠ¨æ¨é€æ•°æ®
    PULL = "pull"      # æ‹‰æ¨¡å¼ï¼šè§‚å¯Ÿè€…ä¸»åŠ¨æ‹‰å–æ•°æ®

@dataclass
class Event:
    """äº‹ä»¶å¯¹è±¡ - å°è£…é€šçŸ¥ä¿¡æ¯"""
    name: str
    data: Dict[str, Any]
    source: Any
    timestamp: float

class NotificationManager:
    """
    é€šçŸ¥ç®¡ç†å™¨ - ç®¡ç†äº‹ä»¶åˆ†å‘

    æ”¯æŒï¼š
    1. åŒæ­¥/å¼‚æ­¥é€šçŸ¥
    2. äº‹ä»¶è¿‡æ»¤
    3. ä¼˜å…ˆçº§æ’åº
    """

    def __init__(self):
        self._observers: Dict[str, List[Callable]] = {}
        self._priority: Dict[Callable, int] = {}

    def subscribe(self, event_name: str, callback: Callable, priority: int = 0):
        """è®¢é˜…ç‰¹å®šäº‹ä»¶"""
        if event_name not in self._observers:
            self._observers[event_name] = []
        self._observers[event_name].append(callback)
        self._priority[callback] = priority

        # æŒ‰ä¼˜å…ˆçº§æ’åº
        self._observers[event_name].sort(
            key=lambda cb: self._priority.get(cb, 0),
            reverse=True
        )

    def unsubscribe(self, event_name: str, callback: Callable):
        """å–æ¶ˆè®¢é˜…"""
        if event_name in self._observers:
            self._observers[event_name].remove(callback)

    def notify(self, event: Event):
        """å‘é€é€šçŸ¥"""
        callbacks = self._observers.get(event.name, [])
        for callback in callbacks:
            try:
                callback(event)
            except Exception as e:
                print(f"Callback æ‰§è¡Œé”™è¯¯: {e}")

    def notify_all(self, event: Event):
        """é€šçŸ¥æ‰€æœ‰è§‚å¯Ÿè€…ï¼ˆä¸åŒºåˆ†äº‹ä»¶åï¼‰"""
        for callbacks in self._observers.values():
            for callback in callbacks:
                try:
                    callback(event)
                except Exception as e:
                    print(f"Callback æ‰§è¡Œé”™è¯¯: {e}")

# ===== æ¨æ¨¡å¼ vs æ‹‰æ¨¡å¼ =====

class PushSubject:
    """
    æ¨æ¨¡å¼è¢«è§‚å¯Ÿè€…

    ç‰¹ç‚¹ï¼šè¢«è§‚å¯Ÿè€…ä¸»åŠ¨å°†æ•°æ®æ¨é€ç»™è§‚å¯Ÿè€…
    ä¼˜ç‚¹ï¼šè§‚å¯Ÿè€…ç«‹å³è·å¾—æœ€æ–°æ•°æ®
    ç¼ºç‚¹ï¼šå¯èƒ½æ¨é€è§‚å¯Ÿè€…ä¸éœ€è¦çš„æ•°æ®
    """

    def __init__(self):
        self._observers = []
        self._data = {}

    def attach(self, observer):
        self._observers.append(observer)

    def notify(self):
        # æ¨æ¨¡å¼ï¼šå°†æ•°æ®ä½œä¸ºå‚æ•°ä¼ é€’
        for observer in self._observers:
            observer.update(self._data)  # æ¨é€å®Œæ•´æ•°æ®

    def set_data(self, key: str, value: Any):
        self._data[key] = value
        self.notify()

class PullSubject:
    """
    æ‹‰æ¨¡å¼è¢«è§‚å¯Ÿè€…

    ç‰¹ç‚¹ï¼šåªé€šçŸ¥è§‚å¯Ÿè€…"æœ‰å˜åŒ–äº†"ï¼Œè§‚å¯Ÿè€…è‡ªå·±æ¥æ‹‰å–
    ä¼˜ç‚¹ï¼šè§‚å¯Ÿè€…æŒ‰éœ€è·å–æ•°æ®
    ç¼ºç‚¹ï¼šå¯èƒ½éœ€è¦å¤šæ¬¡è®¿é—®è¢«è§‚å¯Ÿè€…
    """

    def __init__(self):
        self._observers = []
        self._data = {}

    def attach(self, observer):
        self._observers.append(observer)

    def notify(self):
        # æ‹‰æ¨¡å¼ï¼šåªä¼ é€’ self å¼•ç”¨
        for observer in self._observers:
            observer.update(self)  # è§‚å¯Ÿè€…éœ€è¦è‡ªå·±è°ƒç”¨ get_data

    def get_data(self, key: str) -> Any:
        """è§‚å¯Ÿè€…è°ƒç”¨æ­¤æ–¹æ³•æ‹‰å–æ•°æ®"""
        return self._data.get(key)

    def set_data(self, key: str, value: Any):
        self._data[key] = value
        self.notify()

# ===== LangChain é£æ ¼çš„ Callback Manager =====

class CallbackManager:
    """
    Callback ç®¡ç†å™¨ - ç±»ä¼¼ LangChain çš„ CallbackManager

    è´Ÿè´£ï¼š
    1. ç®¡ç†å¤šä¸ª Handler
    2. åœ¨åˆé€‚çš„æ—¶æœºè§¦å‘å›è°ƒ
    3. å¤„ç†å¼‚å¸¸
    """

    def __init__(self, handlers: List['BaseHandler'] = None):
        self.handlers = handlers or []

    def add_handler(self, handler: 'BaseHandler'):
        self.handlers.append(handler)

    def remove_handler(self, handler: 'BaseHandler'):
        self.handlers.remove(handler)

    def on_llm_start(self, **kwargs):
        """è§¦å‘ LLM å¼€å§‹äº‹ä»¶"""
        for handler in self.handlers:
            try:
                handler.on_llm_start(**kwargs)
            except Exception as e:
                print(f"Handler {handler.__class__.__name__} é”™è¯¯: {e}")

    def on_llm_end(self, **kwargs):
        """è§¦å‘ LLM ç»“æŸäº‹ä»¶"""
        for handler in self.handlers:
            try:
                handler.on_llm_end(**kwargs)
            except Exception as e:
                print(f"Handler {handler.__class__.__name__} é”™è¯¯: {e}")

    def on_llm_error(self, error: Exception, **kwargs):
        """è§¦å‘ LLM é”™è¯¯äº‹ä»¶"""
        for handler in self.handlers:
            try:
                handler.on_llm_error(error, **kwargs)
            except Exception as e:
                print(f"Handler {handler.__class__.__name__} é”™è¯¯: {e}")
```

**é€šçŸ¥æœºåˆ¶çš„å…³é”®ç‰¹å¾ï¼š**

| ç‰¹å¾ | æ¨æ¨¡å¼ | æ‹‰æ¨¡å¼ |
|------|--------|--------|
| æ•°æ®ä¼ é€’ | è¢«è§‚å¯Ÿè€…æ¨é€ | è§‚å¯Ÿè€…æ‹‰å– |
| å®æ—¶æ€§ | é«˜ | æŒ‰éœ€ |
| è€¦åˆåº¦ | è¾ƒé«˜ï¼ˆéœ€è¦çŸ¥é“æ•°æ®ç»“æ„ï¼‰ | è¾ƒä½ |
| LangChain ä½¿ç”¨ | Callback å‚æ•°ä¼ é€’ | è§‚å¯Ÿè€…å¯ä»¥è®¿é—®ç»„ä»¶çŠ¶æ€ |

**åœ¨ LangChain æºç ä¸­çš„åº”ç”¨ï¼š**

```python
# langchain_core/callbacks/manager.py ç®€åŒ–ç‰ˆ
class CallbackManager:
    """LangChain çš„ Callback ç®¡ç†å™¨"""

    def __init__(self, handlers=None):
        self.handlers = handlers or []

    def on_llm_start(self, serialized, prompts, **kwargs):
        """ä½¿ç”¨æ¨æ¨¡å¼ï¼šç›´æ¥ä¼ é€’æ‰€æœ‰ç›¸å…³æ•°æ®"""
        for handler in self.handlers:
            handler.on_llm_start(
                serialized=serialized,
                prompts=prompts,
                **kwargs
            )
```

---

### æ‰©å±•æ¦‚å¿µ4ï¼šäº‹ä»¶é©±åŠ¨ä¸è§‚å¯Ÿè€…æ¨¡å¼ ğŸ”„

```python
from typing import Callable, Dict, List, Any
import asyncio

class EventEmitter:
    """
    äº‹ä»¶å‘å°„å™¨ - è§‚å¯Ÿè€…æ¨¡å¼çš„äº‹ä»¶é©±åŠ¨å˜ä½“

    ç±»ä¼¼äº Node.js çš„ EventEmitter
    """

    def __init__(self):
        self._listeners: Dict[str, List[Callable]] = {}

    def on(self, event: str, listener: Callable) -> 'EventEmitter':
        """æ³¨å†Œäº‹ä»¶ç›‘å¬å™¨"""
        if event not in self._listeners:
            self._listeners[event] = []
        self._listeners[event].append(listener)
        return self

    def off(self, event: str, listener: Callable) -> 'EventEmitter':
        """ç§»é™¤äº‹ä»¶ç›‘å¬å™¨"""
        if event in self._listeners:
            self._listeners[event].remove(listener)
        return self

    def emit(self, event: str, *args, **kwargs) -> bool:
        """è§¦å‘äº‹ä»¶"""
        if event not in self._listeners:
            return False

        for listener in self._listeners[event]:
            listener(*args, **kwargs)
        return True

    def once(self, event: str, listener: Callable) -> 'EventEmitter':
        """æ³¨å†Œä¸€æ¬¡æ€§ç›‘å¬å™¨"""
        def wrapper(*args, **kwargs):
            self.off(event, wrapper)
            listener(*args, **kwargs)

        self.on(event, wrapper)
        return self

class AsyncEventEmitter(EventEmitter):
    """å¼‚æ­¥äº‹ä»¶å‘å°„å™¨"""

    async def emit_async(self, event: str, *args, **kwargs):
        """å¼‚æ­¥è§¦å‘äº‹ä»¶"""
        if event not in self._listeners:
            return False

        tasks = []
        for listener in self._listeners[event]:
            if asyncio.iscoroutinefunction(listener):
                tasks.append(listener(*args, **kwargs))
            else:
                listener(*args, **kwargs)

        if tasks:
            await asyncio.gather(*tasks)
        return True

# ä½¿ç”¨ç¤ºä¾‹
emitter = EventEmitter()

# æ³¨å†Œç›‘å¬å™¨
emitter.on("llm_start", lambda prompt: print(f"å¼€å§‹: {prompt}"))
emitter.on("llm_end", lambda result: print(f"ç»“æŸ: {result}"))
emitter.on("llm_token", lambda token: print(token, end=""))

# è§¦å‘äº‹ä»¶
emitter.emit("llm_start", "Hello, World!")
emitter.emit("llm_token", "Hello")
emitter.emit("llm_token", ", ")
emitter.emit("llm_token", "World!")
emitter.emit("llm_end", "Hello, World!")
```

---

### æ‰©å±•æ¦‚å¿µ5ï¼šå“åº”å¼ç¼–ç¨‹ä¸è§‚å¯Ÿè€… ğŸ“¡

```python
from typing import TypeVar, Generic, Callable, List

T = TypeVar('T')

class Observable(Generic[T]):
    """
    å¯è§‚å¯Ÿå¯¹è±¡ - å“åº”å¼ç¼–ç¨‹é£æ ¼

    ç±»ä¼¼äº RxPython çš„ Observable
    """

    def __init__(self, subscribe_func: Callable = None):
        self._subscribe_func = subscribe_func
        self._observers: List['ObserverInterface[T]'] = []

    def subscribe(self, observer: 'ObserverInterface[T]'):
        """è®¢é˜…"""
        self._observers.append(observer)
        if self._subscribe_func:
            self._subscribe_func(observer)
        return Subscription(self, observer)

    def _emit(self, value: T):
        """å‘é€å€¼"""
        for observer in self._observers:
            observer.on_next(value)

    def _complete(self):
        """å®Œæˆ"""
        for observer in self._observers:
            observer.on_complete()

    def _error(self, error: Exception):
        """é”™è¯¯"""
        for observer in self._observers:
            observer.on_error(error)

    # æ“ä½œç¬¦
    def map(self, mapper: Callable[[T], Any]) -> 'Observable':
        """æ˜ å°„æ“ä½œç¬¦"""
        def subscribe(observer):
            class MapObserver:
                def on_next(self, value):
                    observer.on_next(mapper(value))
                def on_error(self, error):
                    observer.on_error(error)
                def on_complete(self):
                    observer.on_complete()
            self.subscribe(MapObserver())

        return Observable(subscribe)

    def filter(self, predicate: Callable[[T], bool]) -> 'Observable':
        """è¿‡æ»¤æ“ä½œç¬¦"""
        def subscribe(observer):
            class FilterObserver:
                def on_next(self, value):
                    if predicate(value):
                        observer.on_next(value)
                def on_error(self, error):
                    observer.on_error(error)
                def on_complete(self):
                    observer.on_complete()
            self.subscribe(FilterObserver())

        return Observable(subscribe)

class ObserverInterface(Generic[T]):
    """è§‚å¯Ÿè€…æ¥å£"""

    def on_next(self, value: T):
        """æ¥æ”¶ä¸‹ä¸€ä¸ªå€¼"""
        pass

    def on_error(self, error: Exception):
        """æ¥æ”¶é”™è¯¯"""
        pass

    def on_complete(self):
        """å®Œæˆ"""
        pass

class Subscription:
    """è®¢é˜…å¯¹è±¡"""

    def __init__(self, observable: Observable, observer):
        self._observable = observable
        self._observer = observer

    def unsubscribe(self):
        """å–æ¶ˆè®¢é˜…"""
        self._observable._observers.remove(self._observer)
```

---

## 4. ã€æœ€å°å¯ç”¨ã€‘

æŒæ¡ä»¥ä¸‹å†…å®¹ï¼Œå°±èƒ½ç†è§£ LangChain Callback ç³»ç»Ÿçš„è®¾è®¡ï¼š

### 4.1 å®šä¹‰è§‚å¯Ÿè€…æ¥å£

```python
from abc import ABC, abstractmethod

class LLMCallback(ABC):
    """è§‚å¯Ÿè€…æ¥å£"""

    def on_start(self, prompt: str):
        """LLM å¼€å§‹æ—¶è°ƒç”¨ï¼ˆå¯é€‰å®ç°ï¼‰"""
        pass

    def on_end(self, result: str):
        """LLM ç»“æŸæ—¶è°ƒç”¨ï¼ˆå¯é€‰å®ç°ï¼‰"""
        pass

    def on_error(self, error: Exception):
        """LLM å‡ºé”™æ—¶è°ƒç”¨ï¼ˆå¯é€‰å®ç°ï¼‰"""
        pass
```

### 4.2 è¢«è§‚å¯Ÿè€…ç®¡ç†è§‚å¯Ÿè€…

```python
class LLMModel:
    """è¢«è§‚å¯Ÿè€…"""

    def __init__(self):
        self.callbacks = []  # è§‚å¯Ÿè€…åˆ—è¡¨

    def add_callback(self, callback: LLMCallback):
        """æ·»åŠ è§‚å¯Ÿè€…"""
        self.callbacks.append(callback)

    def remove_callback(self, callback: LLMCallback):
        """ç§»é™¤è§‚å¯Ÿè€…"""
        self.callbacks.remove(callback)

    def _notify(self, event: str, data):
        """é€šçŸ¥æ‰€æœ‰è§‚å¯Ÿè€…"""
        for cb in self.callbacks:
            method = getattr(cb, event, None)
            if method:
                method(data)
```

### 4.3 å®ç°å…·ä½“è§‚å¯Ÿè€…

```python
class PrintCallback(LLMCallback):
    """æ‰“å°å›è°ƒ"""

    def on_start(self, prompt):
        print(f"[START] {prompt}")

    def on_end(self, result):
        print(f"[END] {result}")

class CountCallback(LLMCallback):
    """è®¡æ•°å›è°ƒ"""

    def __init__(self):
        self.count = 0

    def on_end(self, result):
        self.count += 1
        print(f"[COUNT] æ€»è°ƒç”¨: {self.count}")
```

### 4.4 ä½¿ç”¨è§‚å¯Ÿè€…æ¨¡å¼

```python
# åˆ›å»ºè¢«è§‚å¯Ÿè€…
model = LLMModel()

# æ·»åŠ è§‚å¯Ÿè€…
model.add_callback(PrintCallback())
model.add_callback(CountCallback())

# æ‰§è¡Œæ—¶è‡ªåŠ¨é€šçŸ¥
model.generate("Hello")  # æ‰€æœ‰ callback éƒ½ä¼šè¢«è°ƒç”¨
```

**è¿™äº›çŸ¥è¯†è¶³ä»¥ï¼š**
- ç†è§£ LangChain `BaseCallbackHandler` çš„è®¾è®¡
- å®ç°è‡ªå®šä¹‰çš„ Callback Handler
- ç†è§£ä¸ºä»€ä¹ˆ Callback å¯ä»¥åŠ¨æ€æ·»åŠ /ç§»é™¤
- ä¸º LLM åº”ç”¨æ·»åŠ æ—¥å¿—ã€ç›‘æ§ã€æµå¼è¾“å‡ºç­‰åŠŸèƒ½

---

## 5. ã€1ä¸ªç±»æ¯”ã€‘ï¼ˆåŒè½¨åˆ¶ï¼‰

### ç±»æ¯”1ï¼šè§‚å¯Ÿè€…æ¨¡å¼ = è®¢é˜…é€šçŸ¥ç³»ç»Ÿ

#### ğŸ¨ å‰ç«¯è§†è§’ï¼šEventEmitter / DOM äº‹ä»¶

è§‚å¯Ÿè€…æ¨¡å¼å°±åƒ JavaScript çš„äº‹ä»¶ç³»ç»Ÿã€‚

```typescript
// JavaScript äº‹ä»¶ç›‘å¬ = è§‚å¯Ÿè€…æ¨¡å¼
const button = document.getElementById('btn');

// æ·»åŠ è§‚å¯Ÿè€…ï¼ˆäº‹ä»¶ç›‘å¬å™¨ï¼‰
button.addEventListener('click', (e) => {
  console.log('ç‚¹å‡»äº†æŒ‰é’®');
});

button.addEventListener('click', (e) => {
  analytics.track('button_click');
});

// ç‚¹å‡»æŒ‰é’®ï¼ˆçŠ¶æ€å˜åŒ–ï¼‰æ—¶ï¼Œæ‰€æœ‰ç›‘å¬å™¨éƒ½ä¼šè¢«è°ƒç”¨
button.click();
```

```python
# Python å¯¹åº”ï¼šLangChain Callback
model = ChatOpenAI()

# æ·»åŠ è§‚å¯Ÿè€…
model.callbacks = [
    LoggingHandler(),
    MetricsHandler(),
]

# è°ƒç”¨æ—¶è‡ªåŠ¨è§¦å‘æ‰€æœ‰ callback
model.invoke("Hello")
```

#### ğŸ§’ å°æœ‹å‹è§†è§’ï¼šç­çº§å¾®ä¿¡ç¾¤

è§‚å¯Ÿè€…æ¨¡å¼å°±åƒç­çº§å¾®ä¿¡ç¾¤çš„æ¶ˆæ¯é€šçŸ¥ã€‚

**ç”Ÿæ´»ä¾‹å­ï¼š**
```
ç­çº§å¾®ä¿¡ç¾¤ï¼ˆè§‚å¯Ÿè€…æ¨¡å¼ï¼‰ï¼š

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           ç­ä¸»ä»»ï¼ˆè¢«è§‚å¯Ÿè€…ï¼‰          â”‚
â”‚                                     â”‚
â”‚   çŠ¶æ€ï¼šæ˜å¤©è¦æ˜¥æ¸¸ï¼                  â”‚
â”‚                                     â”‚
â”‚   ç¾¤æˆå‘˜ï¼ˆè§‚å¯Ÿè€…ï¼‰ï¼š                  â”‚
â”‚   - å°æ˜çš„å¦ˆå¦ˆ âœ“ å·²è¯»               â”‚
â”‚   - å°çº¢çš„çˆ¸çˆ¸ âœ“ å·²è¯»               â”‚
â”‚   - å°åçš„å¥¶å¥¶ âœ“ å·²è¯»               â”‚
â”‚   - å°åˆšçš„çˆ¸çˆ¸ âœ“ å·²è¯»               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ç­ä¸»ä»»å‘æ¶ˆæ¯ï¼ˆçŠ¶æ€å˜åŒ–ï¼‰
  â†“
æ‰€æœ‰ç¾¤æˆå‘˜éƒ½æ”¶åˆ°é€šçŸ¥ï¼ˆè‡ªåŠ¨é€šçŸ¥ï¼‰
  â†“
æ¯ä¸ªå®¶é•¿å¯ä»¥é€‰æ‹©æ€ä¹ˆå¤„ç†ï¼ˆå„è‡ªå“åº”ï¼‰

ç‰¹ç‚¹ï¼š
1. ç­ä¸»ä»»ä¸éœ€è¦é€ä¸ªæ‰“ç”µè¯ï¼ˆç»Ÿä¸€é€šçŸ¥ï¼‰
2. æ–°å®¶é•¿è¿›ç¾¤å°±èƒ½æ”¶åˆ°æ¶ˆæ¯ï¼ˆåŠ¨æ€æ·»åŠ è§‚å¯Ÿè€…ï¼‰
3. é€€ç¾¤å°±ä¸å†æ”¶åˆ°ï¼ˆåŠ¨æ€ç§»é™¤è§‚å¯Ÿè€…ï¼‰
4. ç­ä¸»ä»»ä¸å…³å¿ƒè°çœ‹äº†ï¼ˆå‘å¸ƒè€…ä¸ä¾èµ–å…·ä½“è®¢é˜…è€…ï¼‰
```

---

### ç±»æ¯”2ï¼šæ¨æ¨¡å¼ vs æ‹‰æ¨¡å¼

#### ğŸ¨ å‰ç«¯è§†è§’ï¼šProps vs Context

```typescript
// æ¨æ¨¡å¼ï¼šåƒ Propsï¼Œçˆ¶ç»„ä»¶ç›´æ¥ä¼ æ•°æ®
function Parent() {
  const [data, setData] = useState({ count: 0 });

  return (
    // ç›´æ¥æŠŠæ•°æ®æ¨ç»™å­ç»„ä»¶
    <Child data={data} />
  );
}

function Child({ data }) {
  // å­ç»„ä»¶ç›´æ¥ä½¿ç”¨æ¨è¿‡æ¥çš„æ•°æ®
  return <div>{data.count}</div>;
}

// æ‹‰æ¨¡å¼ï¼šåƒ Contextï¼Œå­ç»„ä»¶è‡ªå·±å»å–
const DataContext = createContext();

function Parent() {
  const [data, setData] = useState({ count: 0 });

  return (
    <DataContext.Provider value={data}>
      <Child />
    </DataContext.Provider>
  );
}

function Child() {
  // å­ç»„ä»¶ä¸»åŠ¨æ‹‰å–éœ€è¦çš„æ•°æ®
  const data = useContext(DataContext);
  return <div>{data.count}</div>;
}
```

```python
# Python å¯¹åº”
# æ¨æ¨¡å¼
def on_llm_end(self, response, tokens, cost):  # æ•°æ®ä½œä¸ºå‚æ•°æ¨è¿‡æ¥
    print(f"å“åº”: {response}")

# æ‹‰æ¨¡å¼
def on_llm_end(self, llm):  # åªä¼ å¼•ç”¨ï¼Œè‡ªå·±å»æ‹‰
    response = llm.get_response()  # è‡ªå·±è°ƒç”¨è·å–
    tokens = llm.get_token_count()
```

#### ğŸ§’ å°æœ‹å‹è§†è§’ï¼šé€é¤ vs è‡ªåŠ©é¤

```
æ¨æ¨¡å¼ï¼šåƒå¤–å–é€é¤
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ å¤–å–å°å“¥ï¼ˆè¢«è§‚å¯Ÿè€…ï¼‰ç›´æ¥é€åˆ°ä½ æ‰‹ä¸Š    â”‚
â”‚                                     â”‚
â”‚ ä½ ç‚¹äº†æ±‰å ¡ã€è–¯æ¡ã€å¯ä¹               â”‚
â”‚ å¤–å–å°å“¥ï¼šå…¨éƒ¨ç»™ä½ ï¼ğŸ”ğŸŸğŸ¥¤            â”‚
â”‚                                     â”‚
â”‚ ä¼˜ç‚¹ï¼šæ–¹ä¾¿ï¼Œç›´æ¥å°±æœ‰                 â”‚
â”‚ ç¼ºç‚¹ï¼šå¯èƒ½é€äº†ä½ ä¸æƒ³è¦çš„             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

æ‹‰æ¨¡å¼ï¼šåƒè‡ªåŠ©é¤
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ é¤å…ï¼ˆè¢«è§‚å¯Ÿè€…ï¼‰å‘Šè¯‰ä½ "èœå¥½äº†"       â”‚
â”‚                                     â”‚
â”‚ ä½ è‡ªå·±å»æ‹¿æƒ³è¦çš„ï¼š                   â”‚
â”‚ - æˆ‘åªè¦æ±‰å ¡ ğŸ”                      â”‚
â”‚ - è–¯æ¡å’Œå¯ä¹ä¸è¦äº†                   â”‚
â”‚                                     â”‚
â”‚ ä¼˜ç‚¹ï¼šæŒ‰éœ€è·å–                       â”‚
â”‚ ç¼ºç‚¹ï¼šè¦è‡ªå·±è·‘ä¸€è¶Ÿ                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### ç±»æ¯”3ï¼šå›è°ƒé“¾ = æµæ°´çº¿

#### ğŸ¨ å‰ç«¯è§†è§’ï¼šExpress ä¸­é—´ä»¶

```typescript
// Express ä¸­é—´ä»¶ = è§‚å¯Ÿè€…é“¾
const app = express();

// å¤šä¸ª"è§‚å¯Ÿè€…"æŒ‰é¡ºåºå¤„ç†è¯·æ±‚
app.use(logger);       // è§‚å¯Ÿè€…1ï¼šè®°å½•æ—¥å¿—
app.use(auth);         // è§‚å¯Ÿè€…2ï¼šéªŒè¯èº«ä»½
app.use(rateLimit);    // è§‚å¯Ÿè€…3ï¼šé™æµ
app.use(handler);      // è§‚å¯Ÿè€…4ï¼šå¤„ç†è¯·æ±‚

// ä¸€ä¸ªè¯·æ±‚åˆ°æ¥ï¼Œæ‰€æœ‰ä¸­é—´ä»¶éƒ½ä¼šè¢«è°ƒç”¨
```

```python
# Python å¯¹åº”ï¼šLangChain Callback é“¾
callbacks = [
    LoggingHandler(),    # è§‚å¯Ÿè€…1
    MetricsHandler(),    # è§‚å¯Ÿè€…2
    CostHandler(),       # è§‚å¯Ÿè€…3
    StreamHandler(),     # è§‚å¯Ÿè€…4
]

# LLM è°ƒç”¨æ—¶ï¼Œæ‰€æœ‰ Handler éƒ½ä¼šè¢«é€šçŸ¥
model.invoke("Hello", callbacks=callbacks)
```

#### ğŸ§’ å°æœ‹å‹è§†è§’ï¼šæ¥åŠ›èµ›çš„è£åˆ¤ä»¬

```
æ¥åŠ›èµ›çš„è£åˆ¤ä»¬ï¼ˆè§‚å¯Ÿè€…é“¾ï¼‰ï¼š

è¿åŠ¨å‘˜è·‘æ­¥ï¼ˆäº‹ä»¶å‘ç”Ÿï¼‰
    â”‚
    â”œâ†’ è®¡æ—¶è£åˆ¤ï¼šå¼€å§‹è®¡æ—¶ï¼â±ï¸
    â”‚
    â”œâ†’ æ‘„åƒè£åˆ¤ï¼šå¼€å§‹å½•åƒï¼ğŸ“¹
    â”‚
    â”œâ†’ å¹¿æ’­å‘˜ï¼šæ’­æŠ¥æ¯”èµ›ï¼ğŸ“¢
    â”‚
    â””â†’ è®°åˆ†å‘˜ï¼šå‡†å¤‡è®°å½•ï¼ğŸ“

æ‰€æœ‰è£åˆ¤åŒæ—¶å·¥ä½œï¼Œäº’ä¸å¹²æ‰°ï¼
```

---

### ç±»æ¯”4ï¼šäº‹ä»¶è¿‡æ»¤ = æ¶ˆæ¯è®¢é˜…

#### ğŸ¨ å‰ç«¯è§†è§’ï¼šRedux Subscribe

```typescript
// Redux çš„è®¢é˜…æœºåˆ¶
const store = createStore(reducer);

// è®¢é˜…æ‰€æœ‰çŠ¶æ€å˜åŒ–
store.subscribe(() => {
  console.log('çŠ¶æ€å˜åŒ–äº†');
});

// ä½¿ç”¨ selector è¿‡æ»¤å…³å¿ƒçš„çŠ¶æ€
const useFilteredSubscribe = (selector) => {
  const [value, setValue] = useState(selector(store.getState()));

  useEffect(() => {
    return store.subscribe(() => {
      const newValue = selector(store.getState());
      if (newValue !== value) {
        setValue(newValue);
      }
    });
  }, []);

  return value;
};
```

```python
# Python å¯¹åº”ï¼šåªå…³å¿ƒç‰¹å®šäº‹ä»¶
class ErrorOnlyHandler(BaseCallbackHandler):
    """åªå…³å¿ƒé”™è¯¯äº‹ä»¶çš„è§‚å¯Ÿè€…"""

    def on_llm_error(self, error, **kwargs):
        # åªå®ç°é”™è¯¯å¤„ç†
        alert.send(f"LLM å‡ºé”™: {error}")

    # å…¶ä»–æ–¹æ³•ä¸å®ç°ï¼Œä½¿ç”¨é»˜è®¤ç©ºå®ç°
```

#### ğŸ§’ å°æœ‹å‹è§†è§’ï¼šè®¢é˜…å–œæ¬¢çš„ UP ä¸»

```
Bç«™è®¢é˜…ï¼ˆäº‹ä»¶è¿‡æ»¤ï¼‰ï¼š

UPä¸»å‘è§†é¢‘ï¼ˆäº‹ä»¶ç±»å‹ï¼‰ï¼š
- æ¸¸æˆè§†é¢‘ ğŸ®
- å­¦ä¹ è§†é¢‘ ğŸ“š
- éŸ³ä¹è§†é¢‘ ğŸµ
- ç”Ÿæ´»è§†é¢‘ ğŸ“·

å°æ˜çš„è®¢é˜…è®¾ç½®ï¼š
âœ“ æ¸¸æˆè§†é¢‘ â†’ æ”¶åˆ°é€šçŸ¥
âœ— å­¦ä¹ è§†é¢‘ â†’ ä¸é€šçŸ¥ï¼ˆä¸æ„Ÿå…´è¶£ï¼‰
âœ“ éŸ³ä¹è§†é¢‘ â†’ æ”¶åˆ°é€šçŸ¥
âœ— ç”Ÿæ´»è§†é¢‘ â†’ ä¸é€šçŸ¥ï¼ˆä¸æ„Ÿå…´è¶£ï¼‰

è§‚å¯Ÿè€…å¯ä»¥é€‰æ‹©åªå…³å¿ƒæŸäº›äº‹ä»¶ï¼
```

---

### ç±»æ¯”æ€»ç»“è¡¨

| è§‚å¯Ÿè€…æ¨¡å¼æ¦‚å¿µ | å‰ç«¯ç±»æ¯” | å°æœ‹å‹ç±»æ¯” |
|---------------|---------|-----------|
| è¢«è§‚å¯Ÿè€… | EventTarget / Store | ç­ä¸»ä»» / UPä¸» |
| è§‚å¯Ÿè€… | EventListener / Subscriber | ç¾¤æˆå‘˜ / ç²‰ä¸ |
| è®¢é˜…/æ³¨å†Œ | addEventListener / subscribe | åŠ å…¥ç¾¤èŠ / å…³æ³¨ |
| å–æ¶ˆè®¢é˜… | removeEventListener / unsubscribe | é€€ç¾¤ / å–å…³ |
| é€šçŸ¥/è§¦å‘ | dispatchEvent / dispatch | å‘æ¶ˆæ¯ / å‘è§†é¢‘ |
| æ¨æ¨¡å¼ | Props ä¼ é€’ | å¤–å–é€é¤ |
| æ‹‰æ¨¡å¼ | Context è·å– | è‡ªåŠ©é¤å–é¤ |
| å›è°ƒé“¾ | Express ä¸­é—´ä»¶ | æ¥åŠ›èµ›è£åˆ¤ |
| äº‹ä»¶è¿‡æ»¤ | Selector / Filter | è®¢é˜…åˆ†ç±» |

---

## 6. ã€åç›´è§‰ç‚¹ã€‘

### è¯¯åŒº1ï¼šè§‚å¯Ÿè€…æ¨¡å¼å°±æ˜¯ç®€å•çš„å›è°ƒå‡½æ•° âŒ

**ä¸ºä»€ä¹ˆé”™ï¼Ÿ**
- å›è°ƒå‡½æ•°æ˜¯**ä¸€å¯¹ä¸€**çš„ï¼šä¸€ä¸ªäº‹ä»¶å¯¹åº”ä¸€ä¸ªå›è°ƒ
- è§‚å¯Ÿè€…æ¨¡å¼æ˜¯**ä¸€å¯¹å¤š**çš„ï¼šä¸€ä¸ªäº‹ä»¶é€šçŸ¥å¤šä¸ªè§‚å¯Ÿè€…
- å›è°ƒå‡½æ•°é€šå¸¸æ˜¯ä¸´æ—¶çš„ï¼Œè§‚å¯Ÿè€…æ˜¯æŒä¹…çš„è®¢é˜…å…³ç³»
- è§‚å¯Ÿè€…æ¨¡å¼æœ‰å®Œæ•´çš„æ³¨å†Œ/æ³¨é”€/é€šçŸ¥æœºåˆ¶

**ä¸ºä»€ä¹ˆäººä»¬å®¹æ˜“è¿™æ ·é”™ï¼Ÿ**
å› ä¸ºä¸¤è€…éƒ½æ¶‰åŠ"æŸä»¶äº‹å‘ç”Ÿæ—¶æ‰§è¡ŒæŸä¸ªå‡½æ•°"ï¼Œè¡¨é¢çœ‹èµ·æ¥å¾ˆåƒã€‚ä½†è®¾è®¡ç›®çš„å’Œä½¿ç”¨åœºæ™¯å®Œå…¨ä¸åŒã€‚

**æ­£ç¡®ç†è§£ï¼š**

```python
# å›è°ƒå‡½æ•°ï¼šä¸€å¯¹ä¸€ï¼Œä¸´æ—¶
def fetch_data(url, callback):
    result = requests.get(url)
    callback(result)  # åªèƒ½æœ‰ä¸€ä¸ªå›è°ƒ

fetch_data("http://api.com", lambda r: print(r))

# è§‚å¯Ÿè€…æ¨¡å¼ï¼šä¸€å¯¹å¤šï¼ŒæŒä¹…
class DataFetcher:
    def __init__(self):
        self.observers = []  # å¯ä»¥æœ‰å¤šä¸ªè§‚å¯Ÿè€…

    def add_observer(self, observer):
        self.observers.append(observer)

    def fetch(self, url):
        result = requests.get(url)
        # é€šçŸ¥æ‰€æœ‰è§‚å¯Ÿè€…
        for observer in self.observers:
            observer.on_data(result)

fetcher = DataFetcher()
fetcher.add_observer(LogObserver())      # è§‚å¯Ÿè€…1
fetcher.add_observer(CacheObserver())    # è§‚å¯Ÿè€…2
fetcher.add_observer(AnalyticsObserver()) # è§‚å¯Ÿè€…3
fetcher.fetch("http://api.com")  # ä¸‰ä¸ªè§‚å¯Ÿè€…éƒ½ä¼šè¢«é€šçŸ¥
```

---

### è¯¯åŒº2ï¼šè§‚å¯Ÿè€…è¶Šå¤šè¶Šå¥½ï¼Œå¯ä»¥æ— é™æ·»åŠ  âŒ

**ä¸ºä»€ä¹ˆé”™ï¼Ÿ**
- è¿‡å¤šçš„è§‚å¯Ÿè€…ä¼šå¯¼è‡´**æ€§èƒ½é—®é¢˜**
- è§‚å¯Ÿè€…ä¹‹é—´å¯èƒ½æœ‰**é¡ºåºä¾èµ–**ï¼ˆå®é™…ä¸Šä¸åº”è¯¥æœ‰ï¼‰
- è°ƒè¯•å›°éš¾ï¼šä¸çŸ¥é“å“ªä¸ªè§‚å¯Ÿè€…å¯¼è‡´äº†é—®é¢˜
- å†…å­˜æ³„æ¼ï¼šå¿˜è®°ç§»é™¤ä¸å†éœ€è¦çš„è§‚å¯Ÿè€…

**ä¸ºä»€ä¹ˆäººä»¬å®¹æ˜“è¿™æ ·é”™ï¼Ÿ**
è§‚å¯Ÿè€…æ¨¡å¼çš„è®¾è®¡è®©æ·»åŠ è§‚å¯Ÿè€…å˜å¾—éå¸¸ç®€å•ï¼Œå®¹æ˜“è¿‡åº¦ä½¿ç”¨ã€‚è€Œä¸”"æ·»åŠ ä¸€ä¸ª callback ä¸ä¼šå½±å“å…¶ä»–åŠŸèƒ½"çš„æƒ³æ³•ä¼šè®©äººæ‰ä»¥è½»å¿ƒã€‚

**æ­£ç¡®ç†è§£ï¼š**

```python
# é”™è¯¯ï¼šæ— èŠ‚åˆ¶åœ°æ·»åŠ è§‚å¯Ÿè€…
model = LLMModel()
model.add_callback(LoggingCallback())
model.add_callback(MetricsCallback())
model.add_callback(CostCallback())
model.add_callback(CacheCallback())
model.add_callback(AlertCallback())
model.add_callback(DebugCallback())
model.add_callback(TraceCallback())
# ... 20 ä¸ª callback
# é—®é¢˜ï¼šæ¯æ¬¡è°ƒç”¨éƒ½è¦æ‰§è¡Œ 20 ä¸ªå›è°ƒï¼

# æ­£ç¡®ï¼šæŒ‰éœ€æ·»åŠ ï¼ŒåŠæ—¶æ¸…ç†
class SmartCallbackManager:
    def __init__(self, max_callbacks: int = 10):
        self.callbacks = []
        self.max_callbacks = max_callbacks

    def add_callback(self, callback):
        if len(self.callbacks) >= self.max_callbacks:
            raise ValueError(f"æœ€å¤šåªèƒ½æ·»åŠ  {self.max_callbacks} ä¸ªå›è°ƒ")
        self.callbacks.append(callback)

    def clear(self):
        """æ¸…ç†æ‰€æœ‰å›è°ƒ"""
        self.callbacks.clear()

# ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨ç¡®ä¿æ¸…ç†
class CallbackContext:
    def __init__(self, model, callbacks):
        self.model = model
        self.callbacks = callbacks

    def __enter__(self):
        for cb in self.callbacks:
            self.model.add_callback(cb)
        return self.model

    def __exit__(self, *args):
        for cb in self.callbacks:
            self.model.remove_callback(cb)

# ä½¿ç”¨
with CallbackContext(model, [LoggingCallback()]) as m:
    m.generate("Hello")
# é€€å‡º with å—æ—¶è‡ªåŠ¨æ¸…ç† callback
```

---

### è¯¯åŒº3ï¼šè§‚å¯Ÿè€…ä¹‹é—´å¯ä»¥äº’ç›¸ä¾èµ–å’Œé€šä¿¡ âŒ

**ä¸ºä»€ä¹ˆé”™ï¼Ÿ**
- è§‚å¯Ÿè€…åº”è¯¥æ˜¯**ç‹¬ç«‹çš„**ï¼Œä¸åº”è¯¥çŸ¥é“å…¶ä»–è§‚å¯Ÿè€…çš„å­˜åœ¨
- è§‚å¯Ÿè€…ä¹‹é—´çš„ä¾èµ–ä¼šå¯¼è‡´**å¾ªç¯è°ƒç”¨**
- è¿åäº†è§‚å¯Ÿè€…æ¨¡å¼"æ¾è€¦åˆ"çš„è®¾è®¡åˆè¡·
- å¦‚æœéœ€è¦åè°ƒå¤šä¸ªè§‚å¯Ÿè€…ï¼Œåº”è¯¥é€šè¿‡è¢«è§‚å¯Ÿè€…æˆ–ä¸­ä»‹è€…

**ä¸ºä»€ä¹ˆäººä»¬å®¹æ˜“è¿™æ ·é”™ï¼Ÿ**
å½“å¤šä¸ªè§‚å¯Ÿè€…éœ€è¦ååŒå·¥ä½œæ—¶ï¼ˆæ¯”å¦‚æ—¥å¿—éœ€è¦åŒ…å«æŒ‡æ ‡ä¿¡æ¯ï¼‰ï¼Œç›´è§‰ä¸Šä¼šæƒ³è®©å®ƒä»¬ç›´æ¥é€šä¿¡ã€‚ä½†è¿™ä¼šç ´åæ¨¡å¼çš„ç®€æ´æ€§ã€‚

**æ­£ç¡®ç†è§£ï¼š**

```python
# é”™è¯¯ï¼šè§‚å¯Ÿè€…ä¹‹é—´äº’ç›¸ä¾èµ–
class LoggingCallback(LLMCallback):
    def __init__(self, metrics_callback):
        self.metrics = metrics_callback  # ä¾èµ–å¦ä¸€ä¸ªè§‚å¯Ÿè€…ï¼

    def on_end(self, result):
        # è®¿é—®å¦ä¸€ä¸ªè§‚å¯Ÿè€…çš„æ•°æ®
        count = self.metrics.call_count  # è€¦åˆï¼
        print(f"ç¬¬ {count} æ¬¡è°ƒç”¨: {result}")

# æ­£ç¡®ï¼šé€šè¿‡è¢«è§‚å¯Ÿè€…æˆ–äº‹ä»¶æºå¸¦æ‰€éœ€ä¿¡æ¯
class LoggingCallback(LLMCallback):
    def on_end(self, result, metadata=None):
        # ä»äº‹ä»¶å‚æ•°è·å–ä¿¡æ¯ï¼Œä¸ä¾èµ–å…¶ä»–è§‚å¯Ÿè€…
        call_count = metadata.get("call_count", 0) if metadata else 0
        print(f"ç¬¬ {call_count} æ¬¡è°ƒç”¨: {result}")

# æˆ–è€…ï¼šä½¿ç”¨ä¸­ä»‹è€…æ¨¡å¼
class CallbackMediator:
    """ä¸­ä»‹è€…ï¼šåè°ƒå¤šä¸ª callback ä¹‹é—´çš„é€šä¿¡"""

    def __init__(self):
        self.shared_state = {}

    def set(self, key, value):
        self.shared_state[key] = value

    def get(self, key, default=None):
        return self.shared_state.get(key, default)

class MetricsCallback(LLMCallback):
    def __init__(self, mediator):
        self.mediator = mediator
        self.count = 0

    def on_end(self, result):
        self.count += 1
        self.mediator.set("call_count", self.count)  # é€šè¿‡ä¸­ä»‹è€…å…±äº«

class LoggingCallback(LLMCallback):
    def __init__(self, mediator):
        self.mediator = mediator

    def on_end(self, result):
        count = self.mediator.get("call_count", 0)  # ä»ä¸­ä»‹è€…è·å–
        print(f"ç¬¬ {count} æ¬¡è°ƒç”¨: {result}")
```

---

## 7. ã€å®æˆ˜ä»£ç ã€‘

```python
"""
ç¤ºä¾‹ï¼šæ„å»º LangChain é£æ ¼çš„ Callback ç³»ç»Ÿ
æ¼”ç¤ºè§‚å¯Ÿè€…æ¨¡å¼åœ¨ LLM åº”ç”¨ä¸­çš„æ ¸å¿ƒç”¨æ³•
"""

from abc import ABC, abstractmethod
from typing import Any, Dict, List, Optional, Generator
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum
import time
import json

# ===== 1. åŸºç¡€ç±»å‹å®šä¹‰ =====
print("=== 1. åŸºç¡€ç±»å‹å®šä¹‰ ===")

class EventType(Enum):
    """äº‹ä»¶ç±»å‹æšä¸¾"""
    LLM_START = "llm_start"
    LLM_END = "llm_end"
    LLM_ERROR = "llm_error"
    LLM_TOKEN = "llm_token"
    CHAIN_START = "chain_start"
    CHAIN_END = "chain_end"
    TOOL_START = "tool_start"
    TOOL_END = "tool_end"

@dataclass
class Event:
    """äº‹ä»¶å¯¹è±¡"""
    type: EventType
    data: Dict[str, Any]
    timestamp: datetime = field(default_factory=datetime.now)
    source: str = ""

# ===== 2. è§‚å¯Ÿè€…æ¥å£ï¼ˆBaseCallbackHandlerï¼‰ =====
print("\n=== 2. è§‚å¯Ÿè€…æ¥å£ ===")

class BaseCallbackHandler(ABC):
    """
    å›è°ƒå¤„ç†å™¨åŸºç±» - ç±»ä¼¼ LangChain çš„ BaseCallbackHandler

    å®šä¹‰äº† LLM/Chain/Tool æ‰§è¡Œè¿‡ç¨‹ä¸­çš„æ‰€æœ‰é’©å­æ–¹æ³•
    å­ç±»å¯ä»¥é€‰æ‹©æ€§åœ°è¦†ç›–å…³å¿ƒçš„æ–¹æ³•
    """

    # ===== LLM ç›¸å…³å›è°ƒ =====

    def on_llm_start(self, serialized: Dict[str, Any], prompts: List[str], **kwargs) -> None:
        """LLM å¼€å§‹æ‰§è¡Œæ—¶è°ƒç”¨"""
        pass

    def on_llm_end(self, response: str, **kwargs) -> None:
        """LLM æ‰§è¡Œç»“æŸæ—¶è°ƒç”¨"""
        pass

    def on_llm_error(self, error: Exception, **kwargs) -> None:
        """LLM æ‰§è¡Œå‡ºé”™æ—¶è°ƒç”¨"""
        pass

    def on_llm_new_token(self, token: str, **kwargs) -> None:
        """æµå¼è¾“å‡ºæ¯ä¸ª token æ—¶è°ƒç”¨"""
        pass

    # ===== Chain ç›¸å…³å›è°ƒ =====

    def on_chain_start(self, serialized: Dict[str, Any], inputs: Dict[str, Any], **kwargs) -> None:
        """Chain å¼€å§‹æ‰§è¡Œæ—¶è°ƒç”¨"""
        pass

    def on_chain_end(self, outputs: Dict[str, Any], **kwargs) -> None:
        """Chain æ‰§è¡Œç»“æŸæ—¶è°ƒç”¨"""
        pass

    def on_chain_error(self, error: Exception, **kwargs) -> None:
        """Chain æ‰§è¡Œå‡ºé”™æ—¶è°ƒç”¨"""
        pass

    # ===== Tool ç›¸å…³å›è°ƒ =====

    def on_tool_start(self, serialized: Dict[str, Any], input_str: str, **kwargs) -> None:
        """Tool å¼€å§‹æ‰§è¡Œæ—¶è°ƒç”¨"""
        pass

    def on_tool_end(self, output: str, **kwargs) -> None:
        """Tool æ‰§è¡Œç»“æŸæ—¶è°ƒç”¨"""
        pass

    def on_tool_error(self, error: Exception, **kwargs) -> None:
        """Tool æ‰§è¡Œå‡ºé”™æ—¶è°ƒç”¨"""
        pass

# ===== 3. å…·ä½“è§‚å¯Ÿè€…å®ç° =====
print("\n=== 3. å…·ä½“è§‚å¯Ÿè€…å®ç° ===")

class StdOutCallbackHandler(BaseCallbackHandler):
    """æ ‡å‡†è¾“å‡ºå›è°ƒå¤„ç†å™¨ - æ‰“å°æ‰§è¡Œè¿‡ç¨‹"""

    def __init__(self, color: bool = True):
        self.color = color

    def _print(self, message: str, color_code: str = ""):
        if self.color and color_code:
            print(f"\033[{color_code}m{message}\033[0m")
        else:
            print(message)

    def on_llm_start(self, serialized, prompts, **kwargs):
        self._print("\n> Entering LLM...", "1")  # ç²—ä½“
        for i, prompt in enumerate(prompts):
            self._print(f"  Prompt {i+1}: {prompt[:50]}...", "36")  # é’è‰²

    def on_llm_end(self, response, **kwargs):
        self._print(f"> LLM Response: {response[:100]}...", "32")  # ç»¿è‰²
        self._print("> Finished LLM\n", "1")

    def on_llm_error(self, error, **kwargs):
        self._print(f"> LLM Error: {error}", "31")  # çº¢è‰²

    def on_chain_start(self, serialized, inputs, **kwargs):
        chain_name = serialized.get("name", "Unknown")
        self._print(f"\n>> Entering Chain: {chain_name}", "1;34")  # ç²—ä½“è“è‰²

    def on_chain_end(self, outputs, **kwargs):
        self._print(f">> Chain Output: {str(outputs)[:100]}...", "34")

class StreamingCallbackHandler(BaseCallbackHandler):
    """æµå¼è¾“å‡ºå›è°ƒå¤„ç†å™¨ - å®æ—¶æ˜¾ç¤º token"""

    def __init__(self, stream_prefix: str = ""):
        self.stream_prefix = stream_prefix
        self.token_count = 0

    def on_llm_start(self, serialized, prompts, **kwargs):
        print(f"{self.stream_prefix}", end="", flush=True)
        self.token_count = 0

    def on_llm_new_token(self, token, **kwargs):
        print(token, end="", flush=True)
        self.token_count += 1

    def on_llm_end(self, response, **kwargs):
        print(f"\n[å…± {self.token_count} ä¸ª token]")

class MetricsCallbackHandler(BaseCallbackHandler):
    """æŒ‡æ ‡æ”¶é›†å›è°ƒå¤„ç†å™¨ - æ”¶é›†æ€§èƒ½æ•°æ®"""

    def __init__(self):
        self.llm_calls = 0
        self.chain_calls = 0
        self.tool_calls = 0
        self.errors = 0
        self.total_tokens = 0
        self.start_times: Dict[str, datetime] = {}
        self.durations: List[float] = []

    def on_llm_start(self, serialized, prompts, **kwargs):
        self.start_times["llm"] = datetime.now()

    def on_llm_end(self, response, **kwargs):
        self.llm_calls += 1
        if "llm" in self.start_times:
            duration = (datetime.now() - self.start_times["llm"]).total_seconds()
            self.durations.append(duration)

    def on_llm_new_token(self, token, **kwargs):
        self.total_tokens += 1

    def on_llm_error(self, error, **kwargs):
        self.errors += 1

    def on_chain_start(self, serialized, inputs, **kwargs):
        self.start_times["chain"] = datetime.now()

    def on_chain_end(self, outputs, **kwargs):
        self.chain_calls += 1

    def on_tool_end(self, output, **kwargs):
        self.tool_calls += 1

    def get_summary(self) -> Dict[str, Any]:
        avg_duration = sum(self.durations) / len(self.durations) if self.durations else 0
        return {
            "llm_calls": self.llm_calls,
            "chain_calls": self.chain_calls,
            "tool_calls": self.tool_calls,
            "errors": self.errors,
            "total_tokens": self.total_tokens,
            "avg_duration_seconds": round(avg_duration, 3),
        }

class CostCallbackHandler(BaseCallbackHandler):
    """æˆæœ¬è®¡ç®—å›è°ƒå¤„ç†å™¨ - è®¡ç®— API è°ƒç”¨æˆæœ¬"""

    PRICE_PER_1K_TOKENS = {
        "gpt-4": {"input": 0.03, "output": 0.06},
        "gpt-3.5-turbo": {"input": 0.0015, "output": 0.002},
        "claude-3-opus": {"input": 0.015, "output": 0.075},
        "claude-3-sonnet": {"input": 0.003, "output": 0.015},
    }

    def __init__(self):
        self.total_cost = 0.0
        self.cost_history: List[Dict] = []

    def on_llm_end(self, response, **kwargs):
        model = kwargs.get("model", "gpt-3.5-turbo")
        input_tokens = kwargs.get("input_tokens", 0)
        output_tokens = kwargs.get("output_tokens", len(response.split()))

        prices = self.PRICE_PER_1K_TOKENS.get(model, {"input": 0.01, "output": 0.01})
        cost = (input_tokens / 1000 * prices["input"] +
                output_tokens / 1000 * prices["output"])

        self.total_cost += cost
        self.cost_history.append({
            "model": model,
            "cost": cost,
            "timestamp": datetime.now().isoformat(),
        })

        print(f"[COST] æœ¬æ¬¡: ${cost:.6f}, ç´¯è®¡: ${self.total_cost:.6f}")

class JSONLogCallbackHandler(BaseCallbackHandler):
    """JSON æ—¥å¿—å›è°ƒå¤„ç†å™¨ - è¾“å‡ºç»“æ„åŒ–æ—¥å¿—"""

    def __init__(self, log_file: str = None):
        self.log_file = log_file
        self.logs: List[Dict] = []

    def _log(self, event: str, data: Dict):
        log_entry = {
            "timestamp": datetime.now().isoformat(),
            "event": event,
            "data": data,
        }
        self.logs.append(log_entry)

        if self.log_file:
            with open(self.log_file, "a") as f:
                f.write(json.dumps(log_entry) + "\n")

    def on_llm_start(self, serialized, prompts, **kwargs):
        self._log("llm_start", {"prompts": prompts, "model": serialized.get("name")})

    def on_llm_end(self, response, **kwargs):
        self._log("llm_end", {"response_length": len(response)})

    def on_llm_error(self, error, **kwargs):
        self._log("llm_error", {"error": str(error), "type": type(error).__name__})

# ===== 4. Callback ç®¡ç†å™¨ï¼ˆè¢«è§‚å¯Ÿè€…ï¼‰ =====
print("\n=== 4. Callback ç®¡ç†å™¨ ===")

class CallbackManager:
    """
    Callback ç®¡ç†å™¨ - ç±»ä¼¼ LangChain çš„ CallbackManager

    ä½œä¸ºè¢«è§‚å¯Ÿè€…ï¼Œç®¡ç†æ‰€æœ‰ Handler å¹¶åœ¨é€‚å½“æ—¶æœºè§¦å‘å›è°ƒ
    """

    def __init__(self, handlers: List[BaseCallbackHandler] = None):
        self.handlers = handlers or []

    def add_handler(self, handler: BaseCallbackHandler) -> None:
        """æ·»åŠ  Handler"""
        if handler not in self.handlers:
            self.handlers.append(handler)
            print(f"[CallbackManager] æ·»åŠ  Handler: {handler.__class__.__name__}")

    def remove_handler(self, handler: BaseCallbackHandler) -> None:
        """ç§»é™¤ Handler"""
        if handler in self.handlers:
            self.handlers.remove(handler)
            print(f"[CallbackManager] ç§»é™¤ Handler: {handler.__class__.__name__}")

    def _trigger(self, event_name: str, *args, **kwargs) -> None:
        """è§¦å‘æŒ‡å®šäº‹ä»¶"""
        for handler in self.handlers:
            method = getattr(handler, event_name, None)
            if method:
                try:
                    method(*args, **kwargs)
                except Exception as e:
                    print(f"[CallbackManager] Handler {handler.__class__.__name__} é”™è¯¯: {e}")

    # ===== LLM äº‹ä»¶ =====

    def on_llm_start(self, serialized: Dict, prompts: List[str], **kwargs):
        self._trigger("on_llm_start", serialized, prompts, **kwargs)

    def on_llm_end(self, response: str, **kwargs):
        self._trigger("on_llm_end", response, **kwargs)

    def on_llm_error(self, error: Exception, **kwargs):
        self._trigger("on_llm_error", error, **kwargs)

    def on_llm_new_token(self, token: str, **kwargs):
        self._trigger("on_llm_new_token", token, **kwargs)

    # ===== Chain äº‹ä»¶ =====

    def on_chain_start(self, serialized: Dict, inputs: Dict, **kwargs):
        self._trigger("on_chain_start", serialized, inputs, **kwargs)

    def on_chain_end(self, outputs: Dict, **kwargs):
        self._trigger("on_chain_end", outputs, **kwargs)

    # ===== Tool äº‹ä»¶ =====

    def on_tool_start(self, serialized: Dict, input_str: str, **kwargs):
        self._trigger("on_tool_start", serialized, input_str, **kwargs)

    def on_tool_end(self, output: str, **kwargs):
        self._trigger("on_tool_end", output, **kwargs)

# ===== 5. LLM æ¨¡å‹ï¼ˆä½¿ç”¨ Callbackï¼‰ =====
print("\n=== 5. LLM æ¨¡å‹ ===")

class FakeLLM:
    """
    æ¨¡æ‹Ÿ LLM - å±•ç¤ºå¦‚ä½•åœ¨æ¨¡å‹ä¸­ä½¿ç”¨ Callback

    ç±»ä¼¼ LangChain çš„ ChatModel
    """

    def __init__(self, model_name: str = "gpt-3.5-turbo"):
        self.model_name = model_name

    def invoke(self, prompt: str, callbacks: CallbackManager = None) -> str:
        """åŒæ­¥è°ƒç”¨"""
        serialized = {"name": self.model_name, "type": "llm"}

        # é€šçŸ¥å¼€å§‹
        if callbacks:
            callbacks.on_llm_start(serialized, [prompt])

        try:
            # æ¨¡æ‹Ÿ API è°ƒç”¨
            time.sleep(0.1)
            response = f"[{self.model_name}] Response to: {prompt}"

            # é€šçŸ¥ç»“æŸ
            if callbacks:
                callbacks.on_llm_end(response, model=self.model_name)

            return response

        except Exception as e:
            if callbacks:
                callbacks.on_llm_error(e)
            raise

    def stream(self, prompt: str, callbacks: CallbackManager = None) -> Generator[str, None, None]:
        """æµå¼è°ƒç”¨"""
        serialized = {"name": self.model_name, "type": "llm"}

        if callbacks:
            callbacks.on_llm_start(serialized, [prompt])

        try:
            response = f"[{self.model_name}] Response to: {prompt}"
            full_response = ""

            for char in response:
                time.sleep(0.02)  # æ¨¡æ‹Ÿæµå¼å»¶è¿Ÿ
                full_response += char

                if callbacks:
                    callbacks.on_llm_new_token(char)

                yield char

            if callbacks:
                callbacks.on_llm_end(full_response, model=self.model_name)

        except Exception as e:
            if callbacks:
                callbacks.on_llm_error(e)
            raise

# ===== 6. ä½¿ç”¨ç¤ºä¾‹ =====
print("\n=== 6. ä½¿ç”¨ç¤ºä¾‹ ===")

# åˆ›å»º LLM
llm = FakeLLM("gpt-4")

# åˆ›å»º Callback ç®¡ç†å™¨
callback_manager = CallbackManager()

# æ·»åŠ å„ç§ Handler
stdout_handler = StdOutCallbackHandler()
metrics_handler = MetricsCallbackHandler()
cost_handler = CostCallbackHandler()

callback_manager.add_handler(stdout_handler)
callback_manager.add_handler(metrics_handler)
callback_manager.add_handler(cost_handler)

# åŒæ­¥è°ƒç”¨
print("\n--- åŒæ­¥è°ƒç”¨ ---")
response = llm.invoke("What is Python?", callbacks=callback_manager)
print(f"æœ€ç»ˆå“åº”: {response}")

# æµå¼è°ƒç”¨
print("\n--- æµå¼è°ƒç”¨ ---")
streaming_handler = StreamingCallbackHandler("AI: ")
callback_manager.add_handler(streaming_handler)

for chunk in llm.stream("Explain machine learning", callbacks=callback_manager):
    pass  # token å·²ç»åœ¨ callback ä¸­æ‰“å°

# æŸ¥çœ‹æŒ‡æ ‡
print("\n--- æŒ‡æ ‡æ±‡æ€» ---")
print(json.dumps(metrics_handler.get_summary(), indent=2))

# ===== 7. Chain ç¤ºä¾‹ï¼ˆåµŒå¥— Callbackï¼‰ =====
print("\n=== 7. Chain ç¤ºä¾‹ ===")

class FakeChain:
    """æ¨¡æ‹Ÿ Chain - å±•ç¤ºåµŒå¥—çš„ Callback è°ƒç”¨"""

    def __init__(self, llm: FakeLLM, name: str = "SimpleChain"):
        self.llm = llm
        self.name = name

    def invoke(self, inputs: Dict, callbacks: CallbackManager = None) -> Dict:
        serialized = {"name": self.name, "type": "chain"}

        # Chain å¼€å§‹
        if callbacks:
            callbacks.on_chain_start(serialized, inputs)

        try:
            # è°ƒç”¨ LLMï¼ˆä¼šè§¦å‘ LLM çš„ callbackï¼‰
            prompt = inputs.get("prompt", "")
            response = self.llm.invoke(prompt, callbacks=callbacks)

            outputs = {"response": response}

            # Chain ç»“æŸ
            if callbacks:
                callbacks.on_chain_end(outputs)

            return outputs

        except Exception as e:
            if callbacks:
                callbacks.on_chain_error(e)
            raise

# ä½¿ç”¨ Chain
chain = FakeChain(llm, name="QAChain")
result = chain.invoke({"prompt": "What is AI?"}, callbacks=callback_manager)
print(f"\nChain ç»“æœ: {result}")

# ===== 8. åŠ¨æ€æ·»åŠ /ç§»é™¤ Handler =====
print("\n=== 8. åŠ¨æ€æ·»åŠ /ç§»é™¤ Handler ===")

# ç§»é™¤ streaming handler
callback_manager.remove_handler(streaming_handler)

# æ·»åŠ  JSON æ—¥å¿— handler
json_handler = JSONLogCallbackHandler()
callback_manager.add_handler(json_handler)

# å†æ¬¡è°ƒç”¨
llm.invoke("Final test", callbacks=callback_manager)

# æŸ¥çœ‹ JSON æ—¥å¿—
print("\nJSON æ—¥å¿—:")
for log in json_handler.logs[-2:]:
    print(json.dumps(log, indent=2))

print("\n=== å®Œæˆ ===")
```

**è¿è¡Œè¾“å‡ºç¤ºä¾‹ï¼š**
```
=== 1. åŸºç¡€ç±»å‹å®šä¹‰ ===

=== 2. è§‚å¯Ÿè€…æ¥å£ ===

=== 3. å…·ä½“è§‚å¯Ÿè€…å®ç° ===

=== 4. Callback ç®¡ç†å™¨ ===

=== 5. LLM æ¨¡å‹ ===

=== 6. ä½¿ç”¨ç¤ºä¾‹ ===
[CallbackManager] æ·»åŠ  Handler: StdOutCallbackHandler
[CallbackManager] æ·»åŠ  Handler: MetricsCallbackHandler
[CallbackManager] æ·»åŠ  Handler: CostCallbackHandler

--- åŒæ­¥è°ƒç”¨ ---

> Entering LLM...
  Prompt 1: What is Python?...
> LLM Response: [gpt-4] Response to: What is Python?...
> Finished LLM

[COST] æœ¬æ¬¡: $0.000360, ç´¯è®¡: $0.000360
æœ€ç»ˆå“åº”: [gpt-4] Response to: What is Python?

--- æµå¼è°ƒç”¨ ---
[CallbackManager] æ·»åŠ  Handler: StreamingCallbackHandler
AI: [gpt-4] Response to: Explain machine learning
[å…± 47 ä¸ª token]
[COST] æœ¬æ¬¡: $0.002820, ç´¯è®¡: $0.003180

--- æŒ‡æ ‡æ±‡æ€» ---
{
  "llm_calls": 2,
  "chain_calls": 0,
  "tool_calls": 0,
  "errors": 0,
  "total_tokens": 47,
  "avg_duration_seconds": 0.523
}

=== 7. Chain ç¤ºä¾‹ ===

>> Entering Chain: QAChain

> Entering LLM...
  Prompt 1: What is AI?...
> LLM Response: [gpt-4] Response to: What is AI?...
> Finished LLM

[COST] æœ¬æ¬¡: $0.000240, ç´¯è®¡: $0.003420
>> Chain Output: {'response': '[gpt-4] Response to: What is AI?'}...

Chain ç»“æœ: {'response': '[gpt-4] Response to: What is AI?'}

=== 8. åŠ¨æ€æ·»åŠ /ç§»é™¤ Handler ===
[CallbackManager] ç§»é™¤ Handler: StreamingCallbackHandler
[CallbackManager] æ·»åŠ  Handler: JSONLogCallbackHandler

> Entering LLM...
  Prompt 1: Final test...
> LLM Response: [gpt-4] Response to: Final test...
> Finished LLM

[COST] æœ¬æ¬¡: $0.000240, ç´¯è®¡: $0.003660

JSON æ—¥å¿—:
{
  "timestamp": "2024-01-15T10:30:45.123456",
  "event": "llm_start",
  "data": {"prompts": ["Final test"], "model": "gpt-4"}
}
{
  "timestamp": "2024-01-15T10:30:45.234567",
  "event": "llm_end",
  "data": {"response_length": 35}
}

=== å®Œæˆ ===
```

---

## 8. ã€é¢è¯•å¿…é—®ã€‘

### é—®é¢˜ï¼š"ä»€ä¹ˆæ˜¯è§‚å¯Ÿè€…æ¨¡å¼ï¼Ÿåœ¨ LangChain ä¸­æ˜¯æ€ä¹ˆåº”ç”¨çš„ï¼Ÿ"

**æ™®é€šå›ç­”ï¼ˆâŒ ä¸å‡ºå½©ï¼‰ï¼š**
"è§‚å¯Ÿè€…æ¨¡å¼æ˜¯ä¸€ç§è®¾è®¡æ¨¡å¼ï¼Œå½“ä¸€ä¸ªå¯¹è±¡çŠ¶æ€æ”¹å˜æ—¶é€šçŸ¥å…¶ä»–å¯¹è±¡ã€‚LangChain çš„ Callback å°±æ˜¯ç”¨è¿™ä¸ªæ¨¡å¼å®ç°çš„ï¼Œå¯ä»¥åœ¨ LLM è°ƒç”¨æ—¶è§¦å‘å›è°ƒã€‚"

**å‡ºå½©å›ç­”ï¼ˆâœ… æ¨èï¼‰ï¼š**

> **è§‚å¯Ÿè€…æ¨¡å¼æœ‰ä¸‰å±‚ç†è§£ï¼š**
>
> 1. **æ¨¡å¼æœ¬è´¨**ï¼š
>    - å®šä¹‰å¯¹è±¡é—´**ä¸€å¯¹å¤š**çš„ä¾èµ–å…³ç³»
>    - è¢«è§‚å¯Ÿè€…ï¼ˆSubjectï¼‰çŠ¶æ€å˜åŒ–æ—¶ï¼Œè‡ªåŠ¨é€šçŸ¥æ‰€æœ‰è§‚å¯Ÿè€…ï¼ˆObserverï¼‰
>    - æ ¸å¿ƒä»·å€¼ï¼š**è§£è€¦**â€”â€”å‘å¸ƒè€…ä¸éœ€è¦çŸ¥é“è®¢é˜…è€…æ˜¯è°
>
> 2. **å…³é”®ç»„ä»¶**ï¼š
>    - **Subjectï¼ˆè¢«è§‚å¯Ÿè€…ï¼‰**ï¼šç»´æŠ¤è§‚å¯Ÿè€…åˆ—è¡¨ï¼ŒçŠ¶æ€å˜åŒ–æ—¶é€šçŸ¥
>    - **Observerï¼ˆè§‚å¯Ÿè€…ï¼‰**ï¼šå®šä¹‰æ¥æ”¶é€šçŸ¥çš„æ¥å£
>    - **ConcreteObserverï¼ˆå…·ä½“è§‚å¯Ÿè€…ï¼‰**ï¼šå®ç°å“åº”é€»è¾‘
>    - **é€šçŸ¥æœºåˆ¶**ï¼šæ¨æ¨¡å¼ï¼ˆæ¨é€æ•°æ®ï¼‰æˆ–æ‹‰æ¨¡å¼ï¼ˆåªé€šçŸ¥ï¼Œè‡ªå·±æ‹‰å–ï¼‰
>
> 3. **LangChain ä¸­çš„åº”ç”¨**ï¼š
>    ```python
>    # LangChain çš„ Callback ç³»ç»Ÿå°±æ˜¯è§‚å¯Ÿè€…æ¨¡å¼
>
>    # Subjectï¼šLLM/Chain/Agent
>    model = ChatOpenAI()
>
>    # Observersï¼šå„ç§ Handler
>    model.invoke("Hello", callbacks=[
>        StdOutCallbackHandler(),  # æ‰“å°æ—¥å¿—
>        StreamingHandler(),       # æµå¼è¾“å‡º
>        CostHandler(),            # æˆæœ¬è®¡ç®—
>    ])
>
>    # å½“ LLM æ‰§è¡Œæ—¶ï¼Œè‡ªåŠ¨è§¦å‘ï¼š
>    # on_llm_start() â†’ on_llm_new_token() â†’ on_llm_end()
>    ```
>
> **è®¾è®¡ä¼˜åŠ¿**ï¼š
> - **å¯æ’æ‹”**ï¼šåŠ¨æ€æ·»åŠ /ç§»é™¤ Handlerï¼Œä¸å½±å“æ ¸å¿ƒé€»è¾‘
> - **å•ä¸€èŒè´£**ï¼šæ¯ä¸ª Handler åªåšä¸€ä»¶äº‹ï¼ˆæ—¥å¿—/ç›‘æ§/æµå¼/æˆæœ¬ï¼‰
> - **å¼€é—­åŸåˆ™**ï¼šæ–°å¢åŠŸèƒ½åªéœ€æ·»åŠ  Handlerï¼Œä¸æ”¹ LLM ä»£ç 
>
> **ä¸å…¶ä»–æ¨¡å¼çš„å…³ç³»**ï¼š
> - è§‚å¯Ÿè€…æ¨¡å¼å…³æ³¨"é€šçŸ¥å¤šä¸ªå¯¹è±¡"
> - ç­–ç•¥æ¨¡å¼å…³æ³¨"ç®—æ³•å¯æ›¿æ¢"
> - LangChain ä¸¤è€…éƒ½ç”¨ï¼šCallback ç”¨è§‚å¯Ÿè€…ï¼ŒLLM é€‰æ‹©ç”¨ç­–ç•¥

**ä¸ºä»€ä¹ˆè¿™ä¸ªå›ç­”å‡ºå½©ï¼Ÿ**
1. âœ… å±‚æ¬¡æ¸…æ™°ï¼ˆæœ¬è´¨/ç»„ä»¶/åº”ç”¨ï¼‰
2. âœ… ç»“åˆ LangChain çœŸå®ä»£ç 
3. âœ… è¯´æ˜äº†è®¾è®¡ä¼˜åŠ¿
4. âœ… å¯¹æ¯”äº†ç›¸å…³æ¨¡å¼

---

### é—®é¢˜ï¼š"è§‚å¯Ÿè€…æ¨¡å¼å’Œå‘å¸ƒ-è®¢é˜…æ¨¡å¼æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ"

**æ™®é€šå›ç­”ï¼ˆâŒ ä¸å‡ºå½©ï¼‰ï¼š**
"å·®ä¸å¤šå§ï¼Œéƒ½æ˜¯ä¸€ä¸ªå‘æ¶ˆæ¯ï¼Œå¤šä¸ªæ¥æ”¶ã€‚å‘å¸ƒ-è®¢é˜…å¯èƒ½æœ‰ä¸ªä¸­é—´çš„æ¶ˆæ¯é˜Ÿåˆ—ã€‚"

**å‡ºå½©å›ç­”ï¼ˆâœ… æ¨èï¼‰ï¼š**

> **ä¸¤è€…çš„æ ¸å¿ƒåŒºåˆ«åœ¨äºè€¦åˆç¨‹åº¦ï¼š**
>
> | å¯¹æ¯”ç»´åº¦ | è§‚å¯Ÿè€…æ¨¡å¼ | å‘å¸ƒ-è®¢é˜…æ¨¡å¼ |
> |---------|-----------|-------------|
> | è€¦åˆåº¦ | Subject çŸ¥é“ Observer | Publisher ä¸çŸ¥é“ Subscriber |
> | ä¸­é—´å±‚ | æ—  | æœ‰ Event Channel/Broker |
> | é€šä¿¡æ–¹å¼ | ç›´æ¥è°ƒç”¨ | é€šè¿‡æ¶ˆæ¯ä¸­é—´ä»¶ |
> | é€‚ç”¨åœºæ™¯ | åŒä¸€è¿›ç¨‹å†… | è·¨è¿›ç¨‹/åˆ†å¸ƒå¼ |
>
> **è§‚å¯Ÿè€…æ¨¡å¼ï¼š**
> ```python
> # è¢«è§‚å¯Ÿè€…ç›´æ¥æŒæœ‰è§‚å¯Ÿè€…å¼•ç”¨
> class LLM:
>     def __init__(self):
>         self.observers = []  # ç›´æ¥ç®¡ç†è§‚å¯Ÿè€…
>
>     def notify(self):
>         for obs in self.observers:
>             obs.update()  # ç›´æ¥è°ƒç”¨
> ```
>
> **å‘å¸ƒ-è®¢é˜…æ¨¡å¼ï¼š**
> ```python
> # é€šè¿‡æ¶ˆæ¯æ€»çº¿è§£è€¦
> class EventBus:
>     subscribers = {}
>
>     @classmethod
>     def subscribe(cls, event, handler):
>         cls.subscribers.setdefault(event, []).append(handler)
>
>     @classmethod
>     def publish(cls, event, data):
>         for handler in cls.subscribers.get(event, []):
>             handler(data)
>
> # Publisher å’Œ Subscriber äº’ä¸çŸ¥é“å¯¹æ–¹å­˜åœ¨
> EventBus.subscribe("llm_done", lambda d: print(d))
> EventBus.publish("llm_done", "Hello")
> ```
>
> **LangChain çš„é€‰æ‹©**ï¼š
> - æ ¸å¿ƒ Callback ç”¨**è§‚å¯Ÿè€…æ¨¡å¼**ï¼ˆåŒæ­¥ã€ä½å»¶è¿Ÿï¼‰
> - åˆ†å¸ƒå¼è¿½è¸ªï¼ˆLangSmithï¼‰æ›´åƒ**å‘å¸ƒ-è®¢é˜…**ï¼ˆå¼‚æ­¥ã€è·¨æœåŠ¡ï¼‰
>
> **é€‰æ‹©æ ‡å‡†**ï¼š
> - åŒä¸€è¿›ç¨‹ã€éœ€è¦åŒæ­¥å“åº” â†’ è§‚å¯Ÿè€…æ¨¡å¼
> - è·¨è¿›ç¨‹ã€å¼‚æ­¥è§£è€¦ â†’ å‘å¸ƒ-è®¢é˜…æ¨¡å¼

---

## 9. ã€åŒ–éª¨ç»µæŒã€‘

### å¡ç‰‡1ï¼šä»€ä¹ˆæ˜¯è§‚å¯Ÿè€…æ¨¡å¼ ğŸ¯

**ä¸€å¥è¯ï¼š** ä¸€å¯¹å¤šçš„ä¾èµ–å…³ç³»ï¼Œä¸€ä¸ªå¯¹è±¡å˜åŒ–æ—¶è‡ªåŠ¨é€šçŸ¥æ‰€æœ‰ä¾èµ–å®ƒçš„å¯¹è±¡ã€‚

**ä¸¾ä¾‹ï¼š**
```python
class Subject:
    def __init__(self):
        self.observers = []

    def notify(self):
        for obs in self.observers:
            obs.update()  # é€šçŸ¥æ‰€æœ‰è§‚å¯Ÿè€…
```

**åº”ç”¨ï¼š** LangChain çš„ Callback ç³»ç»Ÿï¼Œä¸€ä¸ª LLM è°ƒç”¨é€šçŸ¥å¤šä¸ª Handlerã€‚

---

### å¡ç‰‡2ï¼šè¢«è§‚å¯Ÿè€…ï¼ˆSubjectï¼‰ ğŸ“¢

**ä¸€å¥è¯ï¼š** çŠ¶æ€å˜åŒ–çš„æºå¤´ï¼Œè´Ÿè´£ç®¡ç†è§‚å¯Ÿè€…å¹¶å‘é€é€šçŸ¥ã€‚

**ä¸¾ä¾‹ï¼š**
```python
class LLM:
    callbacks = []  # ç®¡ç†è§‚å¯Ÿè€…

    def add_callback(self, cb):
        self.callbacks.append(cb)

    def invoke(self, prompt):
        for cb in self.callbacks:
            cb.on_start(prompt)  # å‘é€é€šçŸ¥
```

**åº”ç”¨ï¼š** LangChain çš„ ChatModelã€Chainã€Agent éƒ½æ˜¯è¢«è§‚å¯Ÿè€…ã€‚

---

### å¡ç‰‡3ï¼šè§‚å¯Ÿè€…ï¼ˆObserverï¼‰ ğŸ‘€

**ä¸€å¥è¯ï¼š** å…³å¿ƒçŠ¶æ€å˜åŒ–çš„å¯¹è±¡ï¼Œæ”¶åˆ°é€šçŸ¥æ—¶æ‰§è¡Œå“åº”é€»è¾‘ã€‚

**ä¸¾ä¾‹ï¼š**
```python
class LoggingCallback:
    def on_start(self, prompt):
        print(f"[LOG] {prompt}")

    def on_end(self, result):
        print(f"[LOG] {result}")
```

**åº”ç”¨ï¼š** LangChain çš„ BaseCallbackHandler åŠå…¶æ‰€æœ‰å®ç°ç±»ã€‚

---

### å¡ç‰‡4ï¼šé€šçŸ¥æœºåˆ¶ ğŸ“¬

**ä¸€å¥è¯ï¼š** è¢«è§‚å¯Ÿè€…å°†çŠ¶æ€å˜åŒ–ä¼ é€’ç»™è§‚å¯Ÿè€…çš„æ–¹å¼ã€‚

**ä¸¤ç§æ¨¡å¼ï¼š**
```python
# æ¨æ¨¡å¼ï¼šç›´æ¥ä¼ æ•°æ®
def notify(self):
    for obs in self.observers:
        obs.update(self.data)  # æ¨é€æ•°æ®

# æ‹‰æ¨¡å¼ï¼šåªé€šçŸ¥ï¼Œè§‚å¯Ÿè€…è‡ªå·±å–
def notify(self):
    for obs in self.observers:
        obs.update(self)  # ä¼ å¼•ç”¨ï¼Œè‡ªå·±æ‹‰å–
```

**åº”ç”¨ï¼š** LangChain Callback ä½¿ç”¨æ¨æ¨¡å¼ï¼Œç›´æ¥ä¼ é€’ responseã€prompts ç­‰ã€‚

---

### å¡ç‰‡5ï¼šåŠ¨æ€è®¢é˜…ä¸å–æ¶ˆ ğŸ”„

**ä¸€å¥è¯ï¼š** è§‚å¯Ÿè€…å¯ä»¥åœ¨è¿è¡Œæ—¶æ·»åŠ æˆ–ç§»é™¤ï¼Œæ— éœ€ä¿®æ”¹è¢«è§‚å¯Ÿè€…ä»£ç ã€‚

**ä¸¾ä¾‹ï¼š**
```python
model = ChatOpenAI()

# å¼€å‘ç¯å¢ƒ
model.callbacks.append(DebugHandler())

# ç”Ÿäº§ç¯å¢ƒ
model.callbacks.append(MetricsHandler())
model.callbacks.remove(DebugHandler())
```

**åº”ç”¨ï¼š** åŒä¸€ä¸ª LLM åœ¨ä¸åŒç¯å¢ƒä½¿ç”¨ä¸åŒçš„ Handler ç»„åˆã€‚

---

### å¡ç‰‡6ï¼šäº‹ä»¶ç±»å‹ ğŸ·ï¸

**ä¸€å¥è¯ï¼š** è¢«è§‚å¯Ÿè€…å¯ä»¥è§¦å‘å¤šç§ç±»å‹çš„äº‹ä»¶ï¼Œè§‚å¯Ÿè€…é€‰æ‹©æ€§å“åº”ã€‚

**ä¸¾ä¾‹ï¼š**
```python
class BaseCallbackHandler:
    def on_llm_start(self, ...): pass  # LLM å¼€å§‹
    def on_llm_end(self, ...): pass    # LLM ç»“æŸ
    def on_llm_error(self, ...): pass  # LLM å‡ºé”™
    def on_chain_start(self, ...): pass # Chain å¼€å§‹
    # ... æ›´å¤šäº‹ä»¶ç±»å‹
```

**åº”ç”¨ï¼š** LangChain å®šä¹‰äº† LLM/Chain/Tool ç­‰å¤šç§äº‹ä»¶ç±»å‹ã€‚

---

### å¡ç‰‡7ï¼šè§‚å¯Ÿè€…é“¾ ğŸ”—

**ä¸€å¥è¯ï¼š** å¤šä¸ªè§‚å¯Ÿè€…æŒ‰é¡ºåºå¤„ç†åŒä¸€äº‹ä»¶ï¼Œå½¢æˆå¤„ç†é“¾ã€‚

**ä¸¾ä¾‹ï¼š**
```python
callbacks = [
    LoggingHandler(),   # 1. å…ˆè®°å½•æ—¥å¿—
    MetricsHandler(),   # 2. å†æ”¶é›†æŒ‡æ ‡
    CostHandler(),      # 3. æœ€åè®¡ç®—æˆæœ¬
]

# æŒ‰é¡ºåºè§¦å‘
for cb in callbacks:
    cb.on_llm_end(response)
```

**åº”ç”¨ï¼š** LangChain çš„ CallbackManager æŒ‰é¡ºåºè§¦å‘æ‰€æœ‰ Handlerã€‚

---

### å¡ç‰‡8ï¼šè§£è€¦çš„ä»·å€¼ ğŸ”“

**ä¸€å¥è¯ï¼š** è¢«è§‚å¯Ÿè€…ä¸ä¾èµ–å…·ä½“çš„è§‚å¯Ÿè€…å®ç°ï¼Œåªä¾èµ–æŠ½è±¡æ¥å£ã€‚

**ä¸¾ä¾‹ï¼š**
```python
# LLM ä¸çŸ¥é“å…·ä½“æœ‰å“ªäº› Handler
class LLM:
    def invoke(self, prompt, callbacks):
        for cb in callbacks:
            cb.on_end(result)  # åªè°ƒç”¨æ¥å£æ–¹æ³•

# ä»»ä½•å®ç°äº†æ¥å£çš„ Handler éƒ½å¯ä»¥ç”¨
```

**åº”ç”¨ï¼š** å¯ä»¥éšæ—¶æ·»åŠ æ–°çš„ Handler ç±»å‹ï¼Œä¸ä¿®æ”¹ LLM ä»£ç ã€‚

---

### å¡ç‰‡9ï¼šLangChain Callback ç³»ç»Ÿ ğŸ¦œ

**ä¸€å¥è¯ï¼š** LangChain çš„ Callback æ˜¯è§‚å¯Ÿè€…æ¨¡å¼çš„å…¸å‹åº”ç”¨ã€‚

**æ ¸å¿ƒç±»ï¼š**
```python
# è§‚å¯Ÿè€…æ¥å£
class BaseCallbackHandler:
    def on_llm_start(self, ...): ...
    def on_llm_end(self, ...): ...

# è¢«è§‚å¯Ÿè€…ç®¡ç†
class CallbackManager:
    handlers: List[BaseCallbackHandler]

# ä½¿ç”¨
model.invoke("Hello", callbacks=[Handler1(), Handler2()])
```

**åº”ç”¨ï¼š** æ—¥å¿—ã€ç›‘æ§ã€æµå¼è¾“å‡ºã€æˆæœ¬è®¡ç®—ã€è¿½è¸ªç­‰å…¨é  Callbackã€‚

---

### å¡ç‰‡10ï¼šè§‚å¯Ÿè€…æ¨¡å¼æ€»ç»“ â­

**ä¸€å¥è¯ï¼š** ä¸€å¯¹å¤šé€šçŸ¥ï¼Œæ¾è€¦åˆï¼Œå¯æ’æ‹”ã€‚

**æ ¸å¿ƒè¦ç‚¹ï¼š**
1. Subject ç»´æŠ¤ Observer åˆ—è¡¨
2. çŠ¶æ€å˜åŒ–æ—¶è‡ªåŠ¨é€šçŸ¥
3. Observer åªä¾èµ–æ¥å£
4. å¯åŠ¨æ€æ·»åŠ /ç§»é™¤
5. LangChain Callback æ˜¯å…¸å‹åº”ç”¨

**è®°ä½ï¼š** çœ‹åˆ° `callbacks`ã€`handlers`ã€`listeners`ã€`subscribers` å°±æƒ³åˆ°è§‚å¯Ÿè€…æ¨¡å¼ï¼

---

## 10. ã€ä¸€å¥è¯æ€»ç»“ã€‘

**è§‚å¯Ÿè€…æ¨¡å¼é€šè¿‡å®šä¹‰å¯¹è±¡é—´ä¸€å¯¹å¤šçš„ä¾èµ–å…³ç³»ï¼Œå®ç°çŠ¶æ€å˜åŒ–æ—¶è‡ªåŠ¨é€šçŸ¥æ‰€æœ‰è®¢é˜…è€…ï¼Œæ˜¯ LangChain Callback ç³»ç»Ÿçš„æ¶æ„åŸºç¡€ï¼Œä½¿å¾—æ—¥å¿—è®°å½•ã€æ€§èƒ½ç›‘æ§ã€æµå¼è¾“å‡ºã€æˆæœ¬è®¡ç®—ç­‰åŠŸèƒ½å¯ä»¥ä½œä¸ºç‹¬ç«‹çš„ Handler åŠ¨æ€æ’æ‹”ã€‚**

---

## ğŸ“š å­¦ä¹ æ£€æŸ¥æ¸…å•

- [ ] ç†è§£è§‚å¯Ÿè€…æ¨¡å¼çš„æ ¸å¿ƒæ€æƒ³ï¼ˆä¸€å¯¹å¤šã€è‡ªåŠ¨é€šçŸ¥ï¼‰
- [ ] èƒ½åŒºåˆ†è¢«è§‚å¯Ÿè€…ï¼ˆSubjectï¼‰å’Œè§‚å¯Ÿè€…ï¼ˆObserverï¼‰
- [ ] èƒ½å®ç° BaseCallbackHandler é£æ ¼çš„è§‚å¯Ÿè€…æ¥å£
- [ ] èƒ½å®ç° CallbackManager é£æ ¼çš„è¢«è§‚å¯Ÿè€…
- [ ] ç†è§£æ¨æ¨¡å¼å’Œæ‹‰æ¨¡å¼çš„åŒºåˆ«
- [ ] èƒ½å¤Ÿè¯†åˆ« LangChain æºç ä¸­çš„è§‚å¯Ÿè€…æ¨¡å¼
- [ ] ç†è§£è§‚å¯Ÿè€…æ¨¡å¼ vs å‘å¸ƒ-è®¢é˜…æ¨¡å¼çš„åŒºåˆ«
- [ ] èƒ½å¤Ÿä½¿ç”¨è§‚å¯Ÿè€…æ¨¡å¼å®ç°è‡ªå®šä¹‰ Callback Handler

## ğŸ”— ä¸‹ä¸€æ­¥å­¦ä¹ 

- **æŠ½è±¡ç±»ä¸æ¥å£ï¼ˆABCæ¨¡å—ï¼‰**ï¼šè§‚å¯Ÿè€…æ¥å£çš„å®ç°åŸºç¡€
- **ä¾èµ–æ³¨å…¥åŸç†**ï¼šCallback æ³¨å…¥çš„è®¾è®¡æ¨¡å¼
- **Callback å›è°ƒç³»ç»Ÿ**ï¼šLangChain æºç ä¸­çš„å…·ä½“å®ç°
- **æµå¼è¾“å‡º Streaming**ï¼šStreamingCallbackHandler çš„åº”ç”¨

---

**ç‰ˆæœ¬ï¼š** v1.0
**æœ€åæ›´æ–°ï¼š** 2025-12-12
